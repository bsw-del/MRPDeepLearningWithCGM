{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bensa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from cProfile import label\n",
    "from statistics import mode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, SimpleRNN, Dropout, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RecID</th>\n",
       "      <th>PtID</th>\n",
       "      <th>ParentCITYDeviceUploadsID</th>\n",
       "      <th>DeviceDtTm</th>\n",
       "      <th>RecordType</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "      <th>SortOrd</th>\n",
       "      <th>ValueMMOL</th>\n",
       "      <th>DDate</th>\n",
       "      <th>hourOfDay</th>\n",
       "      <th>series</th>\n",
       "      <th>series_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1539485</td>\n",
       "      <td>39</td>\n",
       "      <td>651</td>\n",
       "      <td>2000-04-21 04:31:56</td>\n",
       "      <td>CGM</td>\n",
       "      <td>135.0</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>7880.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2000-04-21</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>73331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1539486</td>\n",
       "      <td>39</td>\n",
       "      <td>651</td>\n",
       "      <td>2000-04-21 04:36:55</td>\n",
       "      <td>CGM</td>\n",
       "      <td>133.0</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>7881.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2000-04-21</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>73331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1539487</td>\n",
       "      <td>39</td>\n",
       "      <td>651</td>\n",
       "      <td>2000-04-21 04:41:55</td>\n",
       "      <td>CGM</td>\n",
       "      <td>133.0</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2000-04-21</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>73331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1539488</td>\n",
       "      <td>39</td>\n",
       "      <td>651</td>\n",
       "      <td>2000-04-21 04:46:56</td>\n",
       "      <td>CGM</td>\n",
       "      <td>133.0</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>7883.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2000-04-21</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>73331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1539489</td>\n",
       "      <td>39</td>\n",
       "      <td>651</td>\n",
       "      <td>2000-04-21 04:51:56</td>\n",
       "      <td>CGM</td>\n",
       "      <td>134.0</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>7884.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2000-04-21</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>73331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  index  Unnamed: 0    RecID  PtID  ParentCITYDeviceUploadsID  \\\n",
       "0             0      0           0  1539485    39                        651   \n",
       "1             1      1           1  1539486    39                        651   \n",
       "2             2      2           2  1539487    39                        651   \n",
       "3             3      3           3  1539488    39                        651   \n",
       "4             4      4           4  1539489    39                        651   \n",
       "\n",
       "            DeviceDtTm RecordType  Value  Units  SortOrd  ValueMMOL  \\\n",
       "0  2000-04-21 04:31:56        CGM  135.0  mg/dL   7880.0        7.5   \n",
       "1  2000-04-21 04:36:55        CGM  133.0  mg/dL   7881.0        7.4   \n",
       "2  2000-04-21 04:41:55        CGM  133.0  mg/dL   7882.0        7.4   \n",
       "3  2000-04-21 04:46:56        CGM  133.0  mg/dL   7883.0        7.4   \n",
       "4  2000-04-21 04:51:56        CGM  134.0  mg/dL   7884.0        7.4   \n",
       "\n",
       "        DDate  hourOfDay  series  series_id  \n",
       "0  2000-04-21          4   False      73331  \n",
       "1  2000-04-21          4   False      73331  \n",
       "2  2000-04-21          4   False      73331  \n",
       "3  2000-04-21          4   False      73331  \n",
       "4  2000-04-21          4   False      73331  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_for_data = 'C:\\\\Users\\\\bensa\\\\Documents\\\\MRPLocal\\\\Data'\n",
    "cgm_data = 'CGM_Processed.csv'\n",
    "file_cgm = os.path.join(path_for_data, cgm_data)\n",
    "\n",
    "data_obj = DataCleaning(filename=file_cgm, path=path_for_data)\n",
    "## load dataframe from cleaned data\n",
    "\n",
    "\n",
    "CGMDf = pd.read_csv(file_cgm)\n",
    "CGMDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58207"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CGMDf[CGMDf.PtID==39].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment Plans\n",
    "\n",
    "Build out models to compare performance on\n",
    "Look at hyperparameter tuning\n",
    "ONce models are adequately baked, then move to A and B below\n",
    "\n",
    "A Experiment on using different patients inputs and keeping track of metrics\n",
    "B Experiment on using feature engineering and build out metrics further\n",
    "\n",
    "\n",
    "Implement Data cleaning from development to the data helper functions\n",
    "Add in ability to look at a per patient basis\n",
    "Perhaps start with overall data size, and then with a % set to train v test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test (df):\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return (X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def root_mean_error(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.math.squared_difference(y_true, y_pred)))\n",
    "\n",
    "\n",
    "class RunModel:\n",
    "\n",
    "    def __init__(self,X_train, X_test, y_train, y_test):\n",
    "        #self.X_train = (tf.convert_to_tensor(X_train) - tf.math.reduce_min(tf.convert_to_tensor(X_train))) / (tf.math.reduce_max(tf.convert_to_tensor(X_train)) - tf.math.reduce_min(tf.convert_to_tensor(X_train)))\n",
    "        #self.y_train = (tf.convert_to_tensor(y_train) - tf.math.reduce_min(tf.convert_to_tensor(y_train))) / (tf.math.reduce_max(tf.convert_to_tensor(y_train)) - tf.math.reduce_min(tf.convert_to_tensor(y_train)))\n",
    "        #self.X_test = (tf.convert_to_tensor(X_test) - tf.math.reduce_min(tf.convert_to_tensor(X_test))) / (tf.math.reduce_max(tf.convert_to_tensor(X_test)) - tf.math.reduce_min(tf.convert_to_tensor(X_test)))\n",
    "        #self.y_test = (tf.convert_to_tensor(y_test) - tf.math.reduce_min(tf.convert_to_tensor(y_test))) / (tf.math.reduce_max(tf.convert_to_tensor(y_test)) - tf.math.reduce_min(tf.convert_to_tensor(y_test)))\n",
    "        self.X_train = np.array(X_train)\n",
    "        self.y_train = np.array(y_train)\n",
    "        self.X_test = np.array(X_test)\n",
    "        self.y_test = np.array(y_test)\n",
    "        self.metric_df = pd.DataFrame()\n",
    "\n",
    "    def rnn_model(self):\n",
    "        model_rnn = Sequential()\n",
    "        model_rnn.add(SimpleRNN(50, activation='relu', input_shape=(8,1)))\n",
    "        model_rnn.add(Dense(10))\n",
    "        model_rnn.add(Dense(1))\n",
    "        print('\\nRunning RNN model...')\n",
    "        model_rnn.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "        hist = model_rnn.fit(self.X_train, self.y_train, epochs=7, validation_split=0.2, batch_size=100)\n",
    "        \n",
    "        train_loss, train_rmse = model_rnn.evaluate(self.X_train, self.y_train)\n",
    "        print(f'RNN Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "\n",
    "        test_loss, test_rmse = model_rnn.evaluate(self.X_test, self.y_test)\n",
    "        print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "        y_pred = model_rnn.predict(self.X_test)\n",
    "        plt.plot(range(len(y_pred)),y_pred, label='Prediction')\n",
    "        plt.plot(self.y_test, label='Actual')\n",
    "        plt.xlabel('Time Series')\n",
    "        plt.ylabel('Readings')\n",
    "        plt.title('Simple RNN MODEL')\n",
    "        plt.legend()\n",
    "        plt.savefig('Model Fig - SimpleRNN.png')\n",
    "        plt.clf()\n",
    "        model_rnn.summary()\n",
    "        self.metric_df['RNN RMSE'] = hist.history['val_root_mean_squared_error']\n",
    "\n",
    "\n",
    "\n",
    "    def lstm_model(self):\n",
    "        model_lstm = Sequential()\n",
    "        model_lstm.add(LSTM(128, activation='relu', input_shape=(8, 1),return_sequences=True))\n",
    "        model_lstm.add(Dropout(0.3))\n",
    "        model_lstm.add(LSTM(64, activation='relu'))\n",
    "        model_lstm.add(Dropout(0.3))\n",
    "        model_lstm.add(Dense(20, activation='relu'))\n",
    "        model_lstm.add(Dense(10, activation='relu'))\n",
    "        model_lstm.add(Dense(1))\n",
    "        print('\\nRunning the LSTM model...')\n",
    "        model_lstm.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "        hist = model_lstm.fit(self.X_train, self.y_train, epochs=7, validation_split=0.2, batch_size=100)\n",
    "        \n",
    "        train_loss, train_rmse = model_lstm.evaluate(self.X_train, self.y_train)\n",
    "        print(f'LSTM Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "\n",
    "        test_loss, test_rmse = model_lstm.evaluate(self.X_test, self.y_test)\n",
    "        print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "        y_pred = model_lstm.predict(self.X_test)\n",
    "        plt.plot(range(len(y_pred)),y_pred, label='Prediction')\n",
    "        plt.plot(self.y_test, label='Actual')\n",
    "        plt.xlabel('Time Series')\n",
    "        plt.ylabel('Readings')\n",
    "        plt.title('LSTM MODEL')\n",
    "        plt.legend()\n",
    "        plt.savefig('Model Fig - LSTM.png')\n",
    "        plt.clf()\n",
    "        model_lstm.summary()\n",
    "        self.metric_df['LSTM RMSE'] = hist.history['val_root_mean_squared_error']\n",
    "\n",
    "\n",
    "    def gru_model(self):\n",
    "        model_gru = Sequential()\n",
    "        model_gru.add(GRU(50, activation='relu', input_shape=(8,1)))\n",
    "        model_gru.add(Dense(1))\n",
    "        print('\\nRunning GRU model...')\n",
    "        model_gru.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "        hist = model_gru.fit(self.X_train, self.y_train, epochs=7, validation_split=0.2, batch_size=100)\n",
    "        \n",
    "        train_loss, train_rmse = model_gru.evaluate(self.X_train, self.y_train)\n",
    "        print(f'GRU Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "\n",
    "        test_loss, test_rmse = model_gru.evaluate(self.X_test, self.y_test)\n",
    "        print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "        y_pred = model_gru.predict(self.X_test)\n",
    "        plt.plot(range(len(y_pred)),y_pred, label='Prediction')\n",
    "        plt.plot(self.y_test, label='Actual')\n",
    "        plt.xlabel('Time Series')\n",
    "        plt.ylabel('Readings')\n",
    "        plt.title('GRU MODEL')\n",
    "        plt.legend()\n",
    "        plt.savefig('Model Fig - GRU.png')\n",
    "        plt.clf()\n",
    "        model_gru.summary()\n",
    "        self.metric_df['GRU RMSE'] = hist.history['val_root_mean_squared_error']\n",
    "\n",
    "\n",
    "    def cnn_lstm_model(self):\n",
    "        model_cnn_lstm = Sequential()\n",
    "        model_cnn_lstm.add(tf.keras.layers.Conv1D(32, 2, activation='relu', input_shape=(8,1)))\n",
    "        model_cnn_lstm.add(tf.keras.layers.MaxPooling1D((1)))\n",
    "        model_cnn_lstm.add(LSTM(10, activation='relu', return_sequences=True))\n",
    "        model_cnn_lstm.add(Flatten())\n",
    "        model_cnn_lstm.add(Dense(1))\n",
    "        print('\\nRunning the CNN+LSTM model...')\n",
    "        model_cnn_lstm.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "        hist = model_cnn_lstm.fit(self.X_train, self.y_train, epochs=7, validation_split=0.2, batch_size=100)\n",
    "        \n",
    "        train_loss, train_rmse = model_cnn_lstm.evaluate(self.X_train, self.y_train)\n",
    "        print(f'CNN+LSTM Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "\n",
    "        test_loss, test_rmse = model_cnn_lstm.evaluate(self.X_test, self.y_test)\n",
    "        print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "        y_pred = model_cnn_lstm.predict(self.X_test)\n",
    "        print(y_pred.shape)\n",
    "        plt.plot(range(len(y_pred)),y_pred, label='Prediction')\n",
    "        plt.plot(self.y_test, label='Actual')\n",
    "        plt.xlabel('Time Series')\n",
    "        plt.ylabel('Readings')\n",
    "        plt.title('CNN+LSTM MODEL')\n",
    "        plt.legend()\n",
    "        plt.savefig('Model Fig - CNN+LSTM.png')\n",
    "        plt.clf()\n",
    "        model_cnn_lstm.summary()\n",
    "        self.metric_df['CNN+LSTM RMSE'] = hist.history['val_root_mean_squared_error']\n",
    "\n",
    "\n",
    "    def main(self):\n",
    "        self.rnn_model()\n",
    "        self.lstm_model()\n",
    "        self.gru_model()\n",
    "        self.cnn_lstm_model()\n",
    "        self.metric_df.plot(xlabel='Epochs', ylabel='RMSE', legend=True)\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7c2045393b2e3298fba416c7980a67b423cc5ff7d51bff314d8a0df9b998066"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
