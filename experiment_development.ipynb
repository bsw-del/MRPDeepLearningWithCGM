{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bensa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from cProfile import label\n",
    "from statistics import mode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, SimpleRNN, Dropout, Flatten\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from datetime import *\n",
    "from os import *\n",
    "from dataprep import *\n",
    "#path='C:\\Users\\bensa\\OneDrive - Microsoft\\Documents\\MRPLocal\\Data'\n",
    "path= 'C:\\\\Users\\\\bensa\\\\OneDrive - Microsoft\\\\Documents\\\\MRPLocal\\\\Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next -- build out table of metrics and the runner\n",
    "Write the metrics to a CSV for storage\n",
    "Use an init for the first metric build\n",
    "\n",
    "Run a few test runs to see what else we need to record.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment Plans\n",
    "\n",
    "Build out models to compare performance on\n",
    "Look at hyperparameter tuning\n",
    "ONce models are adequately baked, then move to A and B below\n",
    "\n",
    "A Experiment on using different patients inputs and keeping track of metrics\n",
    "B Experiment on using feature engineering and build out metrics further\n",
    "\n",
    "\n",
    "Implement Data cleaning from development to the data helper functions\n",
    "Add in ability to look at a per patient basis\n",
    "Perhaps start with overall data size, and then with a % set to train v test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Record the results\n",
    "Execution_time = []\n",
    "train_rmse_results = []\n",
    "test_rmse_results=[]\n",
    "run_id = []\n",
    "sample_size=[]\n",
    "epochs = []\n",
    "batch_size=[]\n",
    "optimizer=[]\n",
    "layers=[]\n",
    "forecast_distance_perf=[]\n",
    "prev_readings=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 3s 60ms/step - loss: 22.9479 - root_mean_squared_error: 4.7904 - val_loss: 10.9236 - val_root_mean_squared_error: 3.3051\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 10.8532 - root_mean_squared_error: 3.2944 - val_loss: 12.9445 - val_root_mean_squared_error: 3.5979\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 11.2775 - root_mean_squared_error: 3.3582 - val_loss: 10.8207 - val_root_mean_squared_error: 3.2895\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 10.3978 - root_mean_squared_error: 3.2246 - val_loss: 11.4836 - val_root_mean_squared_error: 3.3887\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 10.6885 - root_mean_squared_error: 3.2693 - val_loss: 10.5516 - val_root_mean_squared_error: 3.2483\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 10.4513 - root_mean_squared_error: 3.2329 - val_loss: 10.6015 - val_root_mean_squared_error: 3.2560\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 10.3468 - root_mean_squared_error: 3.2166 - val_loss: 10.4176 - val_root_mean_squared_error: 3.2276\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 10.3119 - root_mean_squared_error: 3.2112 - val_loss: 12.9900 - val_root_mean_squared_error: 3.6042\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 9.8255 - root_mean_squared_error: 3.1346 - val_loss: 11.2354 - val_root_mean_squared_error: 3.3519\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 9.7062 - root_mean_squared_error: 3.1155 - val_loss: 10.5700 - val_root_mean_squared_error: 3.2511\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 10.2665 - root_mean_squared_error: 3.2041 - val_loss: 10.8572 - val_root_mean_squared_error: 3.2950\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 10.2314 - root_mean_squared_error: 3.1986 - val_loss: 10.8170 - val_root_mean_squared_error: 3.2889\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 9.9642 - root_mean_squared_error: 3.1566 - val_loss: 12.2918 - val_root_mean_squared_error: 3.5060\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 10.3731 - root_mean_squared_error: 3.2207 - val_loss: 11.4724 - val_root_mean_squared_error: 3.3871\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 9.9474 - root_mean_squared_error: 3.1539 - val_loss: 10.7521 - val_root_mean_squared_error: 3.2790\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 9.9327 - root_mean_squared_error: 3.1516 - val_loss: 11.2144 - val_root_mean_squared_error: 3.3488\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 9.7875 - root_mean_squared_error: 3.1285 - val_loss: 10.6339 - val_root_mean_squared_error: 3.2610\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 3s 85ms/step - loss: 9.6933 - root_mean_squared_error: 3.1134 - val_loss: 10.2521 - val_root_mean_squared_error: 3.2019\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 9.5062 - root_mean_squared_error: 3.0832 - val_loss: 10.3465 - val_root_mean_squared_error: 3.2166\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 9.5327 - root_mean_squared_error: 3.0875 - val_loss: 11.1818 - val_root_mean_squared_error: 3.3439\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 9.4403 - root_mean_squared_error: 3.0725 - val_loss: 10.2765 - val_root_mean_squared_error: 3.2057\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 9.5903 - root_mean_squared_error: 3.0968 - val_loss: 10.2506 - val_root_mean_squared_error: 3.2017\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 9.4687 - root_mean_squared_error: 3.0771 - val_loss: 11.0014 - val_root_mean_squared_error: 3.3168\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 9.9142 - root_mean_squared_error: 3.1487 - val_loss: 10.4491 - val_root_mean_squared_error: 3.2325\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 9.7275 - root_mean_squared_error: 3.1189 - val_loss: 10.3135 - val_root_mean_squared_error: 3.2115\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 9.8629 - root_mean_squared_error: 3.1405 - val_loss: 12.1642 - val_root_mean_squared_error: 3.4877\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 9.5575 - root_mean_squared_error: 3.0915 - val_loss: 10.4888 - val_root_mean_squared_error: 3.2386\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 9.6630 - root_mean_squared_error: 3.1085 - val_loss: 11.8751 - val_root_mean_squared_error: 3.4460\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 9.8061 - root_mean_squared_error: 3.1315 - val_loss: 11.7599 - val_root_mean_squared_error: 3.4293\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 9.6293 - root_mean_squared_error: 3.1031 - val_loss: 10.4933 - val_root_mean_squared_error: 3.2393\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 9.4588 - root_mean_squared_error: 3.0755\n",
      "\n",
      "training time 56.309241\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 9.458761215209961 with RMSE metric of 3.075510025024414\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.7762 - root_mean_squared_error: 2.7886\n",
      "Test set has a loss (MSE) of 7.776162624359131 with RMSE metric of 2.788577079772949\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "46/46 [==============================] - 4s 73ms/step - loss: 13.6453 - root_mean_squared_error: 3.6940 - val_loss: 9.1592 - val_root_mean_squared_error: 3.0264\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 9.3606 - root_mean_squared_error: 3.0595 - val_loss: 8.5330 - val_root_mean_squared_error: 2.9211\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 9.3460 - root_mean_squared_error: 3.0571 - val_loss: 8.9016 - val_root_mean_squared_error: 2.9836\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 9.0534 - root_mean_squared_error: 3.0089 - val_loss: 8.6207 - val_root_mean_squared_error: 2.9361\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 9.7426 - root_mean_squared_error: 3.1213 - val_loss: 8.6495 - val_root_mean_squared_error: 2.9410\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 9.3737 - root_mean_squared_error: 3.0616 - val_loss: 9.1122 - val_root_mean_squared_error: 3.0186\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 8.9322 - root_mean_squared_error: 2.9887 - val_loss: 8.8491 - val_root_mean_squared_error: 2.9747\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 8.9778 - root_mean_squared_error: 2.9963 - val_loss: 8.9699 - val_root_mean_squared_error: 2.9950\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 9.1135 - root_mean_squared_error: 3.0189 - val_loss: 8.5847 - val_root_mean_squared_error: 2.9300\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 9.1074 - root_mean_squared_error: 3.0178 - val_loss: 8.6440 - val_root_mean_squared_error: 2.9401\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 8.8798 - root_mean_squared_error: 2.9799 - val_loss: 9.0612 - val_root_mean_squared_error: 3.0102\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 9.1001 - root_mean_squared_error: 3.0166 - val_loss: 9.3342 - val_root_mean_squared_error: 3.0552\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 9.0118 - root_mean_squared_error: 3.0020 - val_loss: 8.5144 - val_root_mean_squared_error: 2.9179\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 4s 81ms/step - loss: 8.9342 - root_mean_squared_error: 2.9890 - val_loss: 8.2988 - val_root_mean_squared_error: 2.8808\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 8.9554 - root_mean_squared_error: 2.9926 - val_loss: 8.9523 - val_root_mean_squared_error: 2.9920\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 4s 80ms/step - loss: 8.8566 - root_mean_squared_error: 2.9760 - val_loss: 8.3540 - val_root_mean_squared_error: 2.8903\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 8.8993 - root_mean_squared_error: 2.9832 - val_loss: 8.4583 - val_root_mean_squared_error: 2.9083\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 8.9697 - root_mean_squared_error: 2.9949 - val_loss: 8.2432 - val_root_mean_squared_error: 2.8711\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 4s 78ms/step - loss: 8.7963 - root_mean_squared_error: 2.9659 - val_loss: 8.9464 - val_root_mean_squared_error: 2.9910\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 8.9039 - root_mean_squared_error: 2.9839 - val_loss: 9.4477 - val_root_mean_squared_error: 3.0737\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 8.8423 - root_mean_squared_error: 2.9736 - val_loss: 8.5280 - val_root_mean_squared_error: 2.9203\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 8.8310 - root_mean_squared_error: 2.9717 - val_loss: 8.8667 - val_root_mean_squared_error: 2.9777\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 8.8409 - root_mean_squared_error: 2.9734 - val_loss: 9.2946 - val_root_mean_squared_error: 3.0487\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 8.9650 - root_mean_squared_error: 2.9942 - val_loss: 8.4803 - val_root_mean_squared_error: 2.9121\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - 4s 92ms/step - loss: 8.7692 - root_mean_squared_error: 2.9613 - val_loss: 8.4718 - val_root_mean_squared_error: 2.9106\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - 5s 103ms/step - loss: 8.7113 - root_mean_squared_error: 2.9515 - val_loss: 8.5603 - val_root_mean_squared_error: 2.9258\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - 4s 84ms/step - loss: 8.7878 - root_mean_squared_error: 2.9644 - val_loss: 8.5465 - val_root_mean_squared_error: 2.9234\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - 4s 91ms/step - loss: 8.8860 - root_mean_squared_error: 2.9809 - val_loss: 8.5683 - val_root_mean_squared_error: 2.9272\n",
      "Epoch 29/30\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 8.6486 - root_mean_squared_error: 2.9409 - val_loss: 8.5434 - val_root_mean_squared_error: 2.9229\n",
      "Epoch 30/30\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 8.7696 - root_mean_squared_error: 2.9614 - val_loss: 8.4298 - val_root_mean_squared_error: 2.9034\n",
      "409/409 [==============================] - 3s 7ms/step - loss: 8.4146 - root_mean_squared_error: 2.9008\n",
      "\n",
      "training time 99.650129\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 8.414619445800781 with RMSE metric of 2.900796413421631\n",
      "113/113 [==============================] - 0s 4ms/step - loss: 9.2854 - root_mean_squared_error: 3.0472\n",
      "Test set has a loss (MSE) of 9.285355567932129 with RMSE metric of 3.0471880435943604\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "51/51 [==============================] - 5s 79ms/step - loss: 15.9494 - root_mean_squared_error: 3.9937 - val_loss: 9.9407 - val_root_mean_squared_error: 3.1529\n",
      "Epoch 2/30\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 11.8711 - root_mean_squared_error: 3.4454 - val_loss: 11.7482 - val_root_mean_squared_error: 3.4276\n",
      "Epoch 3/30\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 11.4239 - root_mean_squared_error: 3.3799 - val_loss: 10.1065 - val_root_mean_squared_error: 3.1791\n",
      "Epoch 4/30\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 11.0385 - root_mean_squared_error: 3.3224 - val_loss: 9.8613 - val_root_mean_squared_error: 3.1403\n",
      "Epoch 5/30\n",
      "51/51 [==============================] - 6s 122ms/step - loss: 11.0469 - root_mean_squared_error: 3.3237 - val_loss: 9.8214 - val_root_mean_squared_error: 3.1339\n",
      "Epoch 6/30\n",
      "51/51 [==============================] - 6s 113ms/step - loss: 10.9073 - root_mean_squared_error: 3.3026 - val_loss: 9.4790 - val_root_mean_squared_error: 3.0788\n",
      "Epoch 7/30\n",
      "51/51 [==============================] - 7s 140ms/step - loss: 10.6271 - root_mean_squared_error: 3.2599 - val_loss: 9.7278 - val_root_mean_squared_error: 3.1189\n",
      "Epoch 8/30\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 10.6938 - root_mean_squared_error: 3.2701 - val_loss: 11.0910 - val_root_mean_squared_error: 3.3303\n",
      "Epoch 9/30\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 10.6492 - root_mean_squared_error: 3.2633 - val_loss: 11.8350 - val_root_mean_squared_error: 3.4402\n",
      "Epoch 10/30\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 10.9266 - root_mean_squared_error: 3.3055 - val_loss: 9.9093 - val_root_mean_squared_error: 3.1479\n",
      "Epoch 11/30\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 10.7487 - root_mean_squared_error: 3.2785 - val_loss: 9.7650 - val_root_mean_squared_error: 3.1249\n",
      "Epoch 12/30\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 10.5948 - root_mean_squared_error: 3.2550 - val_loss: 9.8028 - val_root_mean_squared_error: 3.1309\n",
      "Epoch 13/30\n",
      "51/51 [==============================] - 6s 115ms/step - loss: 10.6279 - root_mean_squared_error: 3.2600 - val_loss: 10.7685 - val_root_mean_squared_error: 3.2815\n",
      "Epoch 14/30\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 10.7520 - root_mean_squared_error: 3.2790 - val_loss: 9.8357 - val_root_mean_squared_error: 3.1362\n",
      "Epoch 15/30\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 10.6732 - root_mean_squared_error: 3.2670 - val_loss: 9.6876 - val_root_mean_squared_error: 3.1125\n",
      "Epoch 16/30\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 10.4529 - root_mean_squared_error: 3.2331 - val_loss: 10.1306 - val_root_mean_squared_error: 3.1829\n",
      "Epoch 17/30\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 10.5845 - root_mean_squared_error: 3.2534 - val_loss: 10.1071 - val_root_mean_squared_error: 3.1792\n",
      "Epoch 18/30\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 10.5179 - root_mean_squared_error: 3.2431 - val_loss: 9.7638 - val_root_mean_squared_error: 3.1247\n",
      "Epoch 19/30\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 10.7092 - root_mean_squared_error: 3.2725 - val_loss: 9.8142 - val_root_mean_squared_error: 3.1328\n",
      "Epoch 20/30\n",
      "51/51 [==============================] - 4s 89ms/step - loss: 10.5859 - root_mean_squared_error: 3.2536 - val_loss: 9.5249 - val_root_mean_squared_error: 3.0862\n",
      "Epoch 21/30\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 10.7968 - root_mean_squared_error: 3.2859 - val_loss: 11.0973 - val_root_mean_squared_error: 3.3313\n",
      "Epoch 22/30\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 10.7669 - root_mean_squared_error: 3.2813 - val_loss: 9.3231 - val_root_mean_squared_error: 3.0534\n",
      "Epoch 23/30\n",
      "51/51 [==============================] - 5s 105ms/step - loss: 10.8840 - root_mean_squared_error: 3.2991 - val_loss: 9.7487 - val_root_mean_squared_error: 3.1223\n",
      "Epoch 24/30\n",
      "51/51 [==============================] - 5s 104ms/step - loss: 10.5665 - root_mean_squared_error: 3.2506 - val_loss: 9.6505 - val_root_mean_squared_error: 3.1065\n",
      "Epoch 25/30\n",
      "51/51 [==============================] - 6s 121ms/step - loss: 10.4791 - root_mean_squared_error: 3.2371 - val_loss: 9.7344 - val_root_mean_squared_error: 3.1200\n",
      "Epoch 26/30\n",
      "51/51 [==============================] - 7s 143ms/step - loss: 10.7777 - root_mean_squared_error: 3.2829 - val_loss: 9.8333 - val_root_mean_squared_error: 3.1358\n",
      "Epoch 27/30\n",
      "51/51 [==============================] - 6s 117ms/step - loss: 11.0517 - root_mean_squared_error: 3.3244 - val_loss: 10.6669 - val_root_mean_squared_error: 3.2660\n",
      "Epoch 28/30\n",
      "51/51 [==============================] - 6s 112ms/step - loss: 10.6879 - root_mean_squared_error: 3.2692 - val_loss: 9.5485 - val_root_mean_squared_error: 3.0901\n",
      "Epoch 29/30\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 10.5375 - root_mean_squared_error: 3.2462 - val_loss: 9.7478 - val_root_mean_squared_error: 3.1222\n",
      "Epoch 30/30\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 10.6639 - root_mean_squared_error: 3.2656 - val_loss: 9.6081 - val_root_mean_squared_error: 3.0997\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 9.9202 - root_mean_squared_error: 3.1496\n",
      "\n",
      "training time 154.134169\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 9.920234680175781 with RMSE metric of 3.1496403217315674\n",
      "187/187 [==============================] - 1s 8ms/step - loss: 11.8158 - root_mean_squared_error: 3.4374\n",
      "Test set has a loss (MSE) of 11.815764427185059 with RMSE metric of 3.437406539916992\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "66/66 [==============================] - 8s 100ms/step - loss: 8.5859 - root_mean_squared_error: 2.9302 - val_loss: 6.0916 - val_root_mean_squared_error: 2.4681\n",
      "Epoch 2/30\n",
      "66/66 [==============================] - 5s 78ms/step - loss: 6.1828 - root_mean_squared_error: 2.4865 - val_loss: 5.3931 - val_root_mean_squared_error: 2.3223\n",
      "Epoch 3/30\n",
      "66/66 [==============================] - 5s 70ms/step - loss: 5.9388 - root_mean_squared_error: 2.4370 - val_loss: 5.4281 - val_root_mean_squared_error: 2.3298\n",
      "Epoch 4/30\n",
      "66/66 [==============================] - 5s 73ms/step - loss: 5.9722 - root_mean_squared_error: 2.4438 - val_loss: 5.3350 - val_root_mean_squared_error: 2.3098\n",
      "Epoch 5/30\n",
      "66/66 [==============================] - 4s 65ms/step - loss: 5.8269 - root_mean_squared_error: 2.4139 - val_loss: 5.7068 - val_root_mean_squared_error: 2.3889\n",
      "Epoch 6/30\n",
      "66/66 [==============================] - 5s 71ms/step - loss: 5.7868 - root_mean_squared_error: 2.4056 - val_loss: 5.3997 - val_root_mean_squared_error: 2.3237\n",
      "Epoch 7/30\n",
      "66/66 [==============================] - 5s 73ms/step - loss: 5.7590 - root_mean_squared_error: 2.3998 - val_loss: 5.4082 - val_root_mean_squared_error: 2.3256\n",
      "Epoch 8/30\n",
      "66/66 [==============================] - 5s 69ms/step - loss: 5.9528 - root_mean_squared_error: 2.4398 - val_loss: 5.9901 - val_root_mean_squared_error: 2.4475\n",
      "Epoch 9/30\n",
      "66/66 [==============================] - 4s 69ms/step - loss: 5.8412 - root_mean_squared_error: 2.4169 - val_loss: 5.3051 - val_root_mean_squared_error: 2.3033\n",
      "Epoch 10/30\n",
      "66/66 [==============================] - 5s 69ms/step - loss: 5.7302 - root_mean_squared_error: 2.3938 - val_loss: 5.3939 - val_root_mean_squared_error: 2.3225\n",
      "Epoch 11/30\n",
      "66/66 [==============================] - 5s 72ms/step - loss: 5.7493 - root_mean_squared_error: 2.3978 - val_loss: 5.6002 - val_root_mean_squared_error: 2.3665\n",
      "Epoch 12/30\n",
      "66/66 [==============================] - 5s 70ms/step - loss: 5.7398 - root_mean_squared_error: 2.3958 - val_loss: 5.5529 - val_root_mean_squared_error: 2.3565\n",
      "Epoch 13/30\n",
      "66/66 [==============================] - 4s 66ms/step - loss: 5.6606 - root_mean_squared_error: 2.3792 - val_loss: 5.3791 - val_root_mean_squared_error: 2.3193\n",
      "Epoch 14/30\n",
      "66/66 [==============================] - 5s 72ms/step - loss: 5.7297 - root_mean_squared_error: 2.3937 - val_loss: 5.3021 - val_root_mean_squared_error: 2.3026\n",
      "Epoch 15/30\n",
      "66/66 [==============================] - 5s 69ms/step - loss: 5.7469 - root_mean_squared_error: 2.3973 - val_loss: 5.6204 - val_root_mean_squared_error: 2.3707\n",
      "Epoch 16/30\n",
      "66/66 [==============================] - 4s 67ms/step - loss: 5.7470 - root_mean_squared_error: 2.3973 - val_loss: 5.3968 - val_root_mean_squared_error: 2.3231\n",
      "Epoch 17/30\n",
      "66/66 [==============================] - 4s 67ms/step - loss: 5.6175 - root_mean_squared_error: 2.3701 - val_loss: 5.5706 - val_root_mean_squared_error: 2.3602\n",
      "Epoch 18/30\n",
      "66/66 [==============================] - 4s 68ms/step - loss: 5.9298 - root_mean_squared_error: 2.4351 - val_loss: 5.7376 - val_root_mean_squared_error: 2.3953\n",
      "Epoch 19/30\n",
      "66/66 [==============================] - 4s 67ms/step - loss: 5.5712 - root_mean_squared_error: 2.3603 - val_loss: 5.3426 - val_root_mean_squared_error: 2.3114\n",
      "Epoch 20/30\n",
      "66/66 [==============================] - 5s 71ms/step - loss: 5.7172 - root_mean_squared_error: 2.3911 - val_loss: 5.8108 - val_root_mean_squared_error: 2.4106\n",
      "Epoch 21/30\n",
      "66/66 [==============================] - 4s 66ms/step - loss: 5.7362 - root_mean_squared_error: 2.3950 - val_loss: 5.6320 - val_root_mean_squared_error: 2.3732\n",
      "Epoch 22/30\n",
      "66/66 [==============================] - 5s 69ms/step - loss: 5.9211 - root_mean_squared_error: 2.4333 - val_loss: 5.3746 - val_root_mean_squared_error: 2.3183\n",
      "Epoch 23/30\n",
      "66/66 [==============================] - 4s 68ms/step - loss: 5.6439 - root_mean_squared_error: 2.3757 - val_loss: 5.3056 - val_root_mean_squared_error: 2.3034\n",
      "Epoch 24/30\n",
      "66/66 [==============================] - 4s 68ms/step - loss: 5.6958 - root_mean_squared_error: 2.3866 - val_loss: 5.2513 - val_root_mean_squared_error: 2.2916\n",
      "Epoch 25/30\n",
      "66/66 [==============================] - 5s 73ms/step - loss: 5.5822 - root_mean_squared_error: 2.3627 - val_loss: 5.2291 - val_root_mean_squared_error: 2.2867\n",
      "Epoch 26/30\n",
      "66/66 [==============================] - 5s 69ms/step - loss: 5.6385 - root_mean_squared_error: 2.3745 - val_loss: 5.3857 - val_root_mean_squared_error: 2.3207\n",
      "Epoch 27/30\n",
      "66/66 [==============================] - 4s 67ms/step - loss: 5.6875 - root_mean_squared_error: 2.3849 - val_loss: 5.6843 - val_root_mean_squared_error: 2.3842\n",
      "Epoch 28/30\n",
      "66/66 [==============================] - 4s 66ms/step - loss: 5.6463 - root_mean_squared_error: 2.3762 - val_loss: 5.3892 - val_root_mean_squared_error: 2.3215\n",
      "Epoch 29/30\n",
      "66/66 [==============================] - 4s 67ms/step - loss: 5.7815 - root_mean_squared_error: 2.4045 - val_loss: 5.5151 - val_root_mean_squared_error: 2.3484\n",
      "Epoch 30/30\n",
      "66/66 [==============================] - 4s 67ms/step - loss: 5.8375 - root_mean_squared_error: 2.4161 - val_loss: 5.3334 - val_root_mean_squared_error: 2.3094\n",
      "588/588 [==============================] - 2s 4ms/step - loss: 5.3057 - root_mean_squared_error: 2.3034\n",
      "\n",
      "training time 142.02455\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 5.305667400360107 with RMSE metric of 2.303403377532959\n",
      "259/259 [==============================] - 1s 4ms/step - loss: 5.7868 - root_mean_squared_error: 2.4056\n",
      "Test set has a loss (MSE) of 5.786800384521484 with RMSE metric of 2.4055769443511963\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 3s 62ms/step - loss: 11.4424 - root_mean_squared_error: 3.3827 - val_loss: 7.0331 - val_root_mean_squared_error: 2.6520\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 6.4651 - root_mean_squared_error: 2.5427 - val_loss: 6.7243 - val_root_mean_squared_error: 2.5931\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 6.1754 - root_mean_squared_error: 2.4850 - val_loss: 7.2708 - val_root_mean_squared_error: 2.6964\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 6.1167 - root_mean_squared_error: 2.4732 - val_loss: 6.5271 - val_root_mean_squared_error: 2.5548\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 6.1424 - root_mean_squared_error: 2.4784 - val_loss: 7.2379 - val_root_mean_squared_error: 2.6903\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 2s 65ms/step - loss: 5.8493 - root_mean_squared_error: 2.4185 - val_loss: 6.4879 - val_root_mean_squared_error: 2.5471\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 2s 70ms/step - loss: 6.0226 - root_mean_squared_error: 2.4541 - val_loss: 10.2122 - val_root_mean_squared_error: 3.1957\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 2s 67ms/step - loss: 6.4587 - root_mean_squared_error: 2.5414 - val_loss: 6.5317 - val_root_mean_squared_error: 2.5557\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 2s 69ms/step - loss: 5.7423 - root_mean_squared_error: 2.3963 - val_loss: 6.5479 - val_root_mean_squared_error: 2.5589\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 5.8909 - root_mean_squared_error: 2.4271 - val_loss: 6.5716 - val_root_mean_squared_error: 2.5635\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 5.5676 - root_mean_squared_error: 2.3596 - val_loss: 6.5072 - val_root_mean_squared_error: 2.5509\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 5.7386 - root_mean_squared_error: 2.3955 - val_loss: 7.1299 - val_root_mean_squared_error: 2.6702\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 5.6463 - root_mean_squared_error: 2.3762 - val_loss: 7.0566 - val_root_mean_squared_error: 2.6564\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 2s 64ms/step - loss: 5.9889 - root_mean_squared_error: 2.4472 - val_loss: 6.4180 - val_root_mean_squared_error: 2.5334\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 5.5020 - root_mean_squared_error: 2.3456 - val_loss: 6.4935 - val_root_mean_squared_error: 2.5482\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 2s 65ms/step - loss: 5.5230 - root_mean_squared_error: 2.3501 - val_loss: 6.7114 - val_root_mean_squared_error: 2.5906\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 5.5960 - root_mean_squared_error: 2.3656 - val_loss: 6.7065 - val_root_mean_squared_error: 2.5897\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 6.1114 - root_mean_squared_error: 2.4721 - val_loss: 6.5397 - val_root_mean_squared_error: 2.5573\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 2s 63ms/step - loss: 5.4467 - root_mean_squared_error: 2.3338 - val_loss: 6.1972 - val_root_mean_squared_error: 2.4894\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 5.3295 - root_mean_squared_error: 2.3086 - val_loss: 6.4401 - val_root_mean_squared_error: 2.5377\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 5.6685 - root_mean_squared_error: 2.3809 - val_loss: 6.3553 - val_root_mean_squared_error: 2.5210\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 5.3408 - root_mean_squared_error: 2.3110 - val_loss: 6.1884 - val_root_mean_squared_error: 2.4877\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 5.4812 - root_mean_squared_error: 2.3412 - val_loss: 6.4348 - val_root_mean_squared_error: 2.5367\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 2s 67ms/step - loss: 5.6123 - root_mean_squared_error: 2.3690 - val_loss: 7.1254 - val_root_mean_squared_error: 2.6693\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 6.0761 - root_mean_squared_error: 2.4650 - val_loss: 6.2943 - val_root_mean_squared_error: 2.5088\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 5.4589 - root_mean_squared_error: 2.3364 - val_loss: 6.3378 - val_root_mean_squared_error: 2.5175\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 5.4107 - root_mean_squared_error: 2.3261 - val_loss: 8.4101 - val_root_mean_squared_error: 2.9000\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 5.9709 - root_mean_squared_error: 2.4435 - val_loss: 6.5209 - val_root_mean_squared_error: 2.5536\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 2s 64ms/step - loss: 5.4647 - root_mean_squared_error: 2.3377 - val_loss: 6.5016 - val_root_mean_squared_error: 2.5498\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 5.5193 - root_mean_squared_error: 2.3493 - val_loss: 6.4751 - val_root_mean_squared_error: 2.5446\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 5.5680 - root_mean_squared_error: 2.3597\n",
      "\n",
      "training time 61.432781\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 5.567978382110596 with RMSE metric of 2.35965633392334\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5893 - root_mean_squared_error: 2.3642\n",
      "Test set has a loss (MSE) of 5.589293479919434 with RMSE metric of 2.364168643951416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (5):\n",
    "    ## Simple RNN Model\n",
    "    ## Initialize\n",
    "    model_name = 'SimpleRNN optimized - 60 mins'\n",
    "    num_layers = 3\n",
    "    epochs_num = 30\n",
    "    batch_size_set = 200\n",
    "    optimizer_set = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    forecast_distance=12\n",
    "    number_readings=8\n",
    "\n",
    "    ## Get New Data\n",
    "    a=DataSampling(path=path)\n",
    "    a.samplingDF\n",
    "    X_train,X_test,y_train,y_test = a.SampleValidSequences(num_clients=3, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "\n",
    "    #SETUP THE STACK\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(SimpleRNN(150, activation='tanh', input_shape=(number_readings,1)))\n",
    "    model_rnn.add(Dropout(0.1))\n",
    "    model_rnn.add(Dense(10))\n",
    "    model_rnn.add(Dense(1))\n",
    "    #START THE RUN\n",
    "    print('\\nRunning RNN model...')\n",
    "    start = datetime.now()\n",
    "\n",
    "    model_rnn.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    hist = model_rnn.fit(X_train, y_train, epochs=epochs_num, validation_split=0.3, batch_size=batch_size_set)\n",
    "    train_loss, train_rmse = model_rnn.evaluate(X_train, y_train)\n",
    "    train_time = (datetime.now()-start).total_seconds()\n",
    "    print(\"\\ntraining time %s\" % train_time)\n",
    "\n",
    "    #PRINT RESULTS\n",
    "    print(f'RNN Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "    #Test set results\n",
    "    test_loss, test_rmse = model_rnn.evaluate(X_test, y_test)\n",
    "    print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "\n",
    "    #y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "    Execution_time.append(train_time)\n",
    "    train_rmse_results.append(train_rmse)\n",
    "    test_rmse_results.append(test_rmse)\n",
    "    run_id.append(model_name+str(datetime.now()))\n",
    "    sample_size.append(len(X_train))\n",
    "    epochs.append(epochs_num)\n",
    "    batch_size.append(batch_size_set)\n",
    "    optimizer.append(optimizer_set)\n",
    "    layers.append(num_layers)\n",
    "    forecast_distance_perf.append(forecast_distance)\n",
    "    prev_readings.append(number_readings)\n",
    "\n",
    "## determine why this is pushing out lists instead of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running LSTM model...\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 4s 96ms/step - loss: 42.9958 - root_mean_squared_error: 6.5571 - val_loss: 29.9209 - val_root_mean_squared_error: 5.4700\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 14.4209 - root_mean_squared_error: 3.7975 - val_loss: 12.4249 - val_root_mean_squared_error: 3.5249\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 9.3560 - root_mean_squared_error: 3.0588 - val_loss: 16.2381 - val_root_mean_squared_error: 4.0297\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 8.2417 - root_mean_squared_error: 2.8708 - val_loss: 9.3973 - val_root_mean_squared_error: 3.0655\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 7.3981 - root_mean_squared_error: 2.7200 - val_loss: 9.3159 - val_root_mean_squared_error: 3.0522\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 6.7376 - root_mean_squared_error: 2.5957 - val_loss: 8.7871 - val_root_mean_squared_error: 2.9643\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 6.3326 - root_mean_squared_error: 2.5165 - val_loss: 7.6956 - val_root_mean_squared_error: 2.7741\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 5.5694 - root_mean_squared_error: 2.3600 - val_loss: 6.3314 - val_root_mean_squared_error: 2.5162\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 5.5220 - root_mean_squared_error: 2.3499 - val_loss: 6.2760 - val_root_mean_squared_error: 2.5052\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 5.1472 - root_mean_squared_error: 2.2688 - val_loss: 5.8425 - val_root_mean_squared_error: 2.4171\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 4.7295 - root_mean_squared_error: 2.1747 - val_loss: 5.6525 - val_root_mean_squared_error: 2.3775\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 4.8396 - root_mean_squared_error: 2.1999 - val_loss: 5.7000 - val_root_mean_squared_error: 2.3875\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 4.7664 - root_mean_squared_error: 2.1832 - val_loss: 6.5858 - val_root_mean_squared_error: 2.5663\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 4.5999 - root_mean_squared_error: 2.1447 - val_loss: 5.6242 - val_root_mean_squared_error: 2.3715\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 4.3275 - root_mean_squared_error: 2.0803 - val_loss: 6.8561 - val_root_mean_squared_error: 2.6184\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 4.5184 - root_mean_squared_error: 2.1257 - val_loss: 5.5807 - val_root_mean_squared_error: 2.3624\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 4.3674 - root_mean_squared_error: 2.0898 - val_loss: 5.9502 - val_root_mean_squared_error: 2.4393\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 4.6133 - root_mean_squared_error: 2.1479 - val_loss: 5.3939 - val_root_mean_squared_error: 2.3225\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 4.3385 - root_mean_squared_error: 2.0829 - val_loss: 6.6694 - val_root_mean_squared_error: 2.5825\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 4.3450 - root_mean_squared_error: 2.0845 - val_loss: 5.3073 - val_root_mean_squared_error: 2.3038\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 3.8971 - root_mean_squared_error: 1.9741\n",
      "\n",
      "training time 13.531632\n",
      "LSTM Model: \n",
      "Training set has a loss (MSE) of 3.8970932960510254 with RMSE metric of 1.974105715751648\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 2.9502 - root_mean_squared_error: 1.7176\n",
      "Test set has a loss (MSE) of 2.9502344131469727 with RMSE metric of 1.7176246643066406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## LSTM Model\n",
    "## Initialize\n",
    "model_name = 'LSTM - Personal'\n",
    "num_layers = 4\n",
    "epochs_num = 20\n",
    "batch_size_set = 100\n",
    "optimizer_set = 'adam'\n",
    "forecast_distance=6\n",
    "number_readings=8\n",
    "\n",
    "## Get New Data\n",
    "a=DataSampling(path=path)\n",
    "a.samplingDF\n",
    "X_train,X_test,y_train,y_test = a.SampleValidSequences(num_clients=1, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "\n",
    "#SETUP THE STACK\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(150, activation='relu', input_shape=(number_readings, 1),return_sequences=True))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(LSTM(64, activation='relu'))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(10, activation='relu'))\n",
    "model_lstm.add(Dense(1))\n",
    "\n",
    "#START THE RUN\n",
    "print('\\nRunning LSTM model...')\n",
    "start = datetime.now()\n",
    "\n",
    "model_lstm.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "hist = model_lstm.fit(X_train, y_train, epochs=epochs_num, validation_split=0.2, batch_size=batch_size_set)\n",
    "train_loss, train_rmse = model_lstm.evaluate(X_train, y_train)\n",
    "train_time = (datetime.now()-start).total_seconds()\n",
    "print(\"\\ntraining time %s\" % train_time)\n",
    "\n",
    "#PRINT RESULTS\n",
    "print(f'LSTM Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "#Test set results\n",
    "test_loss, test_rmse = model_lstm.evaluate(X_test, y_test)\n",
    "print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "\n",
    "#y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "Execution_time.append(train_time)\n",
    "train_rmse_results.append(train_rmse)\n",
    "test_rmse_results.append(test_rmse)\n",
    "run_id.append(model_name+str(datetime.now()))\n",
    "sample_size.append(len(X_train))\n",
    "epochs.append(epochs_num)\n",
    "batch_size.append(batch_size_set)\n",
    "optimizer.append(optimizer_set)\n",
    "layers.append(num_layers)\n",
    "forecast_distance_perf.append(forecast_distance)\n",
    "prev_readings.append(number_readings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "85/85 [==============================] - 9s 64ms/step - loss: 22.0825 - root_mean_squared_error: 4.6992 - val_loss: 9.3619 - val_root_mean_squared_error: 3.0597\n",
      "Epoch 2/30\n",
      "85/85 [==============================] - 6s 68ms/step - loss: 9.3198 - root_mean_squared_error: 3.0528 - val_loss: 8.1609 - val_root_mean_squared_error: 2.8567\n",
      "Epoch 3/30\n",
      "85/85 [==============================] - 6s 70ms/step - loss: 8.5053 - root_mean_squared_error: 2.9164 - val_loss: 8.0947 - val_root_mean_squared_error: 2.8451\n",
      "Epoch 4/30\n",
      "85/85 [==============================] - 6s 67ms/step - loss: 8.3166 - root_mean_squared_error: 2.8839 - val_loss: 8.7368 - val_root_mean_squared_error: 2.9558\n",
      "Epoch 5/30\n",
      "85/85 [==============================] - 6s 68ms/step - loss: 8.5626 - root_mean_squared_error: 2.9262 - val_loss: 9.0858 - val_root_mean_squared_error: 3.0143\n",
      "Epoch 6/30\n",
      "85/85 [==============================] - 5s 63ms/step - loss: 8.1578 - root_mean_squared_error: 2.8562 - val_loss: 8.1945 - val_root_mean_squared_error: 2.8626\n",
      "Epoch 7/30\n",
      "85/85 [==============================] - 6s 67ms/step - loss: 8.1776 - root_mean_squared_error: 2.8597 - val_loss: 9.7516 - val_root_mean_squared_error: 3.1228\n",
      "Epoch 8/30\n",
      "85/85 [==============================] - 5s 64ms/step - loss: 8.0537 - root_mean_squared_error: 2.8379 - val_loss: 8.3780 - val_root_mean_squared_error: 2.8945\n",
      "Epoch 9/30\n",
      "85/85 [==============================] - 5s 64ms/step - loss: 8.2103 - root_mean_squared_error: 2.8654 - val_loss: 8.5202 - val_root_mean_squared_error: 2.9189\n",
      "Epoch 10/30\n",
      "85/85 [==============================] - 6s 68ms/step - loss: 8.1309 - root_mean_squared_error: 2.8515 - val_loss: 8.0618 - val_root_mean_squared_error: 2.8393\n",
      "Epoch 11/30\n",
      "85/85 [==============================] - 5s 64ms/step - loss: 8.0492 - root_mean_squared_error: 2.8371 - val_loss: 8.2973 - val_root_mean_squared_error: 2.8805\n",
      "Epoch 12/30\n",
      "85/85 [==============================] - 6s 67ms/step - loss: 7.9989 - root_mean_squared_error: 2.8282 - val_loss: 8.1333 - val_root_mean_squared_error: 2.8519\n",
      "Epoch 13/30\n",
      "85/85 [==============================] - 6s 68ms/step - loss: 8.0114 - root_mean_squared_error: 2.8304 - val_loss: 8.2317 - val_root_mean_squared_error: 2.8691\n",
      "Epoch 14/30\n",
      "85/85 [==============================] - 5s 64ms/step - loss: 7.9978 - root_mean_squared_error: 2.8280 - val_loss: 8.2155 - val_root_mean_squared_error: 2.8663\n",
      "Epoch 15/30\n",
      "85/85 [==============================] - 6s 65ms/step - loss: 7.9109 - root_mean_squared_error: 2.8126 - val_loss: 8.1321 - val_root_mean_squared_error: 2.8517\n",
      "Epoch 16/30\n",
      "85/85 [==============================] - 5s 64ms/step - loss: 7.9556 - root_mean_squared_error: 2.8206 - val_loss: 8.2004 - val_root_mean_squared_error: 2.8636\n",
      "Epoch 17/30\n",
      "85/85 [==============================] - 5s 65ms/step - loss: 7.9974 - root_mean_squared_error: 2.8280 - val_loss: 8.1086 - val_root_mean_squared_error: 2.8476\n",
      "Epoch 18/30\n",
      "85/85 [==============================] - 6s 65ms/step - loss: 7.9257 - root_mean_squared_error: 2.8153 - val_loss: 8.5764 - val_root_mean_squared_error: 2.9285\n",
      "Epoch 19/30\n",
      "85/85 [==============================] - 5s 63ms/step - loss: 7.9503 - root_mean_squared_error: 2.8196 - val_loss: 8.1485 - val_root_mean_squared_error: 2.8546\n",
      "Epoch 20/30\n",
      "85/85 [==============================] - 5s 64ms/step - loss: 8.0067 - root_mean_squared_error: 2.8296 - val_loss: 8.7876 - val_root_mean_squared_error: 2.9644\n",
      "Epoch 21/30\n",
      "85/85 [==============================] - 6s 70ms/step - loss: 7.9500 - root_mean_squared_error: 2.8196 - val_loss: 8.0444 - val_root_mean_squared_error: 2.8363\n",
      "Epoch 22/30\n",
      "85/85 [==============================] - 6s 65ms/step - loss: 7.9797 - root_mean_squared_error: 2.8248 - val_loss: 8.0202 - val_root_mean_squared_error: 2.8320\n",
      "Epoch 23/30\n",
      "85/85 [==============================] - 6s 65ms/step - loss: 7.9283 - root_mean_squared_error: 2.8157 - val_loss: 8.3211 - val_root_mean_squared_error: 2.8846\n",
      "Epoch 24/30\n",
      "85/85 [==============================] - 6s 73ms/step - loss: 7.9482 - root_mean_squared_error: 2.8193 - val_loss: 8.4682 - val_root_mean_squared_error: 2.9100\n",
      "Epoch 25/30\n",
      "85/85 [==============================] - 7s 78ms/step - loss: 7.8498 - root_mean_squared_error: 2.8018 - val_loss: 8.0522 - val_root_mean_squared_error: 2.8376\n",
      "Epoch 26/30\n",
      "85/85 [==============================] - 5s 64ms/step - loss: 7.8546 - root_mean_squared_error: 2.8026 - val_loss: 8.0897 - val_root_mean_squared_error: 2.8442\n",
      "Epoch 27/30\n",
      "85/85 [==============================] - 5s 64ms/step - loss: 7.8746 - root_mean_squared_error: 2.8062 - val_loss: 8.1926 - val_root_mean_squared_error: 2.8623\n",
      "Epoch 28/30\n",
      "85/85 [==============================] - 5s 64ms/step - loss: 7.8531 - root_mean_squared_error: 2.8023 - val_loss: 8.0445 - val_root_mean_squared_error: 2.8363\n",
      "Epoch 29/30\n",
      "85/85 [==============================] - 5s 64ms/step - loss: 7.8088 - root_mean_squared_error: 2.7944 - val_loss: 8.1672 - val_root_mean_squared_error: 2.8578\n",
      "Epoch 30/30\n",
      "85/85 [==============================] - 6s 65ms/step - loss: 7.9243 - root_mean_squared_error: 2.8150 - val_loss: 8.0022 - val_root_mean_squared_error: 2.8288\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 7.6831 - root_mean_squared_error: 2.7718\n",
      "\n",
      "training time 175.085271\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 7.683079242706299 with RMSE metric of 2.771836757659912\n",
      "264/264 [==============================] - 1s 5ms/step - loss: 7.8100 - root_mean_squared_error: 2.7946\n",
      "Test set has a loss (MSE) of 7.809970378875732 with RMSE metric of 2.7946324348449707\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 8s 60ms/step - loss: 18.0637 - root_mean_squared_error: 4.2501 - val_loss: 5.9300 - val_root_mean_squared_error: 2.4352\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 6.4359 - root_mean_squared_error: 2.5369 - val_loss: 5.1955 - val_root_mean_squared_error: 2.2794\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 6s 68ms/step - loss: 5.9154 - root_mean_squared_error: 2.4322 - val_loss: 5.1002 - val_root_mean_squared_error: 2.2584\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 5s 65ms/step - loss: 5.8059 - root_mean_squared_error: 2.4095 - val_loss: 5.5038 - val_root_mean_squared_error: 2.3460\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 5.6519 - root_mean_squared_error: 2.3774 - val_loss: 5.4579 - val_root_mean_squared_error: 2.3362\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 5s 65ms/step - loss: 5.6353 - root_mean_squared_error: 2.3739 - val_loss: 5.4429 - val_root_mean_squared_error: 2.3330\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 5.6311 - root_mean_squared_error: 2.3730 - val_loss: 6.5076 - val_root_mean_squared_error: 2.5510\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 5.6499 - root_mean_squared_error: 2.3770 - val_loss: 5.3412 - val_root_mean_squared_error: 2.3111\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 5.5417 - root_mean_squared_error: 2.3541 - val_loss: 5.2627 - val_root_mean_squared_error: 2.2941\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 5.4963 - root_mean_squared_error: 2.3444 - val_loss: 5.1931 - val_root_mean_squared_error: 2.2788\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 5.4960 - root_mean_squared_error: 2.3443 - val_loss: 5.1836 - val_root_mean_squared_error: 2.2768\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 5.5271 - root_mean_squared_error: 2.3510 - val_loss: 5.4156 - val_root_mean_squared_error: 2.3271\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 5.5033 - root_mean_squared_error: 2.3459 - val_loss: 5.3982 - val_root_mean_squared_error: 2.3234\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 6s 66ms/step - loss: 5.4659 - root_mean_squared_error: 2.3379 - val_loss: 5.0758 - val_root_mean_squared_error: 2.2530\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 5.4648 - root_mean_squared_error: 2.3377 - val_loss: 5.2612 - val_root_mean_squared_error: 2.2937\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 5.4632 - root_mean_squared_error: 2.3373 - val_loss: 5.5267 - val_root_mean_squared_error: 2.3509\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 5.4837 - root_mean_squared_error: 2.3417 - val_loss: 5.6300 - val_root_mean_squared_error: 2.3728\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 5.4525 - root_mean_squared_error: 2.3351 - val_loss: 5.0209 - val_root_mean_squared_error: 2.2407\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 5.4416 - root_mean_squared_error: 2.3327 - val_loss: 5.1254 - val_root_mean_squared_error: 2.2639\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 6s 66ms/step - loss: 5.4702 - root_mean_squared_error: 2.3388 - val_loss: 6.2406 - val_root_mean_squared_error: 2.4981\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 5.5374 - root_mean_squared_error: 2.3532 - val_loss: 5.0720 - val_root_mean_squared_error: 2.2521\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 5.4617 - root_mean_squared_error: 2.3370 - val_loss: 5.0072 - val_root_mean_squared_error: 2.2377\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 6s 71ms/step - loss: 5.4743 - root_mean_squared_error: 2.3397 - val_loss: 5.2214 - val_root_mean_squared_error: 2.2850\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 5.4262 - root_mean_squared_error: 2.3294 - val_loss: 5.1085 - val_root_mean_squared_error: 2.2602\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 6s 66ms/step - loss: 5.4267 - root_mean_squared_error: 2.3295 - val_loss: 5.3904 - val_root_mean_squared_error: 2.3217\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 5s 65ms/step - loss: 5.4097 - root_mean_squared_error: 2.3259 - val_loss: 5.2232 - val_root_mean_squared_error: 2.2854\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 6s 66ms/step - loss: 5.3828 - root_mean_squared_error: 2.3201 - val_loss: 5.0422 - val_root_mean_squared_error: 2.2455\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 6s 67ms/step - loss: 5.3660 - root_mean_squared_error: 2.3165 - val_loss: 5.0692 - val_root_mean_squared_error: 2.2515\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 5.3442 - root_mean_squared_error: 2.3117 - val_loss: 5.1598 - val_root_mean_squared_error: 2.2715\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 5.3460 - root_mean_squared_error: 2.3121 - val_loss: 5.4756 - val_root_mean_squared_error: 2.3400\n",
      "650/650 [==============================] - 3s 4ms/step - loss: 5.3416 - root_mean_squared_error: 2.3112\n",
      "\n",
      "training time 167.871598\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 5.341559886932373 with RMSE metric of 2.3111815452575684\n",
      "269/269 [==============================] - 1s 5ms/step - loss: 6.5073 - root_mean_squared_error: 2.5509\n",
      "Test set has a loss (MSE) of 6.507339954376221 with RMSE metric of 2.5509488582611084\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "108/108 [==============================] - 11s 66ms/step - loss: 17.4486 - root_mean_squared_error: 4.1772 - val_loss: 10.7456 - val_root_mean_squared_error: 3.2780\n",
      "Epoch 2/30\n",
      "108/108 [==============================] - 8s 70ms/step - loss: 9.7800 - root_mean_squared_error: 3.1273 - val_loss: 8.7868 - val_root_mean_squared_error: 2.9643\n",
      "Epoch 3/30\n",
      "108/108 [==============================] - 8s 78ms/step - loss: 9.3314 - root_mean_squared_error: 3.0547 - val_loss: 9.1603 - val_root_mean_squared_error: 3.0266\n",
      "Epoch 4/30\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 9.2451 - root_mean_squared_error: 3.0406 - val_loss: 9.1351 - val_root_mean_squared_error: 3.0224\n",
      "Epoch 5/30\n",
      "108/108 [==============================] - 7s 69ms/step - loss: 9.0815 - root_mean_squared_error: 3.0135 - val_loss: 8.6386 - val_root_mean_squared_error: 2.9392\n",
      "Epoch 6/30\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 9.1129 - root_mean_squared_error: 3.0188 - val_loss: 8.8511 - val_root_mean_squared_error: 2.9751\n",
      "Epoch 7/30\n",
      "108/108 [==============================] - 8s 77ms/step - loss: 9.0580 - root_mean_squared_error: 3.0097 - val_loss: 8.5246 - val_root_mean_squared_error: 2.9197\n",
      "Epoch 8/30\n",
      "108/108 [==============================] - 7s 67ms/step - loss: 9.0057 - root_mean_squared_error: 3.0009 - val_loss: 8.7709 - val_root_mean_squared_error: 2.9616\n",
      "Epoch 9/30\n",
      "108/108 [==============================] - 8s 74ms/step - loss: 8.9963 - root_mean_squared_error: 2.9994 - val_loss: 8.7677 - val_root_mean_squared_error: 2.9610\n",
      "Epoch 10/30\n",
      "108/108 [==============================] - 7s 70ms/step - loss: 9.0272 - root_mean_squared_error: 3.0045 - val_loss: 8.6691 - val_root_mean_squared_error: 2.9443\n",
      "Epoch 11/30\n",
      "108/108 [==============================] - 8s 72ms/step - loss: 9.0266 - root_mean_squared_error: 3.0044 - val_loss: 8.4677 - val_root_mean_squared_error: 2.9099\n",
      "Epoch 12/30\n",
      "108/108 [==============================] - 7s 64ms/step - loss: 8.9195 - root_mean_squared_error: 2.9866 - val_loss: 8.9237 - val_root_mean_squared_error: 2.9872\n",
      "Epoch 13/30\n",
      "108/108 [==============================] - 8s 73ms/step - loss: 8.9633 - root_mean_squared_error: 2.9939 - val_loss: 8.6066 - val_root_mean_squared_error: 2.9337\n",
      "Epoch 14/30\n",
      "108/108 [==============================] - 7s 67ms/step - loss: 8.9955 - root_mean_squared_error: 2.9992 - val_loss: 8.8960 - val_root_mean_squared_error: 2.9826\n",
      "Epoch 15/30\n",
      "108/108 [==============================] - 8s 72ms/step - loss: 8.9486 - root_mean_squared_error: 2.9914 - val_loss: 8.6952 - val_root_mean_squared_error: 2.9488\n",
      "Epoch 16/30\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 8.9768 - root_mean_squared_error: 2.9961 - val_loss: 9.2069 - val_root_mean_squared_error: 3.0343\n",
      "Epoch 17/30\n",
      "108/108 [==============================] - 8s 72ms/step - loss: 8.9097 - root_mean_squared_error: 2.9849 - val_loss: 8.6909 - val_root_mean_squared_error: 2.9480\n",
      "Epoch 18/30\n",
      "108/108 [==============================] - 7s 68ms/step - loss: 8.8279 - root_mean_squared_error: 2.9712 - val_loss: 8.7297 - val_root_mean_squared_error: 2.9546\n",
      "Epoch 19/30\n",
      "108/108 [==============================] - 8s 70ms/step - loss: 8.9114 - root_mean_squared_error: 2.9852 - val_loss: 9.0653 - val_root_mean_squared_error: 3.0109\n",
      "Epoch 20/30\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 8.9607 - root_mean_squared_error: 2.9934 - val_loss: 8.7245 - val_root_mean_squared_error: 2.9537\n",
      "Epoch 21/30\n",
      "108/108 [==============================] - 8s 75ms/step - loss: 8.9164 - root_mean_squared_error: 2.9860 - val_loss: 8.7558 - val_root_mean_squared_error: 2.9590\n",
      "Epoch 22/30\n",
      "108/108 [==============================] - 9s 85ms/step - loss: 8.9322 - root_mean_squared_error: 2.9887 - val_loss: 8.5957 - val_root_mean_squared_error: 2.9318\n",
      "Epoch 23/30\n",
      "108/108 [==============================] - 7s 69ms/step - loss: 8.8949 - root_mean_squared_error: 2.9824 - val_loss: 8.9186 - val_root_mean_squared_error: 2.9864\n",
      "Epoch 24/30\n",
      "108/108 [==============================] - 8s 74ms/step - loss: 8.8848 - root_mean_squared_error: 2.9807 - val_loss: 8.7380 - val_root_mean_squared_error: 2.9560\n",
      "Epoch 25/30\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 8.8777 - root_mean_squared_error: 2.9795 - val_loss: 8.5919 - val_root_mean_squared_error: 2.9312\n",
      "Epoch 26/30\n",
      "108/108 [==============================] - 8s 78ms/step - loss: 8.9022 - root_mean_squared_error: 2.9837 - val_loss: 9.2328 - val_root_mean_squared_error: 3.0386\n",
      "Epoch 27/30\n",
      "108/108 [==============================] - 7s 67ms/step - loss: 8.8886 - root_mean_squared_error: 2.9814 - val_loss: 8.5366 - val_root_mean_squared_error: 2.9217\n",
      "Epoch 28/30\n",
      "108/108 [==============================] - 8s 75ms/step - loss: 8.9052 - root_mean_squared_error: 2.9842 - val_loss: 8.9271 - val_root_mean_squared_error: 2.9878\n",
      "Epoch 29/30\n",
      "108/108 [==============================] - 7s 69ms/step - loss: 8.9494 - root_mean_squared_error: 2.9916 - val_loss: 8.7772 - val_root_mean_squared_error: 2.9626\n",
      "Epoch 30/30\n",
      "108/108 [==============================] - 8s 76ms/step - loss: 8.8630 - root_mean_squared_error: 2.9771 - val_loss: 9.0055 - val_root_mean_squared_error: 3.0009\n",
      "843/843 [==============================] - 4s 5ms/step - loss: 8.9106 - root_mean_squared_error: 2.9851\n",
      "\n",
      "training time 238.90272\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 8.910638809204102 with RMSE metric of 2.9850692749023438\n",
      "407/407 [==============================] - 2s 5ms/step - loss: 10.2771 - root_mean_squared_error: 3.2058\n",
      "Test set has a loss (MSE) of 10.277063369750977 with RMSE metric of 3.2057859897613525\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "153/153 [==============================] - 15s 81ms/step - loss: 18.3994 - root_mean_squared_error: 4.2895 - val_loss: 12.3407 - val_root_mean_squared_error: 3.5129\n",
      "Epoch 2/30\n",
      "153/153 [==============================] - 11s 75ms/step - loss: 10.5222 - root_mean_squared_error: 3.2438 - val_loss: 12.3089 - val_root_mean_squared_error: 3.5084\n",
      "Epoch 3/30\n",
      "153/153 [==============================] - 11s 75ms/step - loss: 10.1064 - root_mean_squared_error: 3.1791 - val_loss: 12.1960 - val_root_mean_squared_error: 3.4923\n",
      "Epoch 4/30\n",
      "153/153 [==============================] - 12s 79ms/step - loss: 10.0363 - root_mean_squared_error: 3.1680 - val_loss: 12.1613 - val_root_mean_squared_error: 3.4873\n",
      "Epoch 5/30\n",
      "153/153 [==============================] - 11s 71ms/step - loss: 10.0061 - root_mean_squared_error: 3.1632 - val_loss: 11.6865 - val_root_mean_squared_error: 3.4186\n",
      "Epoch 6/30\n",
      "153/153 [==============================] - 11s 75ms/step - loss: 9.9984 - root_mean_squared_error: 3.1620 - val_loss: 11.7222 - val_root_mean_squared_error: 3.4238\n",
      "Epoch 7/30\n",
      "153/153 [==============================] - 12s 77ms/step - loss: 9.8676 - root_mean_squared_error: 3.1413 - val_loss: 12.0216 - val_root_mean_squared_error: 3.4672\n",
      "Epoch 8/30\n",
      "153/153 [==============================] - 11s 73ms/step - loss: 9.7879 - root_mean_squared_error: 3.1286 - val_loss: 11.5662 - val_root_mean_squared_error: 3.4009\n",
      "Epoch 9/30\n",
      "153/153 [==============================] - 11s 71ms/step - loss: 9.8320 - root_mean_squared_error: 3.1356 - val_loss: 11.5577 - val_root_mean_squared_error: 3.3997\n",
      "Epoch 10/30\n",
      "153/153 [==============================] - 11s 71ms/step - loss: 9.7364 - root_mean_squared_error: 3.1203 - val_loss: 11.6876 - val_root_mean_squared_error: 3.4187\n",
      "Epoch 11/30\n",
      "153/153 [==============================] - 12s 76ms/step - loss: 9.9751 - root_mean_squared_error: 3.1583 - val_loss: 11.9704 - val_root_mean_squared_error: 3.4598\n",
      "Epoch 12/30\n",
      "153/153 [==============================] - 13s 82ms/step - loss: 9.7146 - root_mean_squared_error: 3.1168 - val_loss: 11.4643 - val_root_mean_squared_error: 3.3859\n",
      "Epoch 13/30\n",
      "153/153 [==============================] - 11s 72ms/step - loss: 9.7029 - root_mean_squared_error: 3.1150 - val_loss: 11.4555 - val_root_mean_squared_error: 3.3846\n",
      "Epoch 14/30\n",
      "153/153 [==============================] - 11s 74ms/step - loss: 9.7154 - root_mean_squared_error: 3.1170 - val_loss: 11.6278 - val_root_mean_squared_error: 3.4100\n",
      "Epoch 15/30\n",
      "153/153 [==============================] - 11s 72ms/step - loss: 9.7108 - root_mean_squared_error: 3.1162 - val_loss: 11.5817 - val_root_mean_squared_error: 3.4032\n",
      "Epoch 16/30\n",
      "153/153 [==============================] - 11s 69ms/step - loss: 9.7644 - root_mean_squared_error: 3.1248 - val_loss: 11.7155 - val_root_mean_squared_error: 3.4228\n",
      "Epoch 17/30\n",
      "153/153 [==============================] - 11s 70ms/step - loss: 9.7184 - root_mean_squared_error: 3.1174 - val_loss: 11.9543 - val_root_mean_squared_error: 3.4575\n",
      "Epoch 18/30\n",
      "153/153 [==============================] - 11s 70ms/step - loss: 9.6821 - root_mean_squared_error: 3.1116 - val_loss: 11.4994 - val_root_mean_squared_error: 3.3911\n",
      "Epoch 19/30\n",
      "153/153 [==============================] - 11s 69ms/step - loss: 9.6770 - root_mean_squared_error: 3.1108 - val_loss: 11.4007 - val_root_mean_squared_error: 3.3765\n",
      "Epoch 20/30\n",
      "153/153 [==============================] - 10s 67ms/step - loss: 9.6247 - root_mean_squared_error: 3.1024 - val_loss: 11.9181 - val_root_mean_squared_error: 3.4523\n",
      "Epoch 21/30\n",
      "153/153 [==============================] - 11s 71ms/step - loss: 9.5886 - root_mean_squared_error: 3.0966 - val_loss: 11.8594 - val_root_mean_squared_error: 3.4438\n",
      "Epoch 22/30\n",
      "153/153 [==============================] - 10s 68ms/step - loss: 9.6954 - root_mean_squared_error: 3.1137 - val_loss: 11.6273 - val_root_mean_squared_error: 3.4099\n",
      "Epoch 23/30\n",
      "153/153 [==============================] - 11s 69ms/step - loss: 9.6483 - root_mean_squared_error: 3.1062 - val_loss: 11.8541 - val_root_mean_squared_error: 3.4430\n",
      "Epoch 24/30\n",
      "153/153 [==============================] - 12s 81ms/step - loss: 9.6440 - root_mean_squared_error: 3.1055 - val_loss: 12.2523 - val_root_mean_squared_error: 3.5003\n",
      "Epoch 25/30\n",
      "153/153 [==============================] - 11s 69ms/step - loss: 9.5828 - root_mean_squared_error: 3.0956 - val_loss: 12.4457 - val_root_mean_squared_error: 3.5279\n",
      "Epoch 26/30\n",
      "153/153 [==============================] - 11s 70ms/step - loss: 9.7385 - root_mean_squared_error: 3.1206 - val_loss: 11.6617 - val_root_mean_squared_error: 3.4149\n",
      "Epoch 27/30\n",
      "153/153 [==============================] - 10s 67ms/step - loss: 9.6928 - root_mean_squared_error: 3.1133 - val_loss: 11.7385 - val_root_mean_squared_error: 3.4262\n",
      "Epoch 28/30\n",
      "153/153 [==============================] - 11s 70ms/step - loss: 9.6425 - root_mean_squared_error: 3.1052 - val_loss: 11.7181 - val_root_mean_squared_error: 3.4232\n",
      "Epoch 29/30\n",
      "153/153 [==============================] - 10s 68ms/step - loss: 9.6428 - root_mean_squared_error: 3.1053 - val_loss: 11.7122 - val_root_mean_squared_error: 3.4223\n",
      "Epoch 30/30\n",
      "153/153 [==============================] - 10s 68ms/step - loss: 9.6300 - root_mean_squared_error: 3.1032 - val_loss: 11.9276 - val_root_mean_squared_error: 3.4536\n",
      "1192/1192 [==============================] - 4s 3ms/step - loss: 10.0216 - root_mean_squared_error: 3.1657\n",
      "\n",
      "training time 339.243854\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 10.021580696105957 with RMSE metric of 3.1656880378723145\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 10.4228 - root_mean_squared_error: 3.2284\n",
      "Test set has a loss (MSE) of 10.422750473022461 with RMSE metric of 3.228428602218628\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "76/76 [==============================] - 8s 77ms/step - loss: 21.3680 - root_mean_squared_error: 4.6226 - val_loss: 13.5011 - val_root_mean_squared_error: 3.6744\n",
      "Epoch 2/30\n",
      "76/76 [==============================] - 5s 70ms/step - loss: 12.9236 - root_mean_squared_error: 3.5949 - val_loss: 12.8162 - val_root_mean_squared_error: 3.5800\n",
      "Epoch 3/30\n",
      "76/76 [==============================] - 5s 69ms/step - loss: 12.6095 - root_mean_squared_error: 3.5510 - val_loss: 12.8328 - val_root_mean_squared_error: 3.5823\n",
      "Epoch 4/30\n",
      "76/76 [==============================] - 5s 72ms/step - loss: 12.3656 - root_mean_squared_error: 3.5165 - val_loss: 12.6728 - val_root_mean_squared_error: 3.5599\n",
      "Epoch 5/30\n",
      "76/76 [==============================] - 6s 75ms/step - loss: 12.1461 - root_mean_squared_error: 3.4851 - val_loss: 12.7249 - val_root_mean_squared_error: 3.5672\n",
      "Epoch 6/30\n",
      "76/76 [==============================] - 5s 68ms/step - loss: 12.3902 - root_mean_squared_error: 3.5200 - val_loss: 13.9407 - val_root_mean_squared_error: 3.7337\n",
      "Epoch 7/30\n",
      "76/76 [==============================] - 5s 71ms/step - loss: 12.5102 - root_mean_squared_error: 3.5370 - val_loss: 13.2441 - val_root_mean_squared_error: 3.6392\n",
      "Epoch 8/30\n",
      "76/76 [==============================] - 5s 69ms/step - loss: 12.4625 - root_mean_squared_error: 3.5302 - val_loss: 12.8866 - val_root_mean_squared_error: 3.5898\n",
      "Epoch 9/30\n",
      "76/76 [==============================] - 5s 69ms/step - loss: 12.2114 - root_mean_squared_error: 3.4945 - val_loss: 12.6203 - val_root_mean_squared_error: 3.5525\n",
      "Epoch 10/30\n",
      "76/76 [==============================] - 6s 72ms/step - loss: 12.0807 - root_mean_squared_error: 3.4757 - val_loss: 12.8795 - val_root_mean_squared_error: 3.5888\n",
      "Epoch 11/30\n",
      "76/76 [==============================] - 5s 70ms/step - loss: 11.9710 - root_mean_squared_error: 3.4599 - val_loss: 14.3617 - val_root_mean_squared_error: 3.7897\n",
      "Epoch 12/30\n",
      "76/76 [==============================] - 5s 72ms/step - loss: 12.4501 - root_mean_squared_error: 3.5285 - val_loss: 12.7562 - val_root_mean_squared_error: 3.5716\n",
      "Epoch 13/30\n",
      "76/76 [==============================] - 5s 68ms/step - loss: 12.2671 - root_mean_squared_error: 3.5024 - val_loss: 12.7859 - val_root_mean_squared_error: 3.5757\n",
      "Epoch 14/30\n",
      "76/76 [==============================] - 5s 69ms/step - loss: 11.9817 - root_mean_squared_error: 3.4615 - val_loss: 14.0193 - val_root_mean_squared_error: 3.7442\n",
      "Epoch 15/30\n",
      "76/76 [==============================] - 5s 66ms/step - loss: 11.9551 - root_mean_squared_error: 3.4576 - val_loss: 12.6048 - val_root_mean_squared_error: 3.5503\n",
      "Epoch 16/30\n",
      "76/76 [==============================] - 6s 78ms/step - loss: 11.8277 - root_mean_squared_error: 3.4391 - val_loss: 12.9561 - val_root_mean_squared_error: 3.5995\n",
      "Epoch 17/30\n",
      "76/76 [==============================] - 5s 67ms/step - loss: 11.9809 - root_mean_squared_error: 3.4613 - val_loss: 13.5092 - val_root_mean_squared_error: 3.6755\n",
      "Epoch 18/30\n",
      "76/76 [==============================] - 5s 70ms/step - loss: 11.9193 - root_mean_squared_error: 3.4524 - val_loss: 13.3101 - val_root_mean_squared_error: 3.6483\n",
      "Epoch 19/30\n",
      "76/76 [==============================] - 6s 74ms/step - loss: 11.9542 - root_mean_squared_error: 3.4575 - val_loss: 12.7238 - val_root_mean_squared_error: 3.5670\n",
      "Epoch 20/30\n",
      "76/76 [==============================] - 5s 68ms/step - loss: 11.9324 - root_mean_squared_error: 3.4543 - val_loss: 12.7683 - val_root_mean_squared_error: 3.5733\n",
      "Epoch 21/30\n",
      "76/76 [==============================] - 6s 78ms/step - loss: 11.9245 - root_mean_squared_error: 3.4532 - val_loss: 12.5556 - val_root_mean_squared_error: 3.5434\n",
      "Epoch 22/30\n",
      "76/76 [==============================] - 5s 71ms/step - loss: 11.8270 - root_mean_squared_error: 3.4390 - val_loss: 13.0352 - val_root_mean_squared_error: 3.6104\n",
      "Epoch 23/30\n",
      "76/76 [==============================] - 5s 71ms/step - loss: 11.8273 - root_mean_squared_error: 3.4391 - val_loss: 12.5513 - val_root_mean_squared_error: 3.5428\n",
      "Epoch 24/30\n",
      "76/76 [==============================] - 5s 71ms/step - loss: 12.0708 - root_mean_squared_error: 3.4743 - val_loss: 12.7809 - val_root_mean_squared_error: 3.5750\n",
      "Epoch 25/30\n",
      "76/76 [==============================] - 5s 66ms/step - loss: 11.9795 - root_mean_squared_error: 3.4611 - val_loss: 12.7748 - val_root_mean_squared_error: 3.5742\n",
      "Epoch 26/30\n",
      "76/76 [==============================] - 5s 67ms/step - loss: 11.8771 - root_mean_squared_error: 3.4463 - val_loss: 12.9982 - val_root_mean_squared_error: 3.6053\n",
      "Epoch 27/30\n",
      "76/76 [==============================] - 5s 69ms/step - loss: 11.9322 - root_mean_squared_error: 3.4543 - val_loss: 13.1534 - val_root_mean_squared_error: 3.6268\n",
      "Epoch 28/30\n",
      "76/76 [==============================] - 5s 71ms/step - loss: 12.0419 - root_mean_squared_error: 3.4702 - val_loss: 12.8666 - val_root_mean_squared_error: 3.5870\n",
      "Epoch 29/30\n",
      "76/76 [==============================] - 5s 70ms/step - loss: 12.0424 - root_mean_squared_error: 3.4702 - val_loss: 12.8779 - val_root_mean_squared_error: 3.5886\n",
      "Epoch 30/30\n",
      "76/76 [==============================] - 6s 73ms/step - loss: 11.8904 - root_mean_squared_error: 3.4482 - val_loss: 13.8781 - val_root_mean_squared_error: 3.7253\n",
      "587/587 [==============================] - 2s 4ms/step - loss: 13.0549 - root_mean_squared_error: 3.6132\n",
      "\n",
      "training time 166.27521\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 13.05487060546875 with RMSE metric of 3.613152503967285\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 12.3231 - root_mean_squared_error: 3.5104\n",
      "Test set has a loss (MSE) of 12.323113441467285 with RMSE metric of 3.5104291439056396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    ## GRU Model\n",
    "    ## Initialize\n",
    "    model_name = 'GRU w Optimized Params - 60 mins'\n",
    "    num_layers = 4\n",
    "    epochs_num = 30\n",
    "    batch_size_set = 200\n",
    "    optimizer_set = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    forecast_distance=12\n",
    "    number_readings=8\n",
    "\n",
    "    ## Get New Data\n",
    "    a=DataSampling(path=path)\n",
    "    a.samplingDF\n",
    "    X_train,X_test,y_train,y_test = a.SampleValidSequences(num_clients=3, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "    #SETUP THE STACK\n",
    "    model_gru = Sequential()\n",
    "    model_gru.add(GRU(60, activation='tanh', input_shape=(number_readings,1), return_sequences=True))\n",
    "    model_gru.add(Dropout(0.1))\n",
    "    model_gru.add(GRU(20, activation='tanh'))\n",
    "    model_gru.add(Dense(10))\n",
    "    model_gru.add(Dense(1))\n",
    "\n",
    "\n",
    "    #START THE RUN\n",
    "    print('\\nRunning GRU model...')\n",
    "    start = datetime.now()\n",
    "\n",
    "    model_gru.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    hist = model_gru.fit(X_train, y_train, epochs=epochs_num, validation_split=0.2, batch_size=batch_size_set)\n",
    "    train_loss, train_rmse = model_gru.evaluate(X_train, y_train)\n",
    "    train_time = (datetime.now()-start).total_seconds()\n",
    "    print(\"\\ntraining time %s\" % train_time)\n",
    "\n",
    "    #PRINT RESULTS\n",
    "    print(f'GRU Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "    #Test set results\n",
    "    test_loss, test_rmse = model_gru.evaluate(X_test, y_test)\n",
    "    print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "\n",
    "    #y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "    Execution_time.append(train_time)\n",
    "    train_rmse_results.append(train_rmse)\n",
    "    test_rmse_results.append(test_rmse)\n",
    "    run_id.append(model_name+str(datetime.now()))\n",
    "    sample_size.append(len(X_train))\n",
    "    epochs.append(epochs_num)\n",
    "    batch_size.append(batch_size_set)\n",
    "    optimizer.append(optimizer_set)\n",
    "    layers.append(num_layers)\n",
    "    forecast_distance_perf.append(forecast_distance)\n",
    "    prev_readings.append(number_readings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running CNN RNN model...\n",
      "Epoch 1/15\n",
      "403/403 [==============================] - 5s 9ms/step - loss: 7.2989 - root_mean_squared_error: 2.7016 - val_loss: 5.0363 - val_root_mean_squared_error: 2.2442\n",
      "Epoch 2/15\n",
      "403/403 [==============================] - 3s 8ms/step - loss: 4.4570 - root_mean_squared_error: 2.1112 - val_loss: 4.7884 - val_root_mean_squared_error: 2.1882\n",
      "Epoch 3/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 4.2042 - root_mean_squared_error: 2.0504 - val_loss: 4.4610 - val_root_mean_squared_error: 2.1121\n",
      "Epoch 4/15\n",
      "403/403 [==============================] - 3s 8ms/step - loss: 4.0461 - root_mean_squared_error: 2.0115 - val_loss: 4.8105 - val_root_mean_squared_error: 2.1933\n",
      "Epoch 5/15\n",
      "403/403 [==============================] - 3s 8ms/step - loss: 3.9426 - root_mean_squared_error: 1.9856 - val_loss: 4.4112 - val_root_mean_squared_error: 2.1003\n",
      "Epoch 6/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 3.9215 - root_mean_squared_error: 1.9803 - val_loss: 5.1797 - val_root_mean_squared_error: 2.2759\n",
      "Epoch 7/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 3.9605 - root_mean_squared_error: 1.9901 - val_loss: 4.2381 - val_root_mean_squared_error: 2.0587\n",
      "Epoch 8/15\n",
      "403/403 [==============================] - 3s 7ms/step - loss: 3.8840 - root_mean_squared_error: 1.9708 - val_loss: 4.2738 - val_root_mean_squared_error: 2.0673\n",
      "Epoch 9/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 3.8923 - root_mean_squared_error: 1.9729 - val_loss: 4.3412 - val_root_mean_squared_error: 2.0836\n",
      "Epoch 10/15\n",
      "403/403 [==============================] - 3s 9ms/step - loss: 3.8652 - root_mean_squared_error: 1.9660 - val_loss: 4.4712 - val_root_mean_squared_error: 2.1145\n",
      "Epoch 11/15\n",
      "403/403 [==============================] - 3s 8ms/step - loss: 3.8434 - root_mean_squared_error: 1.9605 - val_loss: 5.2143 - val_root_mean_squared_error: 2.2835\n",
      "Epoch 12/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 3.8549 - root_mean_squared_error: 1.9634 - val_loss: 4.2543 - val_root_mean_squared_error: 2.0626\n",
      "Epoch 13/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 3.8309 - root_mean_squared_error: 1.9573 - val_loss: 4.2381 - val_root_mean_squared_error: 2.0587\n",
      "Epoch 14/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 3.8506 - root_mean_squared_error: 1.9623 - val_loss: 4.3139 - val_root_mean_squared_error: 2.0770\n",
      "Epoch 15/15\n",
      "403/403 [==============================] - 3s 8ms/step - loss: 3.7934 - root_mean_squared_error: 1.9477 - val_loss: 4.2299 - val_root_mean_squared_error: 2.0567\n",
      "786/786 [==============================] - 4s 5ms/step - loss: 4.2848 - root_mean_squared_error: 2.0700\n",
      "\n",
      "training time 57.233281\n",
      "CNN RNN Model: \n",
      "Training set has a loss (MSE) of 4.284834861755371 with RMSE metric of 2.069984197616577\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 4.1648 - root_mean_squared_error: 2.0408\n",
      "Test set has a loss (MSE) of 4.164759159088135 with RMSE metric of 2.04077410697937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## CNN RNN\n",
    "## Initialize\n",
    "model_name = 'CNN - RNN'\n",
    "num_layers = 4\n",
    "epochs_num = 15\n",
    "batch_size_set = 50\n",
    "optimizer_set = 'adam'\n",
    "forecast_distance=6\n",
    "number_readings=8\n",
    "\n",
    "## Get New Data\n",
    "a=DataSampling(path=path)\n",
    "a.samplingDF\n",
    "X_train,X_test,y_train,y_test = a.SampleValidSequences(num_clients=3, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "#SETUP THE STACK\n",
    "\n",
    "model_cnn_rnn = Sequential()\n",
    "model_cnn_rnn.add(tf.keras.layers.Conv1D(32, 2, activation='relu', input_shape=(number_readings,1)))\n",
    "model_cnn_rnn.add(tf.keras.layers.MaxPooling1D((1)))\n",
    "model_cnn_rnn.add(SimpleRNN(120, activation='relu', return_sequences=True))\n",
    "#model_cnn_rnn.add(LSTM(10, activation='relu', return_sequences=True))\n",
    "model_cnn_rnn.add(Flatten())\n",
    "model_cnn_rnn.add(Dense(1))\n",
    "\n",
    "\n",
    "#START THE RUN\n",
    "print('\\nRunning CNN RNN model...')\n",
    "start = datetime.now()\n",
    "\n",
    "model_cnn_rnn.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "hist = model_cnn_rnn.fit(X_train, y_train, epochs=epochs_num, validation_split=0.2, batch_size=batch_size_set)\n",
    "train_loss, train_rmse = model_gru.evaluate(X_train, y_train)\n",
    "train_time = (datetime.now()-start).total_seconds()\n",
    "print(\"\\ntraining time %s\" % train_time)\n",
    "\n",
    "#PRINT RESULTS\n",
    "print(f'CNN RNN Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "#Test set results\n",
    "test_loss, test_rmse = model_cnn_rnn.evaluate(X_test, y_test)\n",
    "print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "\n",
    "#y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "Execution_time.append(train_time)\n",
    "train_rmse_results.append(train_rmse)\n",
    "test_rmse_results.append(test_rmse)\n",
    "run_id.append(model_name+str(datetime.now()))\n",
    "sample_size.append(len(X_train))\n",
    "epochs.append(epochs_num)\n",
    "batch_size.append(batch_size_set)\n",
    "optimizer.append(optimizer_set)\n",
    "layers.append(num_layers)\n",
    "forecast_distance_perf.append(forecast_distance)\n",
    "prev_readings.append(number_readings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "54/54 [==============================] - 9s 122ms/step - loss: 25.6800 - root_mean_squared_error: 5.0675 - val_loss: 5.3548 - val_root_mean_squared_error: 2.3140\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 6s 115ms/step - loss: 3.9752 - root_mean_squared_error: 1.9938 - val_loss: 4.3298 - val_root_mean_squared_error: 2.0808\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 6s 114ms/step - loss: 3.4911 - root_mean_squared_error: 1.8685 - val_loss: 4.1150 - val_root_mean_squared_error: 2.0285\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 6s 115ms/step - loss: 3.2061 - root_mean_squared_error: 1.7906 - val_loss: 3.8575 - val_root_mean_squared_error: 1.9641\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 6s 112ms/step - loss: 3.0421 - root_mean_squared_error: 1.7442 - val_loss: 3.6566 - val_root_mean_squared_error: 1.9122\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 6s 112ms/step - loss: 2.9093 - root_mean_squared_error: 1.7057 - val_loss: 3.6014 - val_root_mean_squared_error: 1.8977\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 6s 112ms/step - loss: 2.8765 - root_mean_squared_error: 1.6960 - val_loss: 3.5342 - val_root_mean_squared_error: 1.8799\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 6s 112ms/step - loss: 2.8303 - root_mean_squared_error: 1.6823 - val_loss: 3.5336 - val_root_mean_squared_error: 1.8798\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 6s 116ms/step - loss: 2.8092 - root_mean_squared_error: 1.6761 - val_loss: 3.4863 - val_root_mean_squared_error: 1.8672\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 2.7574 - root_mean_squared_error: 1.6605 - val_loss: 3.5093 - val_root_mean_squared_error: 1.8733\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 2.7410 - root_mean_squared_error: 1.6556 - val_loss: 3.4856 - val_root_mean_squared_error: 1.8670\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 6s 112ms/step - loss: 2.7338 - root_mean_squared_error: 1.6534 - val_loss: 3.3961 - val_root_mean_squared_error: 1.8428\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 6s 117ms/step - loss: 2.7335 - root_mean_squared_error: 1.6533 - val_loss: 3.3843 - val_root_mean_squared_error: 1.8396\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 6s 116ms/step - loss: 2.7287 - root_mean_squared_error: 1.6519 - val_loss: 3.4559 - val_root_mean_squared_error: 1.8590\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 6s 115ms/step - loss: 2.6783 - root_mean_squared_error: 1.6365 - val_loss: 3.4121 - val_root_mean_squared_error: 1.8472\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 6s 115ms/step - loss: 2.6757 - root_mean_squared_error: 1.6358 - val_loss: 3.4870 - val_root_mean_squared_error: 1.8673\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 6s 114ms/step - loss: 2.6616 - root_mean_squared_error: 1.6314 - val_loss: 3.4024 - val_root_mean_squared_error: 1.8446\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 2.6588 - root_mean_squared_error: 1.6306 - val_loss: 3.3559 - val_root_mean_squared_error: 1.8319\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 6s 114ms/step - loss: 2.6515 - root_mean_squared_error: 1.6284 - val_loss: 3.3568 - val_root_mean_squared_error: 1.8322\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 6s 112ms/step - loss: 2.7262 - root_mean_squared_error: 1.6511 - val_loss: 3.3499 - val_root_mean_squared_error: 1.8303\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 2.5977 - root_mean_squared_error: 1.6117 - val_loss: 3.3246 - val_root_mean_squared_error: 1.8233\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 2.6278 - root_mean_squared_error: 1.6210 - val_loss: 3.3410 - val_root_mean_squared_error: 1.8278\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 2.6029 - root_mean_squared_error: 1.6134 - val_loss: 3.3041 - val_root_mean_squared_error: 1.8177\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 6s 114ms/step - loss: 2.5575 - root_mean_squared_error: 1.5992 - val_loss: 3.2422 - val_root_mean_squared_error: 1.8006\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 2.5197 - root_mean_squared_error: 1.5874 - val_loss: 3.3608 - val_root_mean_squared_error: 1.8333\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 2.5456 - root_mean_squared_error: 1.5955 - val_loss: 3.4227 - val_root_mean_squared_error: 1.8500\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 2.5619 - root_mean_squared_error: 1.6006 - val_loss: 3.3155 - val_root_mean_squared_error: 1.8209\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 2.5345 - root_mean_squared_error: 1.5920 - val_loss: 3.2571 - val_root_mean_squared_error: 1.8048\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - 6s 117ms/step - loss: 2.5282 - root_mean_squared_error: 1.5900 - val_loss: 3.3488 - val_root_mean_squared_error: 1.8300\n",
      "Epoch 30/30\n",
      "54/54 [==============================] - 6s 116ms/step - loss: 2.5226 - root_mean_squared_error: 1.5883 - val_loss: 3.3304 - val_root_mean_squared_error: 1.8249\n",
      "421/421 [==============================] - 5s 12ms/step - loss: 2.6068 - root_mean_squared_error: 1.6146\n",
      "\n",
      "training time 192.246508\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 2.606811046600342 with RMSE metric of 1.6145621538162231\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 3.3201 - root_mean_squared_error: 1.8221\n",
      "Test set has a loss (MSE) of 3.3201441764831543 with RMSE metric of 1.8221262693405151\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "132/132 [==============================] - 19s 120ms/step - loss: 8.3717 - root_mean_squared_error: 2.8934 - val_loss: 2.9954 - val_root_mean_squared_error: 1.7307\n",
      "Epoch 2/30\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 2.6934 - root_mean_squared_error: 1.6411 - val_loss: 2.5946 - val_root_mean_squared_error: 1.6108\n",
      "Epoch 3/30\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 2.5375 - root_mean_squared_error: 1.5929 - val_loss: 2.5109 - val_root_mean_squared_error: 1.5846\n",
      "Epoch 4/30\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 2.4466 - root_mean_squared_error: 1.5642 - val_loss: 2.4940 - val_root_mean_squared_error: 1.5792\n",
      "Epoch 5/30\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 2.3561 - root_mean_squared_error: 1.5350 - val_loss: 2.3723 - val_root_mean_squared_error: 1.5402\n",
      "Epoch 6/30\n",
      "132/132 [==============================] - 17s 129ms/step - loss: 2.2813 - root_mean_squared_error: 1.5104 - val_loss: 2.4980 - val_root_mean_squared_error: 1.5805\n",
      "Epoch 7/30\n",
      "132/132 [==============================] - 17s 130ms/step - loss: 2.2826 - root_mean_squared_error: 1.5108 - val_loss: 2.3034 - val_root_mean_squared_error: 1.5177\n",
      "Epoch 8/30\n",
      "132/132 [==============================] - 17s 129ms/step - loss: 2.2203 - root_mean_squared_error: 1.4901 - val_loss: 2.2569 - val_root_mean_squared_error: 1.5023\n",
      "Epoch 9/30\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 2.2083 - root_mean_squared_error: 1.4861 - val_loss: 2.3419 - val_root_mean_squared_error: 1.5303\n",
      "Epoch 10/30\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 2.1904 - root_mean_squared_error: 1.4800 - val_loss: 2.2630 - val_root_mean_squared_error: 1.5043\n",
      "Epoch 11/30\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 2.1565 - root_mean_squared_error: 1.4685 - val_loss: 2.3493 - val_root_mean_squared_error: 1.5327\n",
      "Epoch 12/30\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 2.1643 - root_mean_squared_error: 1.4712 - val_loss: 2.2412 - val_root_mean_squared_error: 1.4971\n",
      "Epoch 13/30\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 2.1569 - root_mean_squared_error: 1.4686 - val_loss: 2.2556 - val_root_mean_squared_error: 1.5019\n",
      "Epoch 14/30\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 2.1450 - root_mean_squared_error: 1.4646 - val_loss: 2.2373 - val_root_mean_squared_error: 1.4958\n",
      "Epoch 15/30\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 2.1311 - root_mean_squared_error: 1.4598 - val_loss: 2.1881 - val_root_mean_squared_error: 1.4792\n",
      "Epoch 16/30\n",
      "132/132 [==============================] - 18s 137ms/step - loss: 2.1251 - root_mean_squared_error: 1.4578 - val_loss: 2.2476 - val_root_mean_squared_error: 1.4992\n",
      "Epoch 17/30\n",
      "132/132 [==============================] - 19s 142ms/step - loss: 2.1134 - root_mean_squared_error: 1.4538 - val_loss: 2.2673 - val_root_mean_squared_error: 1.5058\n",
      "Epoch 18/30\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 2.1145 - root_mean_squared_error: 1.4541 - val_loss: 2.1761 - val_root_mean_squared_error: 1.4752\n",
      "Epoch 19/30\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 2.1185 - root_mean_squared_error: 1.4555 - val_loss: 2.1935 - val_root_mean_squared_error: 1.4810\n",
      "Epoch 20/30\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 2.1076 - root_mean_squared_error: 1.4518 - val_loss: 2.2378 - val_root_mean_squared_error: 1.4959\n",
      "Epoch 21/30\n",
      "132/132 [==============================] - 18s 139ms/step - loss: 2.0996 - root_mean_squared_error: 1.4490 - val_loss: 2.1880 - val_root_mean_squared_error: 1.4792\n",
      "Epoch 22/30\n",
      "132/132 [==============================] - 19s 143ms/step - loss: 2.0922 - root_mean_squared_error: 1.4465 - val_loss: 2.1482 - val_root_mean_squared_error: 1.4657\n",
      "Epoch 23/30\n",
      "132/132 [==============================] - 18s 138ms/step - loss: 2.0913 - root_mean_squared_error: 1.4461 - val_loss: 2.1955 - val_root_mean_squared_error: 1.4817\n",
      "Epoch 24/30\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 2.0834 - root_mean_squared_error: 1.4434 - val_loss: 2.2520 - val_root_mean_squared_error: 1.5007\n",
      "Epoch 25/30\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 2.1135 - root_mean_squared_error: 1.4538 - val_loss: 2.2675 - val_root_mean_squared_error: 1.5058\n",
      "Epoch 26/30\n",
      "132/132 [==============================] - 18s 136ms/step - loss: 2.0895 - root_mean_squared_error: 1.4455 - val_loss: 2.1470 - val_root_mean_squared_error: 1.4653\n",
      "Epoch 27/30\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 2.0458 - root_mean_squared_error: 1.4303 - val_loss: 2.1446 - val_root_mean_squared_error: 1.4644\n",
      "Epoch 28/30\n",
      "132/132 [==============================] - 18s 135ms/step - loss: 2.0731 - root_mean_squared_error: 1.4398 - val_loss: 2.1454 - val_root_mean_squared_error: 1.4647\n",
      "Epoch 29/30\n",
      "132/132 [==============================] - 18s 133ms/step - loss: 2.0457 - root_mean_squared_error: 1.4303 - val_loss: 2.1774 - val_root_mean_squared_error: 1.4756\n",
      "Epoch 30/30\n",
      "132/132 [==============================] - 18s 134ms/step - loss: 2.0830 - root_mean_squared_error: 1.4433 - val_loss: 2.1805 - val_root_mean_squared_error: 1.4766\n",
      "1030/1030 [==============================] - 15s 14ms/step - loss: 2.0367 - root_mean_squared_error: 1.4271\n",
      "\n",
      "training time 541.170128\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 2.03668212890625 with RMSE metric of 1.427123785018921\n",
      "407/407 [==============================] - 6s 15ms/step - loss: 2.3445 - root_mean_squared_error: 1.5312\n",
      "Test set has a loss (MSE) of 2.3444535732269287 with RMSE metric of 1.531160831451416\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "99/99 [==============================] - 16s 132ms/step - loss: 21.2878 - root_mean_squared_error: 4.6139 - val_loss: 3.9495 - val_root_mean_squared_error: 1.9873\n",
      "Epoch 2/30\n",
      "99/99 [==============================] - 13s 137ms/step - loss: 4.7258 - root_mean_squared_error: 2.1739 - val_loss: 3.7930 - val_root_mean_squared_error: 1.9476\n",
      "Epoch 3/30\n",
      "99/99 [==============================] - 13s 134ms/step - loss: 4.4550 - root_mean_squared_error: 2.1107 - val_loss: 3.5259 - val_root_mean_squared_error: 1.8777\n",
      "Epoch 4/30\n",
      "99/99 [==============================] - 13s 135ms/step - loss: 4.3556 - root_mean_squared_error: 2.0870 - val_loss: 3.3367 - val_root_mean_squared_error: 1.8267\n",
      "Epoch 5/30\n",
      "99/99 [==============================] - 13s 135ms/step - loss: 4.2881 - root_mean_squared_error: 2.0708 - val_loss: 3.5496 - val_root_mean_squared_error: 1.8840\n",
      "Epoch 6/30\n",
      "99/99 [==============================] - 13s 135ms/step - loss: 4.2152 - root_mean_squared_error: 2.0531 - val_loss: 3.4376 - val_root_mean_squared_error: 1.8541\n",
      "Epoch 7/30\n",
      "99/99 [==============================] - 13s 135ms/step - loss: 4.1470 - root_mean_squared_error: 2.0364 - val_loss: 3.2439 - val_root_mean_squared_error: 1.8011\n",
      "Epoch 8/30\n",
      "99/99 [==============================] - 13s 135ms/step - loss: 4.0986 - root_mean_squared_error: 2.0245 - val_loss: 3.1671 - val_root_mean_squared_error: 1.7796\n",
      "Epoch 9/30\n",
      "99/99 [==============================] - 13s 135ms/step - loss: 4.1337 - root_mean_squared_error: 2.0332 - val_loss: 3.1892 - val_root_mean_squared_error: 1.7858\n",
      "Epoch 10/30\n",
      "99/99 [==============================] - 14s 147ms/step - loss: 4.0227 - root_mean_squared_error: 2.0057 - val_loss: 3.1813 - val_root_mean_squared_error: 1.7836\n",
      "Epoch 11/30\n",
      "99/99 [==============================] - 13s 134ms/step - loss: 4.0670 - root_mean_squared_error: 2.0167 - val_loss: 3.7585 - val_root_mean_squared_error: 1.9387\n",
      "Epoch 12/30\n",
      "99/99 [==============================] - 13s 134ms/step - loss: 4.0481 - root_mean_squared_error: 2.0120 - val_loss: 3.1481 - val_root_mean_squared_error: 1.7743\n",
      "Epoch 13/30\n",
      "99/99 [==============================] - 13s 136ms/step - loss: 4.0390 - root_mean_squared_error: 2.0097 - val_loss: 3.1315 - val_root_mean_squared_error: 1.7696\n",
      "Epoch 14/30\n",
      "99/99 [==============================] - 14s 141ms/step - loss: 3.9804 - root_mean_squared_error: 1.9951 - val_loss: 3.1690 - val_root_mean_squared_error: 1.7802\n",
      "Epoch 15/30\n",
      "99/99 [==============================] - 17s 173ms/step - loss: 3.9783 - root_mean_squared_error: 1.9946 - val_loss: 3.3892 - val_root_mean_squared_error: 1.8410\n",
      "Epoch 16/30\n",
      "99/99 [==============================] - 14s 142ms/step - loss: 3.9784 - root_mean_squared_error: 1.9946 - val_loss: 3.3583 - val_root_mean_squared_error: 1.8326\n",
      "Epoch 17/30\n",
      "99/99 [==============================] - 14s 139ms/step - loss: 3.9355 - root_mean_squared_error: 1.9838 - val_loss: 3.1494 - val_root_mean_squared_error: 1.7747\n",
      "Epoch 18/30\n",
      "99/99 [==============================] - 13s 136ms/step - loss: 3.9435 - root_mean_squared_error: 1.9858 - val_loss: 3.1618 - val_root_mean_squared_error: 1.7781\n",
      "Epoch 19/30\n",
      "99/99 [==============================] - 14s 139ms/step - loss: 3.8950 - root_mean_squared_error: 1.9736 - val_loss: 3.1551 - val_root_mean_squared_error: 1.7762\n",
      "Epoch 20/30\n",
      "99/99 [==============================] - 14s 137ms/step - loss: 3.8940 - root_mean_squared_error: 1.9733 - val_loss: 3.1419 - val_root_mean_squared_error: 1.7725\n",
      "Epoch 21/30\n",
      "99/99 [==============================] - 14s 139ms/step - loss: 3.9416 - root_mean_squared_error: 1.9853 - val_loss: 3.1981 - val_root_mean_squared_error: 1.7883\n",
      "Epoch 22/30\n",
      "99/99 [==============================] - 14s 137ms/step - loss: 3.9014 - root_mean_squared_error: 1.9752 - val_loss: 3.0832 - val_root_mean_squared_error: 1.7559\n",
      "Epoch 23/30\n",
      "99/99 [==============================] - 13s 135ms/step - loss: 3.9354 - root_mean_squared_error: 1.9838 - val_loss: 3.1160 - val_root_mean_squared_error: 1.7652\n",
      "Epoch 24/30\n",
      "99/99 [==============================] - 14s 137ms/step - loss: 3.8661 - root_mean_squared_error: 1.9662 - val_loss: 3.1348 - val_root_mean_squared_error: 1.7705\n",
      "Epoch 25/30\n",
      "99/99 [==============================] - 14s 140ms/step - loss: 3.8684 - root_mean_squared_error: 1.9668 - val_loss: 3.1640 - val_root_mean_squared_error: 1.7788\n",
      "Epoch 26/30\n",
      "99/99 [==============================] - 13s 136ms/step - loss: 3.8957 - root_mean_squared_error: 1.9738 - val_loss: 3.1839 - val_root_mean_squared_error: 1.7843\n",
      "Epoch 27/30\n",
      "99/99 [==============================] - 13s 135ms/step - loss: 3.8385 - root_mean_squared_error: 1.9592 - val_loss: 3.1345 - val_root_mean_squared_error: 1.7705\n",
      "Epoch 28/30\n",
      "99/99 [==============================] - 14s 138ms/step - loss: 3.8385 - root_mean_squared_error: 1.9592 - val_loss: 3.0815 - val_root_mean_squared_error: 1.7554\n",
      "Epoch 29/30\n",
      "99/99 [==============================] - 13s 135ms/step - loss: 3.8295 - root_mean_squared_error: 1.9569 - val_loss: 3.1134 - val_root_mean_squared_error: 1.7645\n",
      "Epoch 30/30\n",
      "99/99 [==============================] - 13s 135ms/step - loss: 3.8246 - root_mean_squared_error: 1.9557 - val_loss: 3.1428 - val_root_mean_squared_error: 1.7728\n",
      "774/774 [==============================] - 12s 15ms/step - loss: 3.6181 - root_mean_squared_error: 1.9021\n",
      "\n",
      "training time 424.143447\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 3.6181259155273438 with RMSE metric of 1.9021371603012085\n",
      "370/370 [==============================] - 6s 14ms/step - loss: 3.5005 - root_mean_squared_error: 1.8710\n",
      "Test set has a loss (MSE) of 3.500458240509033 with RMSE metric of 1.8709511756896973\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "119/119 [==============================] - 18s 129ms/step - loss: 13.5317 - root_mean_squared_error: 3.6785 - val_loss: 4.8641 - val_root_mean_squared_error: 2.2055\n",
      "Epoch 2/30\n",
      "119/119 [==============================] - 16s 132ms/step - loss: 4.2642 - root_mean_squared_error: 2.0650 - val_loss: 4.2091 - val_root_mean_squared_error: 2.0516\n",
      "Epoch 3/30\n",
      "119/119 [==============================] - 16s 132ms/step - loss: 4.0373 - root_mean_squared_error: 2.0093 - val_loss: 4.3785 - val_root_mean_squared_error: 2.0925\n",
      "Epoch 4/30\n",
      "119/119 [==============================] - 15s 130ms/step - loss: 3.9967 - root_mean_squared_error: 1.9992 - val_loss: 4.0555 - val_root_mean_squared_error: 2.0138\n",
      "Epoch 5/30\n",
      "119/119 [==============================] - 15s 127ms/step - loss: 3.8408 - root_mean_squared_error: 1.9598 - val_loss: 3.9915 - val_root_mean_squared_error: 1.9979\n",
      "Epoch 6/30\n",
      "119/119 [==============================] - 15s 128ms/step - loss: 3.8298 - root_mean_squared_error: 1.9570 - val_loss: 3.9495 - val_root_mean_squared_error: 1.9873\n",
      "Epoch 7/30\n",
      "119/119 [==============================] - 15s 129ms/step - loss: 3.8268 - root_mean_squared_error: 1.9562 - val_loss: 4.0137 - val_root_mean_squared_error: 2.0034\n",
      "Epoch 8/30\n",
      "119/119 [==============================] - 16s 132ms/step - loss: 3.7201 - root_mean_squared_error: 1.9288 - val_loss: 3.9005 - val_root_mean_squared_error: 1.9750\n",
      "Epoch 9/30\n",
      "119/119 [==============================] - 15s 130ms/step - loss: 3.7141 - root_mean_squared_error: 1.9272 - val_loss: 3.8399 - val_root_mean_squared_error: 1.9596\n",
      "Epoch 10/30\n",
      "119/119 [==============================] - 15s 130ms/step - loss: 3.7087 - root_mean_squared_error: 1.9258 - val_loss: 3.9394 - val_root_mean_squared_error: 1.9848\n",
      "Epoch 11/30\n",
      "119/119 [==============================] - 15s 128ms/step - loss: 3.7176 - root_mean_squared_error: 1.9281 - val_loss: 3.7762 - val_root_mean_squared_error: 1.9433\n",
      "Epoch 12/30\n",
      "119/119 [==============================] - 15s 127ms/step - loss: 3.6485 - root_mean_squared_error: 1.9101 - val_loss: 3.9483 - val_root_mean_squared_error: 1.9870\n",
      "Epoch 13/30\n",
      "119/119 [==============================] - 15s 129ms/step - loss: 3.6522 - root_mean_squared_error: 1.9111 - val_loss: 3.9424 - val_root_mean_squared_error: 1.9855\n",
      "Epoch 14/30\n",
      "119/119 [==============================] - 16s 131ms/step - loss: 3.6156 - root_mean_squared_error: 1.9015 - val_loss: 3.7084 - val_root_mean_squared_error: 1.9257\n",
      "Epoch 15/30\n",
      "119/119 [==============================] - 16s 131ms/step - loss: 3.6684 - root_mean_squared_error: 1.9153 - val_loss: 3.7682 - val_root_mean_squared_error: 1.9412\n",
      "Epoch 16/30\n",
      "119/119 [==============================] - 15s 130ms/step - loss: 3.5737 - root_mean_squared_error: 1.8904 - val_loss: 3.6919 - val_root_mean_squared_error: 1.9214\n",
      "Epoch 17/30\n",
      "119/119 [==============================] - 15s 127ms/step - loss: 3.5916 - root_mean_squared_error: 1.8952 - val_loss: 3.7523 - val_root_mean_squared_error: 1.9371\n",
      "Epoch 18/30\n",
      "119/119 [==============================] - 15s 128ms/step - loss: 3.5490 - root_mean_squared_error: 1.8839 - val_loss: 3.9138 - val_root_mean_squared_error: 1.9783\n",
      "Epoch 19/30\n",
      "119/119 [==============================] - 15s 128ms/step - loss: 3.5419 - root_mean_squared_error: 1.8820 - val_loss: 3.7140 - val_root_mean_squared_error: 1.9272\n",
      "Epoch 20/30\n",
      "119/119 [==============================] - 17s 140ms/step - loss: 3.5343 - root_mean_squared_error: 1.8800 - val_loss: 3.7225 - val_root_mean_squared_error: 1.9294\n",
      "Epoch 21/30\n",
      "119/119 [==============================] - 15s 129ms/step - loss: 3.5580 - root_mean_squared_error: 1.8863 - val_loss: 3.7331 - val_root_mean_squared_error: 1.9321\n",
      "Epoch 22/30\n",
      "119/119 [==============================] - 15s 130ms/step - loss: 3.5610 - root_mean_squared_error: 1.8871 - val_loss: 3.6738 - val_root_mean_squared_error: 1.9167\n",
      "Epoch 23/30\n",
      "119/119 [==============================] - 15s 128ms/step - loss: 3.5313 - root_mean_squared_error: 1.8792 - val_loss: 3.6694 - val_root_mean_squared_error: 1.9156\n",
      "Epoch 24/30\n",
      "119/119 [==============================] - 15s 128ms/step - loss: 3.5457 - root_mean_squared_error: 1.8830 - val_loss: 3.6098 - val_root_mean_squared_error: 1.9000\n",
      "Epoch 25/30\n",
      "119/119 [==============================] - 15s 127ms/step - loss: 3.4700 - root_mean_squared_error: 1.8628 - val_loss: 3.6793 - val_root_mean_squared_error: 1.9182\n",
      "Epoch 26/30\n",
      "119/119 [==============================] - 15s 128ms/step - loss: 3.4904 - root_mean_squared_error: 1.8683 - val_loss: 3.6003 - val_root_mean_squared_error: 1.8975\n",
      "Epoch 27/30\n",
      "119/119 [==============================] - 16s 131ms/step - loss: 3.4808 - root_mean_squared_error: 1.8657 - val_loss: 3.7090 - val_root_mean_squared_error: 1.9259\n",
      "Epoch 28/30\n",
      "119/119 [==============================] - 15s 129ms/step - loss: 3.4857 - root_mean_squared_error: 1.8670 - val_loss: 3.6885 - val_root_mean_squared_error: 1.9205\n",
      "Epoch 29/30\n",
      "119/119 [==============================] - 15s 128ms/step - loss: 3.5213 - root_mean_squared_error: 1.8765 - val_loss: 3.6060 - val_root_mean_squared_error: 1.8989\n",
      "Epoch 30/30\n",
      "119/119 [==============================] - 15s 128ms/step - loss: 3.4578 - root_mean_squared_error: 1.8595 - val_loss: 3.6351 - val_root_mean_squared_error: 1.9066\n",
      "929/929 [==============================] - 12s 13ms/step - loss: 3.4097 - root_mean_squared_error: 1.8465\n",
      "\n",
      "training time 477.317908\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 3.409682273864746 with RMSE metric of 1.8465324640274048\n",
      "407/407 [==============================] - 6s 14ms/step - loss: 3.8035 - root_mean_squared_error: 1.9503\n",
      "Test set has a loss (MSE) of 3.803525924682617 with RMSE metric of 1.9502630233764648\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "197/197 [==============================] - 30s 140ms/step - loss: 8.0333 - root_mean_squared_error: 2.8343 - val_loss: 2.9383 - val_root_mean_squared_error: 1.7142\n",
      "Epoch 2/30\n",
      "197/197 [==============================] - 26s 131ms/step - loss: 3.4905 - root_mean_squared_error: 1.8683 - val_loss: 2.8434 - val_root_mean_squared_error: 1.6862\n",
      "Epoch 3/30\n",
      "197/197 [==============================] - 26s 131ms/step - loss: 3.3228 - root_mean_squared_error: 1.8229 - val_loss: 2.6914 - val_root_mean_squared_error: 1.6406\n",
      "Epoch 4/30\n",
      "197/197 [==============================] - 279s 1s/step - loss: 3.2399 - root_mean_squared_error: 1.8000 - val_loss: 2.7108 - val_root_mean_squared_error: 1.6465\n",
      "Epoch 5/30\n",
      "197/197 [==============================] - 23s 118ms/step - loss: 3.1947 - root_mean_squared_error: 1.7874 - val_loss: 2.6123 - val_root_mean_squared_error: 1.6163\n",
      "Epoch 6/30\n",
      "197/197 [==============================] - 39s 196ms/step - loss: 3.1417 - root_mean_squared_error: 1.7725 - val_loss: 2.6877 - val_root_mean_squared_error: 1.6394\n",
      "Epoch 7/30\n",
      "197/197 [==============================] - 39s 199ms/step - loss: 3.1357 - root_mean_squared_error: 1.7708 - val_loss: 2.6732 - val_root_mean_squared_error: 1.6350\n",
      "Epoch 8/30\n",
      "197/197 [==============================] - 38s 195ms/step - loss: 3.0989 - root_mean_squared_error: 1.7604 - val_loss: 2.6810 - val_root_mean_squared_error: 1.6374\n",
      "Epoch 9/30\n",
      "197/197 [==============================] - 38s 191ms/step - loss: 3.0877 - root_mean_squared_error: 1.7572 - val_loss: 2.7718 - val_root_mean_squared_error: 1.6649\n",
      "Epoch 10/30\n",
      "197/197 [==============================] - 39s 196ms/step - loss: 3.0822 - root_mean_squared_error: 1.7556 - val_loss: 2.5802 - val_root_mean_squared_error: 1.6063\n",
      "Epoch 11/30\n",
      "197/197 [==============================] - 41s 210ms/step - loss: 3.0584 - root_mean_squared_error: 1.7488 - val_loss: 2.5716 - val_root_mean_squared_error: 1.6036\n",
      "Epoch 12/30\n",
      "197/197 [==============================] - 38s 191ms/step - loss: 3.0378 - root_mean_squared_error: 1.7429 - val_loss: 2.8044 - val_root_mean_squared_error: 1.6746\n",
      "Epoch 13/30\n",
      "197/197 [==============================] - 1990s 10s/step - loss: 3.0365 - root_mean_squared_error: 1.7426 - val_loss: 2.5932 - val_root_mean_squared_error: 1.6104\n",
      "Epoch 14/30\n",
      "197/197 [==============================] - 49s 249ms/step - loss: 3.0249 - root_mean_squared_error: 1.7392 - val_loss: 2.6699 - val_root_mean_squared_error: 1.6340\n",
      "Epoch 15/30\n",
      "197/197 [==============================] - 28s 144ms/step - loss: 3.0226 - root_mean_squared_error: 1.7386 - val_loss: 2.5766 - val_root_mean_squared_error: 1.6052\n",
      "Epoch 16/30\n",
      "197/197 [==============================] - 26s 134ms/step - loss: 3.0122 - root_mean_squared_error: 1.7356 - val_loss: 2.6405 - val_root_mean_squared_error: 1.6249\n",
      "Epoch 17/30\n",
      "197/197 [==============================] - 26s 131ms/step - loss: 2.9969 - root_mean_squared_error: 1.7311 - val_loss: 2.5914 - val_root_mean_squared_error: 1.6098\n",
      "Epoch 18/30\n",
      "197/197 [==============================] - 23s 117ms/step - loss: 2.9796 - root_mean_squared_error: 1.7262 - val_loss: 2.5890 - val_root_mean_squared_error: 1.6090\n",
      "Epoch 19/30\n",
      "197/197 [==============================] - 23s 117ms/step - loss: 2.9902 - root_mean_squared_error: 1.7292 - val_loss: 2.6756 - val_root_mean_squared_error: 1.6357\n",
      "Epoch 20/30\n",
      "197/197 [==============================] - 23s 117ms/step - loss: 2.9953 - root_mean_squared_error: 1.7307 - val_loss: 2.5641 - val_root_mean_squared_error: 1.6013\n",
      "Epoch 21/30\n",
      "197/197 [==============================] - 23s 118ms/step - loss: 3.0032 - root_mean_squared_error: 1.7330 - val_loss: 2.5792 - val_root_mean_squared_error: 1.6060\n",
      "Epoch 22/30\n",
      "197/197 [==============================] - 23s 117ms/step - loss: 2.9712 - root_mean_squared_error: 1.7237 - val_loss: 2.5590 - val_root_mean_squared_error: 1.5997\n",
      "Epoch 23/30\n",
      "197/197 [==============================] - 23s 117ms/step - loss: 2.9892 - root_mean_squared_error: 1.7289 - val_loss: 2.6575 - val_root_mean_squared_error: 1.6302\n",
      "Epoch 24/30\n",
      "197/197 [==============================] - 24s 119ms/step - loss: 2.9819 - root_mean_squared_error: 1.7268 - val_loss: 2.6661 - val_root_mean_squared_error: 1.6328\n",
      "Epoch 25/30\n",
      "197/197 [==============================] - 23s 118ms/step - loss: 2.9468 - root_mean_squared_error: 1.7166 - val_loss: 2.5414 - val_root_mean_squared_error: 1.5942\n",
      "Epoch 26/30\n",
      "197/197 [==============================] - 23s 118ms/step - loss: 2.9464 - root_mean_squared_error: 1.7165 - val_loss: 2.5910 - val_root_mean_squared_error: 1.6097\n",
      "Epoch 27/30\n",
      "197/197 [==============================] - 23s 117ms/step - loss: 2.9458 - root_mean_squared_error: 1.7163 - val_loss: 2.5366 - val_root_mean_squared_error: 1.5927\n",
      "Epoch 28/30\n",
      "197/197 [==============================] - 23s 117ms/step - loss: 2.9466 - root_mean_squared_error: 1.7166 - val_loss: 2.6511 - val_root_mean_squared_error: 1.6282\n",
      "Epoch 29/30\n",
      "197/197 [==============================] - 23s 115ms/step - loss: 2.9426 - root_mean_squared_error: 1.7154 - val_loss: 2.7259 - val_root_mean_squared_error: 1.6510\n",
      "Epoch 30/30\n",
      "197/197 [==============================] - 23s 117ms/step - loss: 2.9478 - root_mean_squared_error: 1.7169 - val_loss: 2.5784 - val_root_mean_squared_error: 1.6057\n",
      "1534/1534 [==============================] - 19s 12ms/step - loss: 2.8059 - root_mean_squared_error: 1.6751\n",
      "\n",
      "training time 3094.266269\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 2.8059093952178955 with RMSE metric of 1.6750849485397339\n",
      "709/709 [==============================] - 10s 14ms/step - loss: 2.4374 - root_mean_squared_error: 1.5612\n",
      "Test set has a loss (MSE) of 2.4374005794525146 with RMSE metric of 1.5612176656723022\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "136/136 [==============================] - 20s 128ms/step - loss: 11.1276 - root_mean_squared_error: 3.3358 - val_loss: 3.0926 - val_root_mean_squared_error: 1.7586\n",
      "Epoch 2/30\n",
      "136/136 [==============================] - 18s 130ms/step - loss: 2.8399 - root_mean_squared_error: 1.6852 - val_loss: 2.6166 - val_root_mean_squared_error: 1.6176\n",
      "Epoch 3/30\n",
      "136/136 [==============================] - 18s 129ms/step - loss: 2.7169 - root_mean_squared_error: 1.6483 - val_loss: 2.5389 - val_root_mean_squared_error: 1.5934\n",
      "Epoch 4/30\n",
      "136/136 [==============================] - 18s 129ms/step - loss: 2.5961 - root_mean_squared_error: 1.6112 - val_loss: 2.5110 - val_root_mean_squared_error: 1.5846\n",
      "Epoch 5/30\n",
      "136/136 [==============================] - 17s 128ms/step - loss: 2.5550 - root_mean_squared_error: 1.5984 - val_loss: 2.4672 - val_root_mean_squared_error: 1.5707\n",
      "Epoch 6/30\n",
      "136/136 [==============================] - 18s 130ms/step - loss: 2.5748 - root_mean_squared_error: 1.6046 - val_loss: 2.5293 - val_root_mean_squared_error: 1.5904\n",
      "Epoch 7/30\n",
      "136/136 [==============================] - 18s 134ms/step - loss: 2.5426 - root_mean_squared_error: 1.5946 - val_loss: 2.5402 - val_root_mean_squared_error: 1.5938\n",
      "Epoch 8/30\n",
      "136/136 [==============================] - 18s 129ms/step - loss: 2.4972 - root_mean_squared_error: 1.5803 - val_loss: 2.5195 - val_root_mean_squared_error: 1.5873\n",
      "Epoch 9/30\n",
      "136/136 [==============================] - 18s 129ms/step - loss: 2.4836 - root_mean_squared_error: 1.5759 - val_loss: 2.5682 - val_root_mean_squared_error: 1.6025\n",
      "Epoch 10/30\n",
      "136/136 [==============================] - 17s 128ms/step - loss: 2.4686 - root_mean_squared_error: 1.5712 - val_loss: 2.5565 - val_root_mean_squared_error: 1.5989\n",
      "Epoch 11/30\n",
      "136/136 [==============================] - 17s 128ms/step - loss: 2.4676 - root_mean_squared_error: 1.5708 - val_loss: 2.4438 - val_root_mean_squared_error: 1.5633\n",
      "Epoch 12/30\n",
      "136/136 [==============================] - 17s 127ms/step - loss: 2.4383 - root_mean_squared_error: 1.5615 - val_loss: 2.4973 - val_root_mean_squared_error: 1.5803\n",
      "Epoch 13/30\n",
      "136/136 [==============================] - 18s 131ms/step - loss: 2.4644 - root_mean_squared_error: 1.5698 - val_loss: 2.4237 - val_root_mean_squared_error: 1.5568\n",
      "Epoch 14/30\n",
      "136/136 [==============================] - 18s 130ms/step - loss: 2.4297 - root_mean_squared_error: 1.5587 - val_loss: 2.4320 - val_root_mean_squared_error: 1.5595\n",
      "Epoch 15/30\n",
      "136/136 [==============================] - 18s 130ms/step - loss: 2.4229 - root_mean_squared_error: 1.5566 - val_loss: 2.4150 - val_root_mean_squared_error: 1.5540\n",
      "Epoch 16/30\n",
      "136/136 [==============================] - 19s 140ms/step - loss: 2.4588 - root_mean_squared_error: 1.5681 - val_loss: 2.4446 - val_root_mean_squared_error: 1.5635\n",
      "Epoch 17/30\n",
      "136/136 [==============================] - 19s 143ms/step - loss: 2.4146 - root_mean_squared_error: 1.5539 - val_loss: 2.4817 - val_root_mean_squared_error: 1.5753\n",
      "Epoch 18/30\n",
      "136/136 [==============================] - 20s 150ms/step - loss: 2.4227 - root_mean_squared_error: 1.5565 - val_loss: 2.5125 - val_root_mean_squared_error: 1.5851\n",
      "Epoch 19/30\n",
      "136/136 [==============================] - 20s 148ms/step - loss: 2.4283 - root_mean_squared_error: 1.5583 - val_loss: 2.3938 - val_root_mean_squared_error: 1.5472\n",
      "Epoch 20/30\n",
      "136/136 [==============================] - 20s 146ms/step - loss: 2.4293 - root_mean_squared_error: 1.5586 - val_loss: 2.4019 - val_root_mean_squared_error: 1.5498\n",
      "Epoch 21/30\n",
      "136/136 [==============================] - 19s 137ms/step - loss: 2.3869 - root_mean_squared_error: 1.5450 - val_loss: 2.3961 - val_root_mean_squared_error: 1.5479\n",
      "Epoch 22/30\n",
      "136/136 [==============================] - 18s 135ms/step - loss: 2.3971 - root_mean_squared_error: 1.5483 - val_loss: 2.4234 - val_root_mean_squared_error: 1.5567\n",
      "Epoch 23/30\n",
      "136/136 [==============================] - 19s 141ms/step - loss: 2.3880 - root_mean_squared_error: 1.5453 - val_loss: 2.4115 - val_root_mean_squared_error: 1.5529\n",
      "Epoch 24/30\n",
      "136/136 [==============================] - 18s 133ms/step - loss: 2.3931 - root_mean_squared_error: 1.5470 - val_loss: 2.4253 - val_root_mean_squared_error: 1.5573\n",
      "Epoch 25/30\n",
      "136/136 [==============================] - 18s 130ms/step - loss: 2.3713 - root_mean_squared_error: 1.5399 - val_loss: 2.3940 - val_root_mean_squared_error: 1.5473\n",
      "Epoch 26/30\n",
      "136/136 [==============================] - 18s 129ms/step - loss: 2.3818 - root_mean_squared_error: 1.5433 - val_loss: 2.4352 - val_root_mean_squared_error: 1.5605\n",
      "Epoch 27/30\n",
      "136/136 [==============================] - 17s 129ms/step - loss: 2.3787 - root_mean_squared_error: 1.5423 - val_loss: 2.4101 - val_root_mean_squared_error: 1.5525\n",
      "Epoch 28/30\n",
      "136/136 [==============================] - 18s 129ms/step - loss: 2.3741 - root_mean_squared_error: 1.5408 - val_loss: 2.3927 - val_root_mean_squared_error: 1.5468\n",
      "Epoch 29/30\n",
      "136/136 [==============================] - 19s 143ms/step - loss: 2.3418 - root_mean_squared_error: 1.5303 - val_loss: 2.4116 - val_root_mean_squared_error: 1.5529\n",
      "Epoch 30/30\n",
      "136/136 [==============================] - 17s 128ms/step - loss: 2.3771 - root_mean_squared_error: 1.5418 - val_loss: 2.4441 - val_root_mean_squared_error: 1.5634\n",
      "1059/1059 [==============================] - 14s 14ms/step - loss: 2.3632 - root_mean_squared_error: 1.5373\n",
      "\n",
      "training time 560.98188\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 2.363204002380371 with RMSE metric of 1.5372716188430786\n",
      "414/414 [==============================] - 6s 14ms/step - loss: 2.4604 - root_mean_squared_error: 1.5686\n",
      "Test set has a loss (MSE) of 2.4604203701019287 with RMSE metric of 1.568572759628296\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "118/118 [==============================] - 19s 140ms/step - loss: 13.6065 - root_mean_squared_error: 3.6887 - val_loss: 6.0073 - val_root_mean_squared_error: 2.4510\n",
      "Epoch 2/30\n",
      "118/118 [==============================] - 16s 137ms/step - loss: 4.3972 - root_mean_squared_error: 2.0969 - val_loss: 5.1082 - val_root_mean_squared_error: 2.2601\n",
      "Epoch 3/30\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 4.1837 - root_mean_squared_error: 2.0454 - val_loss: 4.9600 - val_root_mean_squared_error: 2.2271\n",
      "Epoch 4/30\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 4.0890 - root_mean_squared_error: 2.0221 - val_loss: 4.8924 - val_root_mean_squared_error: 2.2119\n",
      "Epoch 5/30\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 3.9702 - root_mean_squared_error: 1.9925 - val_loss: 4.8984 - val_root_mean_squared_error: 2.2132\n",
      "Epoch 6/30\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 3.8865 - root_mean_squared_error: 1.9714 - val_loss: 4.9056 - val_root_mean_squared_error: 2.2148\n",
      "Epoch 7/30\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 3.8426 - root_mean_squared_error: 1.9603 - val_loss: 4.7241 - val_root_mean_squared_error: 2.1735\n",
      "Epoch 8/30\n",
      "118/118 [==============================] - 16s 132ms/step - loss: 3.7861 - root_mean_squared_error: 1.9458 - val_loss: 4.7277 - val_root_mean_squared_error: 2.1743\n",
      "Epoch 9/30\n",
      "118/118 [==============================] - 16s 132ms/step - loss: 3.7601 - root_mean_squared_error: 1.9391 - val_loss: 4.8023 - val_root_mean_squared_error: 2.1914\n",
      "Epoch 10/30\n",
      "118/118 [==============================] - 17s 140ms/step - loss: 3.7691 - root_mean_squared_error: 1.9414 - val_loss: 4.9013 - val_root_mean_squared_error: 2.2139\n",
      "Epoch 11/30\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 3.7408 - root_mean_squared_error: 1.9341 - val_loss: 4.7229 - val_root_mean_squared_error: 2.1732\n",
      "Epoch 12/30\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 3.7055 - root_mean_squared_error: 1.9250 - val_loss: 4.6636 - val_root_mean_squared_error: 2.1595\n",
      "Epoch 13/30\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 3.6868 - root_mean_squared_error: 1.9201 - val_loss: 4.7142 - val_root_mean_squared_error: 2.1712\n",
      "Epoch 14/30\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 3.6623 - root_mean_squared_error: 1.9137 - val_loss: 4.6053 - val_root_mean_squared_error: 2.1460\n",
      "Epoch 15/30\n",
      "118/118 [==============================] - 16s 132ms/step - loss: 3.6848 - root_mean_squared_error: 1.9196 - val_loss: 4.7287 - val_root_mean_squared_error: 2.1745\n",
      "Epoch 16/30\n",
      "118/118 [==============================] - 16s 131ms/step - loss: 3.6703 - root_mean_squared_error: 1.9158 - val_loss: 4.8385 - val_root_mean_squared_error: 2.1997\n",
      "Epoch 17/30\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 3.6834 - root_mean_squared_error: 1.9192 - val_loss: 4.6962 - val_root_mean_squared_error: 2.1671\n",
      "Epoch 18/30\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 3.6452 - root_mean_squared_error: 1.9092 - val_loss: 4.6725 - val_root_mean_squared_error: 2.1616\n",
      "Epoch 19/30\n",
      "118/118 [==============================] - 16s 132ms/step - loss: 3.6666 - root_mean_squared_error: 1.9148 - val_loss: 4.7657 - val_root_mean_squared_error: 2.1830\n",
      "Epoch 20/30\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 3.6131 - root_mean_squared_error: 1.9008 - val_loss: 4.7304 - val_root_mean_squared_error: 2.1750\n",
      "Epoch 21/30\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 3.6245 - root_mean_squared_error: 1.9038 - val_loss: 4.7465 - val_root_mean_squared_error: 2.1786\n",
      "Epoch 22/30\n",
      "118/118 [==============================] - 15s 128ms/step - loss: 3.6251 - root_mean_squared_error: 1.9040 - val_loss: 4.7524 - val_root_mean_squared_error: 2.1800\n",
      "Epoch 23/30\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 3.6063 - root_mean_squared_error: 1.8990 - val_loss: 4.6943 - val_root_mean_squared_error: 2.1666\n",
      "Epoch 24/30\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 3.6329 - root_mean_squared_error: 1.9060 - val_loss: 4.7995 - val_root_mean_squared_error: 2.1908\n",
      "Epoch 25/30\n",
      "118/118 [==============================] - 15s 128ms/step - loss: 3.6231 - root_mean_squared_error: 1.9035 - val_loss: 4.6630 - val_root_mean_squared_error: 2.1594\n",
      "Epoch 26/30\n",
      "118/118 [==============================] - 15s 127ms/step - loss: 3.6098 - root_mean_squared_error: 1.9000 - val_loss: 4.8214 - val_root_mean_squared_error: 2.1958\n",
      "Epoch 27/30\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 3.6097 - root_mean_squared_error: 1.8999 - val_loss: 4.9050 - val_root_mean_squared_error: 2.2147\n",
      "Epoch 28/30\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 3.6295 - root_mean_squared_error: 1.9051 - val_loss: 4.6309 - val_root_mean_squared_error: 2.1520\n",
      "Epoch 29/30\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 3.6254 - root_mean_squared_error: 1.9041 - val_loss: 4.6863 - val_root_mean_squared_error: 2.1648\n",
      "Epoch 30/30\n",
      "118/118 [==============================] - 16s 139ms/step - loss: 3.5968 - root_mean_squared_error: 1.8965 - val_loss: 4.7117 - val_root_mean_squared_error: 2.1706\n",
      "916/916 [==============================] - 12s 13ms/step - loss: 3.7340 - root_mean_squared_error: 1.9324\n",
      "\n",
      "training time 479.59639\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 3.734018564224243 with RMSE metric of 1.9323608875274658\n",
      "480/480 [==============================] - 6s 13ms/step - loss: 3.7665 - root_mean_squared_error: 1.9408\n",
      "Test set has a loss (MSE) of 3.766517400741577 with RMSE metric of 1.9407517910003662\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "98/98 [==============================] - 15s 128ms/step - loss: 21.5501 - root_mean_squared_error: 4.6422 - val_loss: 3.5428 - val_root_mean_squared_error: 1.8822\n",
      "Epoch 2/30\n",
      "98/98 [==============================] - 13s 130ms/step - loss: 4.0827 - root_mean_squared_error: 2.0206 - val_loss: 2.8549 - val_root_mean_squared_error: 1.6897\n",
      "Epoch 3/30\n",
      "98/98 [==============================] - 13s 128ms/step - loss: 3.7314 - root_mean_squared_error: 1.9317 - val_loss: 2.6513 - val_root_mean_squared_error: 1.6283\n",
      "Epoch 4/30\n",
      "98/98 [==============================] - 13s 129ms/step - loss: 3.6498 - root_mean_squared_error: 1.9105 - val_loss: 2.6755 - val_root_mean_squared_error: 1.6357\n",
      "Epoch 5/30\n",
      "98/98 [==============================] - 13s 129ms/step - loss: 3.5153 - root_mean_squared_error: 1.8749 - val_loss: 2.6054 - val_root_mean_squared_error: 1.6141\n",
      "Epoch 6/30\n",
      "98/98 [==============================] - 12s 126ms/step - loss: 3.5420 - root_mean_squared_error: 1.8820 - val_loss: 2.6098 - val_root_mean_squared_error: 1.6155\n",
      "Epoch 7/30\n",
      "98/98 [==============================] - 12s 127ms/step - loss: 3.4248 - root_mean_squared_error: 1.8506 - val_loss: 2.5154 - val_root_mean_squared_error: 1.5860\n",
      "Epoch 8/30\n",
      "98/98 [==============================] - 12s 127ms/step - loss: 3.4052 - root_mean_squared_error: 1.8453 - val_loss: 2.6058 - val_root_mean_squared_error: 1.6143\n",
      "Epoch 9/30\n",
      "98/98 [==============================] - 13s 131ms/step - loss: 3.3499 - root_mean_squared_error: 1.8303 - val_loss: 2.5246 - val_root_mean_squared_error: 1.5889\n",
      "Epoch 10/30\n",
      "98/98 [==============================] - 13s 129ms/step - loss: 3.3234 - root_mean_squared_error: 1.8230 - val_loss: 2.4908 - val_root_mean_squared_error: 1.5782\n",
      "Epoch 11/30\n",
      "98/98 [==============================] - 13s 129ms/step - loss: 3.3151 - root_mean_squared_error: 1.8207 - val_loss: 2.5225 - val_root_mean_squared_error: 1.5882\n",
      "Epoch 12/30\n",
      "98/98 [==============================] - 13s 134ms/step - loss: 3.3504 - root_mean_squared_error: 1.8304 - val_loss: 2.6031 - val_root_mean_squared_error: 1.6134\n",
      "Epoch 13/30\n",
      "98/98 [==============================] - 15s 151ms/step - loss: 3.3311 - root_mean_squared_error: 1.8251 - val_loss: 2.6359 - val_root_mean_squared_error: 1.6235\n",
      "Epoch 14/30\n",
      "98/98 [==============================] - 15s 149ms/step - loss: 3.2964 - root_mean_squared_error: 1.8156 - val_loss: 2.6495 - val_root_mean_squared_error: 1.6277\n",
      "Epoch 15/30\n",
      "98/98 [==============================] - 15s 151ms/step - loss: 3.3212 - root_mean_squared_error: 1.8224 - val_loss: 2.4859 - val_root_mean_squared_error: 1.5767\n",
      "Epoch 16/30\n",
      "98/98 [==============================] - 15s 149ms/step - loss: 3.2730 - root_mean_squared_error: 1.8091 - val_loss: 2.5124 - val_root_mean_squared_error: 1.5851\n",
      "Epoch 17/30\n",
      "98/98 [==============================] - 14s 143ms/step - loss: 3.2593 - root_mean_squared_error: 1.8054 - val_loss: 2.4563 - val_root_mean_squared_error: 1.5673\n",
      "Epoch 18/30\n",
      "98/98 [==============================] - 15s 149ms/step - loss: 3.2741 - root_mean_squared_error: 1.8095 - val_loss: 2.4840 - val_root_mean_squared_error: 1.5761\n",
      "Epoch 19/30\n",
      "98/98 [==============================] - 15s 151ms/step - loss: 3.2443 - root_mean_squared_error: 1.8012 - val_loss: 2.4303 - val_root_mean_squared_error: 1.5589\n",
      "Epoch 20/30\n",
      "98/98 [==============================] - 18s 180ms/step - loss: 3.3048 - root_mean_squared_error: 1.8179 - val_loss: 2.4718 - val_root_mean_squared_error: 1.5722\n",
      "Epoch 21/30\n",
      "98/98 [==============================] - 15s 150ms/step - loss: 3.2368 - root_mean_squared_error: 1.7991 - val_loss: 2.5128 - val_root_mean_squared_error: 1.5852\n",
      "Epoch 22/30\n",
      "98/98 [==============================] - 15s 149ms/step - loss: 3.2800 - root_mean_squared_error: 1.8111 - val_loss: 2.4384 - val_root_mean_squared_error: 1.5615\n",
      "Epoch 23/30\n",
      "98/98 [==============================] - 14s 139ms/step - loss: 3.2418 - root_mean_squared_error: 1.8005 - val_loss: 2.6461 - val_root_mean_squared_error: 1.6267\n",
      "Epoch 24/30\n",
      "98/98 [==============================] - 15s 150ms/step - loss: 3.2323 - root_mean_squared_error: 1.7979 - val_loss: 2.4621 - val_root_mean_squared_error: 1.5691\n",
      "Epoch 25/30\n",
      "98/98 [==============================] - 15s 151ms/step - loss: 3.2106 - root_mean_squared_error: 1.7918 - val_loss: 2.4558 - val_root_mean_squared_error: 1.5671\n",
      "Epoch 26/30\n",
      "98/98 [==============================] - 15s 151ms/step - loss: 3.2457 - root_mean_squared_error: 1.8016 - val_loss: 2.4530 - val_root_mean_squared_error: 1.5662\n",
      "Epoch 27/30\n",
      "98/98 [==============================] - 15s 152ms/step - loss: 3.1929 - root_mean_squared_error: 1.7869 - val_loss: 2.4740 - val_root_mean_squared_error: 1.5729\n",
      "Epoch 28/30\n",
      "98/98 [==============================] - 14s 144ms/step - loss: 3.2226 - root_mean_squared_error: 1.7952 - val_loss: 2.4889 - val_root_mean_squared_error: 1.5776\n",
      "Epoch 29/30\n",
      "98/98 [==============================] - 15s 150ms/step - loss: 3.1848 - root_mean_squared_error: 1.7846 - val_loss: 2.4635 - val_root_mean_squared_error: 1.5695\n",
      "Epoch 30/30\n",
      "98/98 [==============================] - 14s 147ms/step - loss: 3.1664 - root_mean_squared_error: 1.7794 - val_loss: 2.4631 - val_root_mean_squared_error: 1.5694\n",
      "764/764 [==============================] - 10s 13ms/step - loss: 2.9902 - root_mean_squared_error: 1.7292\n",
      "\n",
      "training time 428.434692\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 2.9902431964874268 with RMSE metric of 1.7292319536209106\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 3.4460 - root_mean_squared_error: 1.8563\n",
      "Test set has a loss (MSE) of 3.445967197418213 with RMSE metric of 1.856331706047058\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "257/257 [==============================] - 42s 154ms/step - loss: 6.6476 - root_mean_squared_error: 2.5783 - val_loss: 3.1393 - val_root_mean_squared_error: 1.7718\n",
      "Epoch 2/30\n",
      "257/257 [==============================] - 38s 146ms/step - loss: 2.9046 - root_mean_squared_error: 1.7043 - val_loss: 3.1292 - val_root_mean_squared_error: 1.7690\n",
      "Epoch 3/30\n",
      "257/257 [==============================] - 38s 148ms/step - loss: 2.7563 - root_mean_squared_error: 1.6602 - val_loss: 2.8629 - val_root_mean_squared_error: 1.6920\n",
      "Epoch 4/30\n",
      "257/257 [==============================] - 39s 151ms/step - loss: 2.6838 - root_mean_squared_error: 1.6382 - val_loss: 2.8360 - val_root_mean_squared_error: 1.6840\n",
      "Epoch 5/30\n",
      "257/257 [==============================] - 38s 146ms/step - loss: 2.6524 - root_mean_squared_error: 1.6286 - val_loss: 3.0737 - val_root_mean_squared_error: 1.7532\n",
      "Epoch 6/30\n",
      "257/257 [==============================] - 40s 154ms/step - loss: 2.6378 - root_mean_squared_error: 1.6241 - val_loss: 2.7784 - val_root_mean_squared_error: 1.6668\n",
      "Epoch 7/30\n",
      "257/257 [==============================] - 38s 150ms/step - loss: 2.5998 - root_mean_squared_error: 1.6124 - val_loss: 2.7806 - val_root_mean_squared_error: 1.6675\n",
      "Epoch 8/30\n",
      "257/257 [==============================] - 38s 148ms/step - loss: 2.5885 - root_mean_squared_error: 1.6089 - val_loss: 2.7578 - val_root_mean_squared_error: 1.6607\n",
      "Epoch 9/30\n",
      "257/257 [==============================] - 39s 152ms/step - loss: 2.5918 - root_mean_squared_error: 1.6099 - val_loss: 2.7207 - val_root_mean_squared_error: 1.6494\n",
      "Epoch 10/30\n",
      "257/257 [==============================] - 39s 152ms/step - loss: 2.5712 - root_mean_squared_error: 1.6035 - val_loss: 2.6967 - val_root_mean_squared_error: 1.6422\n",
      "Epoch 11/30\n",
      "257/257 [==============================] - 40s 154ms/step - loss: 2.5653 - root_mean_squared_error: 1.6016 - val_loss: 2.6790 - val_root_mean_squared_error: 1.6368\n",
      "Epoch 12/30\n",
      "257/257 [==============================] - 37s 143ms/step - loss: 2.5320 - root_mean_squared_error: 1.5912 - val_loss: 2.8143 - val_root_mean_squared_error: 1.6776\n",
      "Epoch 13/30\n",
      "257/257 [==============================] - 39s 151ms/step - loss: 2.5344 - root_mean_squared_error: 1.5920 - val_loss: 2.6994 - val_root_mean_squared_error: 1.6430\n",
      "Epoch 14/30\n",
      "257/257 [==============================] - 38s 150ms/step - loss: 2.5335 - root_mean_squared_error: 1.5917 - val_loss: 2.7132 - val_root_mean_squared_error: 1.6472\n",
      "Epoch 15/30\n",
      "257/257 [==============================] - 38s 148ms/step - loss: 2.5266 - root_mean_squared_error: 1.5895 - val_loss: 2.6792 - val_root_mean_squared_error: 1.6368\n",
      "Epoch 16/30\n",
      "257/257 [==============================] - 38s 149ms/step - loss: 2.5177 - root_mean_squared_error: 1.5867 - val_loss: 2.7223 - val_root_mean_squared_error: 1.6499\n",
      "Epoch 17/30\n",
      "257/257 [==============================] - 39s 152ms/step - loss: 2.5107 - root_mean_squared_error: 1.5845 - val_loss: 2.7859 - val_root_mean_squared_error: 1.6691\n",
      "Epoch 18/30\n",
      "257/257 [==============================] - 37s 145ms/step - loss: 2.5160 - root_mean_squared_error: 1.5862 - val_loss: 2.6873 - val_root_mean_squared_error: 1.6393\n",
      "Epoch 19/30\n",
      "257/257 [==============================] - 39s 153ms/step - loss: 2.5135 - root_mean_squared_error: 1.5854 - val_loss: 2.6527 - val_root_mean_squared_error: 1.6287\n",
      "Epoch 20/30\n",
      "257/257 [==============================] - 38s 149ms/step - loss: 2.5067 - root_mean_squared_error: 1.5833 - val_loss: 2.6292 - val_root_mean_squared_error: 1.6215\n",
      "Epoch 21/30\n",
      "257/257 [==============================] - 38s 149ms/step - loss: 2.5099 - root_mean_squared_error: 1.5843 - val_loss: 2.7165 - val_root_mean_squared_error: 1.6482\n",
      "Epoch 22/30\n",
      "257/257 [==============================] - 38s 149ms/step - loss: 2.5029 - root_mean_squared_error: 1.5821 - val_loss: 2.6553 - val_root_mean_squared_error: 1.6295\n",
      "Epoch 23/30\n",
      "257/257 [==============================] - 39s 151ms/step - loss: 2.5032 - root_mean_squared_error: 1.5822 - val_loss: 2.6727 - val_root_mean_squared_error: 1.6348\n",
      "Epoch 24/30\n",
      "257/257 [==============================] - 39s 151ms/step - loss: 2.5034 - root_mean_squared_error: 1.5822 - val_loss: 2.6554 - val_root_mean_squared_error: 1.6295\n",
      "Epoch 25/30\n",
      "257/257 [==============================] - 38s 147ms/step - loss: 2.4919 - root_mean_squared_error: 1.5786 - val_loss: 2.7671 - val_root_mean_squared_error: 1.6635\n",
      "Epoch 26/30\n",
      "257/257 [==============================] - 39s 151ms/step - loss: 2.4865 - root_mean_squared_error: 1.5769 - val_loss: 2.6464 - val_root_mean_squared_error: 1.6268\n",
      "Epoch 27/30\n",
      "257/257 [==============================] - 40s 155ms/step - loss: 2.4799 - root_mean_squared_error: 1.5748 - val_loss: 2.6473 - val_root_mean_squared_error: 1.6271\n",
      "Epoch 28/30\n",
      "257/257 [==============================] - 37s 143ms/step - loss: 2.4782 - root_mean_squared_error: 1.5742 - val_loss: 2.6384 - val_root_mean_squared_error: 1.6243\n",
      "Epoch 29/30\n",
      "257/257 [==============================] - 39s 150ms/step - loss: 2.4765 - root_mean_squared_error: 1.5737 - val_loss: 2.6795 - val_root_mean_squared_error: 1.6369\n",
      "Epoch 30/30\n",
      "257/257 [==============================] - 39s 152ms/step - loss: 2.4846 - root_mean_squared_error: 1.5763 - val_loss: 2.7049 - val_root_mean_squared_error: 1.6446\n",
      "2007/2007 [==============================] - 27s 13ms/step - loss: 2.4900 - root_mean_squared_error: 1.5780\n",
      "\n",
      "training time 1183.38498\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 2.489992618560791 with RMSE metric of 1.57797110080719\n",
      "873/873 [==============================] - 12s 13ms/step - loss: 2.6442 - root_mean_squared_error: 1.6261\n",
      "Test set has a loss (MSE) of 2.644235134124756 with RMSE metric of 1.6261104345321655\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/30\n",
      "55/55 [==============================] - 11s 163ms/step - loss: 30.8158 - root_mean_squared_error: 5.5512 - val_loss: 5.4247 - val_root_mean_squared_error: 2.3291\n",
      "Epoch 2/30\n",
      "55/55 [==============================] - 9s 157ms/step - loss: 3.9468 - root_mean_squared_error: 1.9866 - val_loss: 4.0627 - val_root_mean_squared_error: 2.0156\n",
      "Epoch 3/30\n",
      "55/55 [==============================] - 8s 149ms/step - loss: 3.4147 - root_mean_squared_error: 1.8479 - val_loss: 3.7188 - val_root_mean_squared_error: 1.9284\n",
      "Epoch 4/30\n",
      "55/55 [==============================] - 8s 152ms/step - loss: 3.1899 - root_mean_squared_error: 1.7860 - val_loss: 3.4584 - val_root_mean_squared_error: 1.8597\n",
      "Epoch 5/30\n",
      "55/55 [==============================] - 8s 152ms/step - loss: 2.9842 - root_mean_squared_error: 1.7275 - val_loss: 3.2218 - val_root_mean_squared_error: 1.7949\n",
      "Epoch 6/30\n",
      "55/55 [==============================] - 8s 154ms/step - loss: 2.8881 - root_mean_squared_error: 1.6994 - val_loss: 3.1275 - val_root_mean_squared_error: 1.7685\n",
      "Epoch 7/30\n",
      "55/55 [==============================] - 8s 146ms/step - loss: 2.8312 - root_mean_squared_error: 1.6826 - val_loss: 3.0947 - val_root_mean_squared_error: 1.7592\n",
      "Epoch 8/30\n",
      "55/55 [==============================] - 9s 161ms/step - loss: 2.7937 - root_mean_squared_error: 1.6714 - val_loss: 3.2312 - val_root_mean_squared_error: 1.7976\n",
      "Epoch 9/30\n",
      "55/55 [==============================] - 8s 141ms/step - loss: 2.8584 - root_mean_squared_error: 1.6907 - val_loss: 3.0259 - val_root_mean_squared_error: 1.7395\n",
      "Epoch 10/30\n",
      "55/55 [==============================] - 8s 148ms/step - loss: 2.6973 - root_mean_squared_error: 1.6424 - val_loss: 2.9757 - val_root_mean_squared_error: 1.7250\n",
      "Epoch 11/30\n",
      "55/55 [==============================] - 8s 150ms/step - loss: 2.6521 - root_mean_squared_error: 1.6285 - val_loss: 2.9489 - val_root_mean_squared_error: 1.7172\n",
      "Epoch 12/30\n",
      "55/55 [==============================] - 8s 141ms/step - loss: 2.6353 - root_mean_squared_error: 1.6234 - val_loss: 3.0202 - val_root_mean_squared_error: 1.7379\n",
      "Epoch 13/30\n",
      "55/55 [==============================] - 8s 153ms/step - loss: 2.6650 - root_mean_squared_error: 1.6325 - val_loss: 3.0908 - val_root_mean_squared_error: 1.7581\n",
      "Epoch 14/30\n",
      "55/55 [==============================] - 8s 148ms/step - loss: 2.6098 - root_mean_squared_error: 1.6155 - val_loss: 2.9663 - val_root_mean_squared_error: 1.7223\n",
      "Epoch 15/30\n",
      "55/55 [==============================] - 8s 145ms/step - loss: 2.5471 - root_mean_squared_error: 1.5960 - val_loss: 2.8786 - val_root_mean_squared_error: 1.6966\n",
      "Epoch 16/30\n",
      "55/55 [==============================] - 8s 152ms/step - loss: 2.5429 - root_mean_squared_error: 1.5946 - val_loss: 2.8622 - val_root_mean_squared_error: 1.6918\n",
      "Epoch 17/30\n",
      "55/55 [==============================] - 8s 144ms/step - loss: 2.6405 - root_mean_squared_error: 1.6250 - val_loss: 2.8475 - val_root_mean_squared_error: 1.6875\n",
      "Epoch 18/30\n",
      "55/55 [==============================] - 8s 145ms/step - loss: 2.5332 - root_mean_squared_error: 1.5916 - val_loss: 2.9247 - val_root_mean_squared_error: 1.7102\n",
      "Epoch 19/30\n",
      "55/55 [==============================] - 7s 135ms/step - loss: 2.5434 - root_mean_squared_error: 1.5948 - val_loss: 2.8998 - val_root_mean_squared_error: 1.7029\n",
      "Epoch 20/30\n",
      "55/55 [==============================] - 8s 146ms/step - loss: 2.5008 - root_mean_squared_error: 1.5814 - val_loss: 2.8063 - val_root_mean_squared_error: 1.6752\n",
      "Epoch 21/30\n",
      "55/55 [==============================] - 9s 158ms/step - loss: 2.4638 - root_mean_squared_error: 1.5697 - val_loss: 2.9227 - val_root_mean_squared_error: 1.7096\n",
      "Epoch 22/30\n",
      "55/55 [==============================] - 8s 141ms/step - loss: 2.4972 - root_mean_squared_error: 1.5803 - val_loss: 2.8021 - val_root_mean_squared_error: 1.6740\n",
      "Epoch 23/30\n",
      "55/55 [==============================] - 9s 156ms/step - loss: 2.4590 - root_mean_squared_error: 1.5681 - val_loss: 2.7799 - val_root_mean_squared_error: 1.6673\n",
      "Epoch 24/30\n",
      "55/55 [==============================] - 9s 158ms/step - loss: 2.4764 - root_mean_squared_error: 1.5737 - val_loss: 2.8046 - val_root_mean_squared_error: 1.6747\n",
      "Epoch 25/30\n",
      "55/55 [==============================] - 8s 138ms/step - loss: 2.4721 - root_mean_squared_error: 1.5723 - val_loss: 2.7869 - val_root_mean_squared_error: 1.6694\n",
      "Epoch 26/30\n",
      "55/55 [==============================] - 8s 147ms/step - loss: 2.4421 - root_mean_squared_error: 1.5627 - val_loss: 2.7942 - val_root_mean_squared_error: 1.6716\n",
      "Epoch 27/30\n",
      "55/55 [==============================] - 9s 159ms/step - loss: 2.4182 - root_mean_squared_error: 1.5551 - val_loss: 2.7683 - val_root_mean_squared_error: 1.6638\n",
      "Epoch 28/30\n",
      "55/55 [==============================] - 8s 143ms/step - loss: 2.4122 - root_mean_squared_error: 1.5531 - val_loss: 2.8041 - val_root_mean_squared_error: 1.6745\n",
      "Epoch 29/30\n",
      "55/55 [==============================] - 8s 154ms/step - loss: 2.4505 - root_mean_squared_error: 1.5654 - val_loss: 2.7319 - val_root_mean_squared_error: 1.6528\n",
      "Epoch 30/30\n",
      "55/55 [==============================] - 8s 154ms/step - loss: 2.4291 - root_mean_squared_error: 1.5586 - val_loss: 2.8697 - val_root_mean_squared_error: 1.6940\n",
      "430/430 [==============================] - 6s 13ms/step - loss: 2.5003 - root_mean_squared_error: 1.5812\n",
      "\n",
      "training time 254.765696\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 2.500314474105835 with RMSE metric of 1.5812382698059082\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 2.1471 - root_mean_squared_error: 1.4653\n",
      "Test set has a loss (MSE) of 2.1470978260040283 with RMSE metric of 1.465297818183899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (10):\n",
    "    ## GRU w Features Model\n",
    "    ## Initialize\n",
    "    model_name = 'GRU - w Features optimized'\n",
    "    num_layers = 4\n",
    "    epochs_num = 30\n",
    "    batch_size_set = 200\n",
    "    optimizer_set = 'adam'\n",
    "    forecast_distance=6\n",
    "    number_readings=8\n",
    "\n",
    "    ## Get New Data\n",
    "    a=DataSampling(path=path)\n",
    "    a.samplingDF\n",
    "    X_train,X_test,y_train,y_test = a.SampleValidSequencesMulti(num_clients=4, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "    #SETUP THE STACK\n",
    "    model_gru = Sequential()\n",
    "    model_gru.add(GRU(150, activation='tanh', input_shape=(number_readings,2), return_sequences=True))\n",
    "    model_gru.add(Dropout(0.1))\n",
    "    model_gru.add(GRU(20, activation='relu'))\n",
    "    model_gru.add(Dense(10))\n",
    "    model_gru.add(Dense(1))\n",
    "\n",
    "\n",
    "    #START THE RUN\n",
    "    print('\\nRunning GRU model...')\n",
    "    start = datetime.now()\n",
    "\n",
    "    model_gru.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    hist = model_gru.fit(X_train, y_train, epochs=epochs_num, validation_split=0.2, batch_size=batch_size_set)\n",
    "    train_loss, train_rmse = model_gru.evaluate(X_train, y_train)\n",
    "    train_time = (datetime.now()-start).total_seconds()\n",
    "    print(\"\\ntraining time %s\" % train_time)\n",
    "\n",
    "    #PRINT RESULTS\n",
    "    print(f'GRU Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "    #Test set results\n",
    "    test_loss, test_rmse = model_gru.evaluate(X_test, y_test)\n",
    "    print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "\n",
    "    #y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "    Execution_time.append(train_time)\n",
    "    train_rmse_results.append(train_rmse)\n",
    "    test_rmse_results.append(test_rmse)\n",
    "    run_id.append(model_name+str(datetime.now()))\n",
    "    sample_size.append(len(X_train))\n",
    "    epochs.append(epochs_num)\n",
    "    batch_size.append(batch_size_set)\n",
    "    optimizer.append(optimizer_set)\n",
    "    layers.append(num_layers)\n",
    "    forecast_distance_perf.append(forecast_distance)\n",
    "    prev_readings.append(number_readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "117/117 [==============================] - 7s 55ms/step - loss: 5.1667 - root_mean_squared_error: 2.2730 - val_loss: 3.7120 - val_root_mean_squared_error: 1.9266\n",
      "Epoch 2/30\n",
      "117/117 [==============================] - 7s 57ms/step - loss: 3.7942 - root_mean_squared_error: 1.9479 - val_loss: 3.7456 - val_root_mean_squared_error: 1.9353\n",
      "Epoch 3/30\n",
      "117/117 [==============================] - 7s 63ms/step - loss: 3.7829 - root_mean_squared_error: 1.9450 - val_loss: 3.8270 - val_root_mean_squared_error: 1.9563\n",
      "Epoch 4/30\n",
      "117/117 [==============================] - 7s 57ms/step - loss: 3.5992 - root_mean_squared_error: 1.8972 - val_loss: 3.9552 - val_root_mean_squared_error: 1.9888\n",
      "Epoch 5/30\n",
      "117/117 [==============================] - 8s 65ms/step - loss: 3.6369 - root_mean_squared_error: 1.9071 - val_loss: 3.5905 - val_root_mean_squared_error: 1.8949\n",
      "Epoch 6/30\n",
      "117/117 [==============================] - 7s 56ms/step - loss: 3.6911 - root_mean_squared_error: 1.9212 - val_loss: 4.2050 - val_root_mean_squared_error: 2.0506\n",
      "Epoch 7/30\n",
      "117/117 [==============================] - 7s 60ms/step - loss: 3.6973 - root_mean_squared_error: 1.9228 - val_loss: 3.5350 - val_root_mean_squared_error: 1.8802\n",
      "Epoch 8/30\n",
      "117/117 [==============================] - 8s 65ms/step - loss: 3.6412 - root_mean_squared_error: 1.9082 - val_loss: 4.1218 - val_root_mean_squared_error: 2.0302\n",
      "Epoch 9/30\n",
      "117/117 [==============================] - 7s 62ms/step - loss: 3.6533 - root_mean_squared_error: 1.9114 - val_loss: 3.8073 - val_root_mean_squared_error: 1.9512\n",
      "Epoch 10/30\n",
      "117/117 [==============================] - 7s 63ms/step - loss: 3.7991 - root_mean_squared_error: 1.9491 - val_loss: 3.5695 - val_root_mean_squared_error: 1.8893\n",
      "Epoch 11/30\n",
      "117/117 [==============================] - 7s 56ms/step - loss: 3.5458 - root_mean_squared_error: 1.8830 - val_loss: 3.5932 - val_root_mean_squared_error: 1.8956\n",
      "Epoch 12/30\n",
      "117/117 [==============================] - 7s 63ms/step - loss: 3.5860 - root_mean_squared_error: 1.8937 - val_loss: 3.6569 - val_root_mean_squared_error: 1.9123\n",
      "Epoch 13/30\n",
      "117/117 [==============================] - 7s 57ms/step - loss: 3.6360 - root_mean_squared_error: 1.9068 - val_loss: 3.5462 - val_root_mean_squared_error: 1.8831\n",
      "Epoch 14/30\n",
      "117/117 [==============================] - 7s 58ms/step - loss: 3.5017 - root_mean_squared_error: 1.8713 - val_loss: 3.7752 - val_root_mean_squared_error: 1.9430\n",
      "Epoch 15/30\n",
      "117/117 [==============================] - 7s 59ms/step - loss: 3.6234 - root_mean_squared_error: 1.9035 - val_loss: 4.1687 - val_root_mean_squared_error: 2.0417\n",
      "Epoch 16/30\n",
      "117/117 [==============================] - 6s 55ms/step - loss: 3.6123 - root_mean_squared_error: 1.9006 - val_loss: 3.6019 - val_root_mean_squared_error: 1.8979\n",
      "Epoch 17/30\n",
      "117/117 [==============================] - 6s 54ms/step - loss: 3.5548 - root_mean_squared_error: 1.8854 - val_loss: 3.5905 - val_root_mean_squared_error: 1.8949\n",
      "Epoch 18/30\n",
      "117/117 [==============================] - 7s 62ms/step - loss: 3.5957 - root_mean_squared_error: 1.8962 - val_loss: 3.7074 - val_root_mean_squared_error: 1.9255\n",
      "Epoch 19/30\n",
      "117/117 [==============================] - 7s 57ms/step - loss: 3.6840 - root_mean_squared_error: 1.9194 - val_loss: 4.0008 - val_root_mean_squared_error: 2.0002\n",
      "Epoch 20/30\n",
      "117/117 [==============================] - 7s 62ms/step - loss: 3.5555 - root_mean_squared_error: 1.8856 - val_loss: 3.4967 - val_root_mean_squared_error: 1.8700\n",
      "Epoch 21/30\n",
      "117/117 [==============================] - 7s 57ms/step - loss: 3.5224 - root_mean_squared_error: 1.8768 - val_loss: 3.7966 - val_root_mean_squared_error: 1.9485\n",
      "Epoch 22/30\n",
      "117/117 [==============================] - 7s 56ms/step - loss: 3.6621 - root_mean_squared_error: 1.9137 - val_loss: 3.5460 - val_root_mean_squared_error: 1.8831\n",
      "Epoch 23/30\n",
      "117/117 [==============================] - 8s 65ms/step - loss: 3.5722 - root_mean_squared_error: 1.8900 - val_loss: 3.6449 - val_root_mean_squared_error: 1.9092\n",
      "Epoch 24/30\n",
      "117/117 [==============================] - 7s 57ms/step - loss: 3.5558 - root_mean_squared_error: 1.8857 - val_loss: 3.7399 - val_root_mean_squared_error: 1.9339\n",
      "Epoch 25/30\n",
      "117/117 [==============================] - 7s 58ms/step - loss: 3.5667 - root_mean_squared_error: 1.8886 - val_loss: 3.6231 - val_root_mean_squared_error: 1.9035\n",
      "Epoch 26/30\n",
      "117/117 [==============================] - 7s 59ms/step - loss: 3.5732 - root_mean_squared_error: 1.8903 - val_loss: 3.5142 - val_root_mean_squared_error: 1.8746\n",
      "Epoch 27/30\n",
      "117/117 [==============================] - 6s 55ms/step - loss: 3.6279 - root_mean_squared_error: 1.9047 - val_loss: 3.6397 - val_root_mean_squared_error: 1.9078\n",
      "Epoch 28/30\n",
      "117/117 [==============================] - 7s 61ms/step - loss: 3.6231 - root_mean_squared_error: 1.9035 - val_loss: 3.4946 - val_root_mean_squared_error: 1.8694\n",
      "Epoch 29/30\n",
      "117/117 [==============================] - 7s 63ms/step - loss: 3.6881 - root_mean_squared_error: 1.9204 - val_loss: 3.7342 - val_root_mean_squared_error: 1.9324\n",
      "Epoch 30/30\n",
      "117/117 [==============================] - 6s 54ms/step - loss: 3.5755 - root_mean_squared_error: 1.8909 - val_loss: 3.8072 - val_root_mean_squared_error: 1.9512\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 3.4874 - root_mean_squared_error: 1.8675\n",
      "\n",
      "training time 210.87241\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 3.487415075302124 with RMSE metric of 1.867462158203125\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 3.5509 - root_mean_squared_error: 1.8844\n",
      "Test set has a loss (MSE) of 3.550861120223999 with RMSE metric of 1.8843728303909302\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "219/219 [==============================] - 14s 63ms/step - loss: 4.5612 - root_mean_squared_error: 2.1357 - val_loss: 3.5120 - val_root_mean_squared_error: 1.8740\n",
      "Epoch 2/30\n",
      "219/219 [==============================] - 13s 57ms/step - loss: 3.2091 - root_mean_squared_error: 1.7914 - val_loss: 3.5914 - val_root_mean_squared_error: 1.8951\n",
      "Epoch 3/30\n",
      "219/219 [==============================] - 14s 63ms/step - loss: 3.1564 - root_mean_squared_error: 1.7766 - val_loss: 3.5827 - val_root_mean_squared_error: 1.8928\n",
      "Epoch 4/30\n",
      "219/219 [==============================] - 13s 61ms/step - loss: 3.2114 - root_mean_squared_error: 1.7921 - val_loss: 3.6372 - val_root_mean_squared_error: 1.9071\n",
      "Epoch 5/30\n",
      "219/219 [==============================] - 13s 59ms/step - loss: 3.1301 - root_mean_squared_error: 1.7692 - val_loss: 3.5867 - val_root_mean_squared_error: 1.8939\n",
      "Epoch 6/30\n",
      "219/219 [==============================] - 13s 60ms/step - loss: 3.1746 - root_mean_squared_error: 1.7817 - val_loss: 3.5639 - val_root_mean_squared_error: 1.8878\n",
      "Epoch 7/30\n",
      "219/219 [==============================] - 13s 60ms/step - loss: 3.0772 - root_mean_squared_error: 1.7542 - val_loss: 3.5621 - val_root_mean_squared_error: 1.8874\n",
      "Epoch 8/30\n",
      "219/219 [==============================] - 13s 60ms/step - loss: 3.1389 - root_mean_squared_error: 1.7717 - val_loss: 3.4012 - val_root_mean_squared_error: 1.8442\n",
      "Epoch 9/30\n",
      "219/219 [==============================] - 13s 61ms/step - loss: 3.1617 - root_mean_squared_error: 1.7781 - val_loss: 3.4946 - val_root_mean_squared_error: 1.8694\n",
      "Epoch 10/30\n",
      "219/219 [==============================] - 12s 57ms/step - loss: 3.1260 - root_mean_squared_error: 1.7680 - val_loss: 3.4323 - val_root_mean_squared_error: 1.8526\n",
      "Epoch 11/30\n",
      "219/219 [==============================] - 13s 59ms/step - loss: 3.1767 - root_mean_squared_error: 1.7823 - val_loss: 3.5378 - val_root_mean_squared_error: 1.8809\n",
      "Epoch 12/30\n",
      "219/219 [==============================] - 12s 57ms/step - loss: 3.1552 - root_mean_squared_error: 1.7763 - val_loss: 3.4261 - val_root_mean_squared_error: 1.8510\n",
      "Epoch 13/30\n",
      "219/219 [==============================] - 13s 59ms/step - loss: 3.1134 - root_mean_squared_error: 1.7645 - val_loss: 3.5707 - val_root_mean_squared_error: 1.8896\n",
      "Epoch 14/30\n",
      "219/219 [==============================] - 12s 54ms/step - loss: 3.1428 - root_mean_squared_error: 1.7728 - val_loss: 3.6619 - val_root_mean_squared_error: 1.9136\n",
      "Epoch 15/30\n",
      "219/219 [==============================] - 13s 59ms/step - loss: 3.1673 - root_mean_squared_error: 1.7797 - val_loss: 3.4634 - val_root_mean_squared_error: 1.8610\n",
      "Epoch 16/30\n",
      "219/219 [==============================] - 12s 57ms/step - loss: 3.1601 - root_mean_squared_error: 1.7777 - val_loss: 3.6454 - val_root_mean_squared_error: 1.9093\n",
      "Epoch 17/30\n",
      "219/219 [==============================] - 13s 59ms/step - loss: 3.2127 - root_mean_squared_error: 1.7924 - val_loss: 3.6471 - val_root_mean_squared_error: 1.9097\n",
      "Epoch 18/30\n",
      "219/219 [==============================] - 13s 62ms/step - loss: 3.2998 - root_mean_squared_error: 1.8165 - val_loss: 3.6439 - val_root_mean_squared_error: 1.9089\n",
      "Epoch 19/30\n",
      "219/219 [==============================] - 12s 57ms/step - loss: 3.2321 - root_mean_squared_error: 1.7978 - val_loss: 3.5481 - val_root_mean_squared_error: 1.8836\n",
      "Epoch 20/30\n",
      "219/219 [==============================] - 13s 60ms/step - loss: 3.2573 - root_mean_squared_error: 1.8048 - val_loss: 3.5216 - val_root_mean_squared_error: 1.8766\n",
      "Epoch 21/30\n",
      "219/219 [==============================] - 12s 53ms/step - loss: 3.2740 - root_mean_squared_error: 1.8094 - val_loss: 4.3800 - val_root_mean_squared_error: 2.0928\n",
      "Epoch 22/30\n",
      "219/219 [==============================] - 13s 61ms/step - loss: 3.3194 - root_mean_squared_error: 1.8219 - val_loss: 3.7151 - val_root_mean_squared_error: 1.9275\n",
      "Epoch 23/30\n",
      "219/219 [==============================] - 13s 59ms/step - loss: 3.4064 - root_mean_squared_error: 1.8457 - val_loss: 3.8260 - val_root_mean_squared_error: 1.9560\n",
      "Epoch 24/30\n",
      "219/219 [==============================] - 13s 59ms/step - loss: 3.3945 - root_mean_squared_error: 1.8424 - val_loss: 3.5919 - val_root_mean_squared_error: 1.8952\n",
      "Epoch 25/30\n",
      "219/219 [==============================] - 13s 57ms/step - loss: 3.3754 - root_mean_squared_error: 1.8372 - val_loss: 3.7390 - val_root_mean_squared_error: 1.9337\n",
      "Epoch 26/30\n",
      "219/219 [==============================] - 12s 56ms/step - loss: 3.3616 - root_mean_squared_error: 1.8335 - val_loss: 3.6130 - val_root_mean_squared_error: 1.9008\n",
      "Epoch 27/30\n",
      "219/219 [==============================] - 13s 59ms/step - loss: 3.3957 - root_mean_squared_error: 1.8427 - val_loss: 3.7008 - val_root_mean_squared_error: 1.9238\n",
      "Epoch 28/30\n",
      "219/219 [==============================] - 12s 56ms/step - loss: 3.4092 - root_mean_squared_error: 1.8464 - val_loss: 3.8945 - val_root_mean_squared_error: 1.9734\n",
      "Epoch 29/30\n",
      "219/219 [==============================] - 13s 59ms/step - loss: 3.3561 - root_mean_squared_error: 1.8320 - val_loss: 3.5038 - val_root_mean_squared_error: 1.8718\n",
      "Epoch 30/30\n",
      "219/219 [==============================] - 12s 55ms/step - loss: 3.2692 - root_mean_squared_error: 1.8081 - val_loss: 3.5784 - val_root_mean_squared_error: 1.8917\n",
      "1708/1708 [==============================] - 5s 3ms/step - loss: 3.0254 - root_mean_squared_error: 1.7394\n",
      "\n",
      "training time 390.821562\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 3.02535343170166 with RMSE metric of 1.7393543720245361\n",
      "725/725 [==============================] - 2s 3ms/step - loss: 3.5771 - root_mean_squared_error: 1.8913\n",
      "Test set has a loss (MSE) of 3.57712721824646 with RMSE metric of 1.8913295269012451\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "222/222 [==============================] - 13s 58ms/step - loss: 5.1687 - root_mean_squared_error: 2.2735 - val_loss: 3.9080 - val_root_mean_squared_error: 1.9769\n",
      "Epoch 2/30\n",
      "222/222 [==============================] - 12s 56ms/step - loss: 4.2123 - root_mean_squared_error: 2.0524 - val_loss: 3.9108 - val_root_mean_squared_error: 1.9776\n",
      "Epoch 3/30\n",
      "222/222 [==============================] - 13s 56ms/step - loss: 4.1529 - root_mean_squared_error: 2.0379 - val_loss: 4.1695 - val_root_mean_squared_error: 2.0419\n",
      "Epoch 4/30\n",
      "222/222 [==============================] - 12s 54ms/step - loss: 4.1544 - root_mean_squared_error: 2.0382 - val_loss: 3.9891 - val_root_mean_squared_error: 1.9973\n",
      "Epoch 5/30\n",
      "222/222 [==============================] - 13s 58ms/step - loss: 4.1013 - root_mean_squared_error: 2.0252 - val_loss: 3.9831 - val_root_mean_squared_error: 1.9958\n",
      "Epoch 6/30\n",
      "222/222 [==============================] - 12s 56ms/step - loss: 4.0915 - root_mean_squared_error: 2.0228 - val_loss: 3.7378 - val_root_mean_squared_error: 1.9333\n",
      "Epoch 7/30\n",
      "222/222 [==============================] - 13s 57ms/step - loss: 4.0976 - root_mean_squared_error: 2.0242 - val_loss: 3.7452 - val_root_mean_squared_error: 1.9353\n",
      "Epoch 8/30\n",
      "222/222 [==============================] - 12s 53ms/step - loss: 4.0845 - root_mean_squared_error: 2.0210 - val_loss: 4.0052 - val_root_mean_squared_error: 2.0013\n",
      "Epoch 9/30\n",
      "222/222 [==============================] - 13s 59ms/step - loss: 4.0280 - root_mean_squared_error: 2.0070 - val_loss: 3.9149 - val_root_mean_squared_error: 1.9786\n",
      "Epoch 10/30\n",
      "222/222 [==============================] - 12s 55ms/step - loss: 4.1202 - root_mean_squared_error: 2.0298 - val_loss: 3.8415 - val_root_mean_squared_error: 1.9600\n",
      "Epoch 11/30\n",
      "222/222 [==============================] - 13s 57ms/step - loss: 4.1010 - root_mean_squared_error: 2.0251 - val_loss: 3.7406 - val_root_mean_squared_error: 1.9341\n",
      "Epoch 12/30\n",
      "222/222 [==============================] - 12s 53ms/step - loss: 4.1491 - root_mean_squared_error: 2.0369 - val_loss: 4.0290 - val_root_mean_squared_error: 2.0072\n",
      "Epoch 13/30\n",
      "222/222 [==============================] - 13s 56ms/step - loss: 4.1061 - root_mean_squared_error: 2.0264 - val_loss: 4.0836 - val_root_mean_squared_error: 2.0208\n",
      "Epoch 14/30\n",
      "222/222 [==============================] - 12s 54ms/step - loss: 4.1737 - root_mean_squared_error: 2.0430 - val_loss: 4.3770 - val_root_mean_squared_error: 2.0921\n",
      "Epoch 15/30\n",
      "222/222 [==============================] - 12s 53ms/step - loss: 4.1643 - root_mean_squared_error: 2.0407 - val_loss: 3.9885 - val_root_mean_squared_error: 1.9971\n",
      "Epoch 16/30\n",
      "222/222 [==============================] - 15s 70ms/step - loss: 4.1077 - root_mean_squared_error: 2.0268 - val_loss: 3.9243 - val_root_mean_squared_error: 1.9810\n",
      "Epoch 17/30\n",
      "222/222 [==============================] - 12s 54ms/step - loss: 4.1918 - root_mean_squared_error: 2.0474 - val_loss: 3.9126 - val_root_mean_squared_error: 1.9780\n",
      "Epoch 18/30\n",
      "222/222 [==============================] - 12s 53ms/step - loss: 4.1758 - root_mean_squared_error: 2.0435 - val_loss: 4.3345 - val_root_mean_squared_error: 2.0819\n",
      "Epoch 19/30\n",
      "222/222 [==============================] - 12s 56ms/step - loss: 4.1574 - root_mean_squared_error: 2.0390 - val_loss: 3.9336 - val_root_mean_squared_error: 1.9833\n",
      "Epoch 20/30\n",
      "222/222 [==============================] - 12s 53ms/step - loss: 4.2448 - root_mean_squared_error: 2.0603 - val_loss: 4.1162 - val_root_mean_squared_error: 2.0288\n",
      "Epoch 21/30\n",
      "222/222 [==============================] - 13s 60ms/step - loss: 4.2355 - root_mean_squared_error: 2.0580 - val_loss: 4.2404 - val_root_mean_squared_error: 2.0592\n",
      "Epoch 22/30\n",
      "222/222 [==============================] - 12s 54ms/step - loss: 4.2411 - root_mean_squared_error: 2.0594 - val_loss: 4.7394 - val_root_mean_squared_error: 2.1770\n",
      "Epoch 23/30\n",
      "222/222 [==============================] - 13s 57ms/step - loss: 4.3335 - root_mean_squared_error: 2.0817 - val_loss: 4.1273 - val_root_mean_squared_error: 2.0316\n",
      "Epoch 24/30\n",
      "222/222 [==============================] - 12s 52ms/step - loss: 4.4060 - root_mean_squared_error: 2.0990 - val_loss: 4.6070 - val_root_mean_squared_error: 2.1464\n",
      "Epoch 25/30\n",
      "222/222 [==============================] - 11s 51ms/step - loss: 4.4498 - root_mean_squared_error: 2.1094 - val_loss: 4.2469 - val_root_mean_squared_error: 2.0608\n",
      "Epoch 26/30\n",
      "222/222 [==============================] - 12s 56ms/step - loss: 4.6134 - root_mean_squared_error: 2.1479 - val_loss: 4.3850 - val_root_mean_squared_error: 2.0940\n",
      "Epoch 27/30\n",
      "222/222 [==============================] - 12s 53ms/step - loss: 4.5072 - root_mean_squared_error: 2.1230 - val_loss: 4.5438 - val_root_mean_squared_error: 2.1316\n",
      "Epoch 28/30\n",
      "222/222 [==============================] - 13s 57ms/step - loss: 4.5332 - root_mean_squared_error: 2.1291 - val_loss: 4.2200 - val_root_mean_squared_error: 2.0543\n",
      "Epoch 29/30\n",
      "222/222 [==============================] - 12s 55ms/step - loss: 4.5342 - root_mean_squared_error: 2.1294 - val_loss: 4.2148 - val_root_mean_squared_error: 2.0530\n",
      "Epoch 30/30\n",
      "222/222 [==============================] - 13s 57ms/step - loss: 4.4968 - root_mean_squared_error: 2.1206 - val_loss: 4.4065 - val_root_mean_squared_error: 2.0992\n",
      "1732/1732 [==============================] - 5s 3ms/step - loss: 4.1239 - root_mean_squared_error: 2.0307\n",
      "\n",
      "training time 376.732575\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 4.123871326446533 with RMSE metric of 2.030731678009033\n",
      "753/753 [==============================] - 2s 3ms/step - loss: 4.1634 - root_mean_squared_error: 2.0404\n",
      "Test set has a loss (MSE) of 4.163357257843018 with RMSE metric of 2.0404305458068848\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "95/95 [==============================] - 6s 57ms/step - loss: 7.8998 - root_mean_squared_error: 2.8107 - val_loss: 5.1322 - val_root_mean_squared_error: 2.2654\n",
      "Epoch 2/30\n",
      "95/95 [==============================] - 5s 53ms/step - loss: 5.4177 - root_mean_squared_error: 2.3276 - val_loss: 5.1989 - val_root_mean_squared_error: 2.2801\n",
      "Epoch 3/30\n",
      "95/95 [==============================] - 5s 54ms/step - loss: 5.1759 - root_mean_squared_error: 2.2751 - val_loss: 5.2244 - val_root_mean_squared_error: 2.2857\n",
      "Epoch 4/30\n",
      "95/95 [==============================] - 5s 55ms/step - loss: 5.1718 - root_mean_squared_error: 2.2742 - val_loss: 4.9301 - val_root_mean_squared_error: 2.2204\n",
      "Epoch 5/30\n",
      "95/95 [==============================] - 5s 55ms/step - loss: 5.0697 - root_mean_squared_error: 2.2516 - val_loss: 4.9123 - val_root_mean_squared_error: 2.2164\n",
      "Epoch 6/30\n",
      "95/95 [==============================] - 5s 53ms/step - loss: 4.9827 - root_mean_squared_error: 2.2322 - val_loss: 5.4291 - val_root_mean_squared_error: 2.3300\n",
      "Epoch 7/30\n",
      "95/95 [==============================] - 5s 55ms/step - loss: 5.2494 - root_mean_squared_error: 2.2912 - val_loss: 4.9971 - val_root_mean_squared_error: 2.2354\n",
      "Epoch 8/30\n",
      "95/95 [==============================] - 5s 50ms/step - loss: 5.0114 - root_mean_squared_error: 2.2386 - val_loss: 4.9227 - val_root_mean_squared_error: 2.2187\n",
      "Epoch 9/30\n",
      "95/95 [==============================] - 5s 51ms/step - loss: 4.9098 - root_mean_squared_error: 2.2158 - val_loss: 4.7621 - val_root_mean_squared_error: 2.1822\n",
      "Epoch 10/30\n",
      "95/95 [==============================] - 5s 56ms/step - loss: 4.9202 - root_mean_squared_error: 2.2181 - val_loss: 4.9918 - val_root_mean_squared_error: 2.2342\n",
      "Epoch 11/30\n",
      "95/95 [==============================] - 5s 52ms/step - loss: 4.9218 - root_mean_squared_error: 2.2185 - val_loss: 4.6441 - val_root_mean_squared_error: 2.1550\n",
      "Epoch 12/30\n",
      "95/95 [==============================] - 5s 55ms/step - loss: 5.0208 - root_mean_squared_error: 2.2407 - val_loss: 4.7285 - val_root_mean_squared_error: 2.1745\n",
      "Epoch 13/30\n",
      "95/95 [==============================] - 5s 52ms/step - loss: 4.8982 - root_mean_squared_error: 2.2132 - val_loss: 5.9595 - val_root_mean_squared_error: 2.4412\n",
      "Epoch 14/30\n",
      "95/95 [==============================] - 5s 53ms/step - loss: 4.9624 - root_mean_squared_error: 2.2276 - val_loss: 4.9705 - val_root_mean_squared_error: 2.2295\n",
      "Epoch 15/30\n",
      "95/95 [==============================] - 5s 54ms/step - loss: 5.1063 - root_mean_squared_error: 2.2597 - val_loss: 5.1682 - val_root_mean_squared_error: 2.2734\n",
      "Epoch 16/30\n",
      "95/95 [==============================] - 5s 52ms/step - loss: 4.9748 - root_mean_squared_error: 2.2304 - val_loss: 5.0815 - val_root_mean_squared_error: 2.2542\n",
      "Epoch 17/30\n",
      "95/95 [==============================] - 5s 55ms/step - loss: 4.9565 - root_mean_squared_error: 2.2263 - val_loss: 4.9818 - val_root_mean_squared_error: 2.2320\n",
      "Epoch 18/30\n",
      "95/95 [==============================] - 5s 53ms/step - loss: 5.0046 - root_mean_squared_error: 2.2371 - val_loss: 4.7300 - val_root_mean_squared_error: 2.1748\n",
      "Epoch 19/30\n",
      "95/95 [==============================] - 5s 54ms/step - loss: 4.9056 - root_mean_squared_error: 2.2149 - val_loss: 4.9645 - val_root_mean_squared_error: 2.2281\n",
      "Epoch 20/30\n",
      "95/95 [==============================] - 5s 56ms/step - loss: 5.1301 - root_mean_squared_error: 2.2650 - val_loss: 5.2734 - val_root_mean_squared_error: 2.2964\n",
      "Epoch 21/30\n",
      "95/95 [==============================] - 5s 55ms/step - loss: 4.9943 - root_mean_squared_error: 2.2348 - val_loss: 5.0833 - val_root_mean_squared_error: 2.2546\n",
      "Epoch 22/30\n",
      "95/95 [==============================] - 8s 82ms/step - loss: 4.9645 - root_mean_squared_error: 2.2281 - val_loss: 4.7212 - val_root_mean_squared_error: 2.1728\n",
      "Epoch 23/30\n",
      "95/95 [==============================] - 7s 72ms/step - loss: 5.0505 - root_mean_squared_error: 2.2473 - val_loss: 4.9080 - val_root_mean_squared_error: 2.2154\n",
      "Epoch 24/30\n",
      "95/95 [==============================] - 5s 50ms/step - loss: 4.9635 - root_mean_squared_error: 2.2279 - val_loss: 4.9036 - val_root_mean_squared_error: 2.2144\n",
      "Epoch 25/30\n",
      "95/95 [==============================] - 5s 50ms/step - loss: 5.0799 - root_mean_squared_error: 2.2539 - val_loss: 5.3485 - val_root_mean_squared_error: 2.3127\n",
      "Epoch 26/30\n",
      "95/95 [==============================] - 5s 49ms/step - loss: 5.0724 - root_mean_squared_error: 2.2522 - val_loss: 5.5831 - val_root_mean_squared_error: 2.3629\n",
      "Epoch 27/30\n",
      "95/95 [==============================] - 5s 49ms/step - loss: 5.0632 - root_mean_squared_error: 2.2502 - val_loss: 4.6940 - val_root_mean_squared_error: 2.1666\n",
      "Epoch 28/30\n",
      "95/95 [==============================] - 5s 51ms/step - loss: 4.9960 - root_mean_squared_error: 2.2352 - val_loss: 5.2954 - val_root_mean_squared_error: 2.3012\n",
      "Epoch 29/30\n",
      "95/95 [==============================] - 5s 49ms/step - loss: 4.9554 - root_mean_squared_error: 2.2261 - val_loss: 4.9829 - val_root_mean_squared_error: 2.2322\n",
      "Epoch 30/30\n",
      "95/95 [==============================] - 5s 49ms/step - loss: 5.0385 - root_mean_squared_error: 2.2447 - val_loss: 5.0701 - val_root_mean_squared_error: 2.2517\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.7718 - root_mean_squared_error: 2.1845\n",
      "\n",
      "training time 158.083537\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 4.771833419799805 with RMSE metric of 2.184452772140503\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 4.9377 - root_mean_squared_error: 2.2221\n",
      "Test set has a loss (MSE) of 4.937686920166016 with RMSE metric of 2.222090721130371\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "161/161 [==============================] - 12s 72ms/step - loss: 4.2028 - root_mean_squared_error: 2.0501 - val_loss: 3.2553 - val_root_mean_squared_error: 1.8042\n",
      "Epoch 2/30\n",
      "161/161 [==============================] - 12s 77ms/step - loss: 2.7290 - root_mean_squared_error: 1.6520 - val_loss: 3.3123 - val_root_mean_squared_error: 1.8200\n",
      "Epoch 3/30\n",
      "161/161 [==============================] - 9s 58ms/step - loss: 2.6141 - root_mean_squared_error: 1.6168 - val_loss: 2.6852 - val_root_mean_squared_error: 1.6387\n",
      "Epoch 4/30\n",
      "161/161 [==============================] - 8s 50ms/step - loss: 2.5326 - root_mean_squared_error: 1.5914 - val_loss: 2.6682 - val_root_mean_squared_error: 1.6335\n",
      "Epoch 5/30\n",
      "161/161 [==============================] - 8s 50ms/step - loss: 2.5569 - root_mean_squared_error: 1.5990 - val_loss: 2.5222 - val_root_mean_squared_error: 1.5882\n",
      "Epoch 6/30\n",
      "161/161 [==============================] - 8s 50ms/step - loss: 2.5445 - root_mean_squared_error: 1.5952 - val_loss: 2.6894 - val_root_mean_squared_error: 1.6399\n",
      "Epoch 7/30\n",
      "161/161 [==============================] - 8s 50ms/step - loss: 2.5405 - root_mean_squared_error: 1.5939 - val_loss: 2.6909 - val_root_mean_squared_error: 1.6404\n",
      "Epoch 8/30\n",
      "161/161 [==============================] - 8s 50ms/step - loss: 2.5251 - root_mean_squared_error: 1.5890 - val_loss: 2.5196 - val_root_mean_squared_error: 1.5873\n",
      "Epoch 9/30\n",
      "161/161 [==============================] - 8s 49ms/step - loss: 2.5082 - root_mean_squared_error: 1.5837 - val_loss: 2.5895 - val_root_mean_squared_error: 1.6092\n",
      "Epoch 10/30\n",
      "161/161 [==============================] - 8s 50ms/step - loss: 2.5944 - root_mean_squared_error: 1.6107 - val_loss: 2.4563 - val_root_mean_squared_error: 1.5672\n",
      "Epoch 11/30\n",
      "161/161 [==============================] - 8s 48ms/step - loss: 2.5096 - root_mean_squared_error: 1.5842 - val_loss: 3.0775 - val_root_mean_squared_error: 1.7543\n",
      "Epoch 12/30\n",
      "161/161 [==============================] - 8s 49ms/step - loss: 2.5737 - root_mean_squared_error: 1.6043 - val_loss: 2.5325 - val_root_mean_squared_error: 1.5914\n",
      "Epoch 13/30\n",
      "161/161 [==============================] - 8s 50ms/step - loss: 2.6761 - root_mean_squared_error: 1.6359 - val_loss: 2.5260 - val_root_mean_squared_error: 1.5894\n",
      "Epoch 14/30\n",
      "161/161 [==============================] - 8s 49ms/step - loss: 2.5697 - root_mean_squared_error: 1.6030 - val_loss: 2.7272 - val_root_mean_squared_error: 1.6514\n",
      "Epoch 15/30\n",
      "161/161 [==============================] - 8s 49ms/step - loss: 2.5322 - root_mean_squared_error: 1.5913 - val_loss: 2.5754 - val_root_mean_squared_error: 1.6048\n",
      "Epoch 16/30\n",
      "161/161 [==============================] - 8s 49ms/step - loss: 2.5837 - root_mean_squared_error: 1.6074 - val_loss: 2.7394 - val_root_mean_squared_error: 1.6551\n",
      "Epoch 17/30\n",
      "161/161 [==============================] - 8s 50ms/step - loss: 2.5693 - root_mean_squared_error: 1.6029 - val_loss: 2.7288 - val_root_mean_squared_error: 1.6519\n",
      "Epoch 18/30\n",
      "161/161 [==============================] - 8s 49ms/step - loss: 2.6472 - root_mean_squared_error: 1.6270 - val_loss: 2.5781 - val_root_mean_squared_error: 1.6057\n",
      "Epoch 19/30\n",
      "161/161 [==============================] - 8s 49ms/step - loss: 2.6018 - root_mean_squared_error: 1.6130 - val_loss: 2.6621 - val_root_mean_squared_error: 1.6316\n",
      "Epoch 20/30\n",
      "161/161 [==============================] - 8s 50ms/step - loss: 2.5901 - root_mean_squared_error: 1.6094 - val_loss: 2.5667 - val_root_mean_squared_error: 1.6021\n",
      "Epoch 21/30\n",
      "161/161 [==============================] - 8s 50ms/step - loss: 2.5728 - root_mean_squared_error: 1.6040 - val_loss: 2.6139 - val_root_mean_squared_error: 1.6168\n",
      "Epoch 22/30\n",
      "161/161 [==============================] - 8s 50ms/step - loss: 2.6729 - root_mean_squared_error: 1.6349 - val_loss: 2.7154 - val_root_mean_squared_error: 1.6478\n",
      "Epoch 23/30\n",
      "161/161 [==============================] - 8s 49ms/step - loss: 2.6484 - root_mean_squared_error: 1.6274 - val_loss: 2.6379 - val_root_mean_squared_error: 1.6242\n",
      "Epoch 24/30\n",
      "161/161 [==============================] - 8s 49ms/step - loss: 2.7509 - root_mean_squared_error: 1.6586 - val_loss: 2.8297 - val_root_mean_squared_error: 1.6822\n",
      "Epoch 25/30\n",
      "161/161 [==============================] - 8s 48ms/step - loss: 2.5985 - root_mean_squared_error: 1.6120 - val_loss: 2.6823 - val_root_mean_squared_error: 1.6378\n",
      "Epoch 26/30\n",
      "161/161 [==============================] - 8s 48ms/step - loss: 2.6736 - root_mean_squared_error: 1.6351 - val_loss: 2.8726 - val_root_mean_squared_error: 1.6949\n",
      "Epoch 27/30\n",
      "161/161 [==============================] - 8s 49ms/step - loss: 2.7212 - root_mean_squared_error: 1.6496 - val_loss: 2.6406 - val_root_mean_squared_error: 1.6250\n",
      "Epoch 28/30\n",
      "161/161 [==============================] - 8s 48ms/step - loss: 2.6987 - root_mean_squared_error: 1.6428 - val_loss: 2.9932 - val_root_mean_squared_error: 1.7301\n",
      "Epoch 29/30\n",
      "161/161 [==============================] - 8s 51ms/step - loss: 2.6567 - root_mean_squared_error: 1.6299 - val_loss: 2.7004 - val_root_mean_squared_error: 1.6433\n",
      "Epoch 30/30\n",
      "161/161 [==============================] - 8s 48ms/step - loss: 2.7024 - root_mean_squared_error: 1.6439 - val_loss: 2.6605 - val_root_mean_squared_error: 1.6311\n",
      "1253/1253 [==============================] - 4s 3ms/step - loss: 2.4237 - root_mean_squared_error: 1.5568\n",
      "\n",
      "training time 252.448919\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 2.4237239360809326 with RMSE metric of 1.5568313598632812\n",
      "568/568 [==============================] - 2s 4ms/step - loss: 2.4886 - root_mean_squared_error: 1.5775\n",
      "Test set has a loss (MSE) of 2.4886481761932373 with RMSE metric of 1.577544927597046\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "112/112 [==============================] - 6s 46ms/step - loss: 8.6394 - root_mean_squared_error: 2.9393 - val_loss: 4.7993 - val_root_mean_squared_error: 2.1907\n",
      "Epoch 2/30\n",
      "112/112 [==============================] - 6s 50ms/step - loss: 5.1885 - root_mean_squared_error: 2.2778 - val_loss: 4.2985 - val_root_mean_squared_error: 2.0733\n",
      "Epoch 3/30\n",
      "112/112 [==============================] - 5s 49ms/step - loss: 4.9625 - root_mean_squared_error: 2.2277 - val_loss: 4.2517 - val_root_mean_squared_error: 2.0620\n",
      "Epoch 4/30\n",
      "112/112 [==============================] - 6s 49ms/step - loss: 4.9251 - root_mean_squared_error: 2.2192 - val_loss: 4.5404 - val_root_mean_squared_error: 2.1308\n",
      "Epoch 5/30\n",
      "112/112 [==============================] - 6s 50ms/step - loss: 4.8896 - root_mean_squared_error: 2.2113 - val_loss: 4.1867 - val_root_mean_squared_error: 2.0461\n",
      "Epoch 6/30\n",
      "112/112 [==============================] - 6s 51ms/step - loss: 4.8000 - root_mean_squared_error: 2.1909 - val_loss: 5.0081 - val_root_mean_squared_error: 2.2379\n",
      "Epoch 7/30\n",
      "112/112 [==============================] - 6s 54ms/step - loss: 4.8242 - root_mean_squared_error: 2.1964 - val_loss: 4.1997 - val_root_mean_squared_error: 2.0493\n",
      "Epoch 8/30\n",
      "112/112 [==============================] - 6s 52ms/step - loss: 4.8096 - root_mean_squared_error: 2.1931 - val_loss: 4.8686 - val_root_mean_squared_error: 2.2065\n",
      "Epoch 9/30\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 4.8167 - root_mean_squared_error: 2.1947 - val_loss: 4.2542 - val_root_mean_squared_error: 2.0626\n",
      "Epoch 10/30\n",
      "112/112 [==============================] - 5s 49ms/step - loss: 4.8326 - root_mean_squared_error: 2.1983 - val_loss: 4.4760 - val_root_mean_squared_error: 2.1157\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 4.7275 - root_mean_squared_error: 2.1743 - val_loss: 4.4412 - val_root_mean_squared_error: 2.1074\n",
      "Epoch 12/30\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 4.7190 - root_mean_squared_error: 2.1723 - val_loss: 4.3570 - val_root_mean_squared_error: 2.0873\n",
      "Epoch 13/30\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 4.6113 - root_mean_squared_error: 2.1474 - val_loss: 4.6114 - val_root_mean_squared_error: 2.1474\n",
      "Epoch 14/30\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 4.9036 - root_mean_squared_error: 2.2144 - val_loss: 4.9977 - val_root_mean_squared_error: 2.2356\n",
      "Epoch 15/30\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 4.7460 - root_mean_squared_error: 2.1785 - val_loss: 4.1757 - val_root_mean_squared_error: 2.0434\n",
      "Epoch 16/30\n",
      "112/112 [==============================] - 6s 50ms/step - loss: 4.7554 - root_mean_squared_error: 2.1807 - val_loss: 5.4694 - val_root_mean_squared_error: 2.3387\n",
      "Epoch 17/30\n",
      "112/112 [==============================] - 6s 52ms/step - loss: 4.8031 - root_mean_squared_error: 2.1916 - val_loss: 4.5816 - val_root_mean_squared_error: 2.1405\n",
      "Epoch 18/30\n",
      "112/112 [==============================] - 6s 50ms/step - loss: 4.7383 - root_mean_squared_error: 2.1768 - val_loss: 4.5232 - val_root_mean_squared_error: 2.1268\n",
      "Epoch 19/30\n",
      "112/112 [==============================] - 6s 50ms/step - loss: 4.7259 - root_mean_squared_error: 2.1739 - val_loss: 4.2628 - val_root_mean_squared_error: 2.0646\n",
      "Epoch 20/30\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 4.7140 - root_mean_squared_error: 2.1712 - val_loss: 4.2330 - val_root_mean_squared_error: 2.0574\n",
      "Epoch 21/30\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 4.7009 - root_mean_squared_error: 2.1682 - val_loss: 4.3483 - val_root_mean_squared_error: 2.0853\n",
      "Epoch 22/30\n",
      "112/112 [==============================] - 6s 50ms/step - loss: 4.6683 - root_mean_squared_error: 2.1606 - val_loss: 4.2416 - val_root_mean_squared_error: 2.0595\n",
      "Epoch 23/30\n",
      "112/112 [==============================] - 5s 49ms/step - loss: 4.7353 - root_mean_squared_error: 2.1761 - val_loss: 4.3578 - val_root_mean_squared_error: 2.0875\n",
      "Epoch 24/30\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 4.7273 - root_mean_squared_error: 2.1742 - val_loss: 4.2120 - val_root_mean_squared_error: 2.0523\n",
      "Epoch 25/30\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 4.7269 - root_mean_squared_error: 2.1741 - val_loss: 4.1107 - val_root_mean_squared_error: 2.0275\n",
      "Epoch 26/30\n",
      "112/112 [==============================] - 6s 50ms/step - loss: 4.9176 - root_mean_squared_error: 2.2176 - val_loss: 4.5315 - val_root_mean_squared_error: 2.1287\n",
      "Epoch 27/30\n",
      "112/112 [==============================] - 5s 49ms/step - loss: 4.8288 - root_mean_squared_error: 2.1975 - val_loss: 4.1894 - val_root_mean_squared_error: 2.0468\n",
      "Epoch 28/30\n",
      "112/112 [==============================] - 6s 50ms/step - loss: 4.9752 - root_mean_squared_error: 2.2305 - val_loss: 4.3826 - val_root_mean_squared_error: 2.0935\n",
      "Epoch 29/30\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 4.9729 - root_mean_squared_error: 2.2300 - val_loss: 5.1465 - val_root_mean_squared_error: 2.2686\n",
      "Epoch 30/30\n",
      "112/112 [==============================] - 5s 49ms/step - loss: 5.0942 - root_mean_squared_error: 2.2570 - val_loss: 4.5382 - val_root_mean_squared_error: 2.1303\n",
      "870/870 [==============================] - 3s 3ms/step - loss: 4.6675 - root_mean_squared_error: 2.1604\n",
      "\n",
      "training time 168.557246\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 4.667537689208984 with RMSE metric of 2.1604485511779785\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.8928 - root_mean_squared_error: 2.2120\n",
      "Test set has a loss (MSE) of 4.892819404602051 with RMSE metric of 2.2119717597961426\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "134/134 [==============================] - 7s 46ms/step - loss: 6.4666 - root_mean_squared_error: 2.5430 - val_loss: 4.8003 - val_root_mean_squared_error: 2.1910\n",
      "Epoch 2/30\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 4.5947 - root_mean_squared_error: 2.1435 - val_loss: 4.7025 - val_root_mean_squared_error: 2.1685\n",
      "Epoch 3/30\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 4.6635 - root_mean_squared_error: 2.1595 - val_loss: 4.1915 - val_root_mean_squared_error: 2.0473\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 4.5541 - root_mean_squared_error: 2.1340 - val_loss: 4.0274 - val_root_mean_squared_error: 2.0069\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 4.2729 - root_mean_squared_error: 2.0671 - val_loss: 3.8244 - val_root_mean_squared_error: 1.9556\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 4.4831 - root_mean_squared_error: 2.1173 - val_loss: 3.6580 - val_root_mean_squared_error: 1.9126\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 4.3146 - root_mean_squared_error: 2.0772 - val_loss: 4.4417 - val_root_mean_squared_error: 2.1075\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 4.4635 - root_mean_squared_error: 2.1127 - val_loss: 3.6107 - val_root_mean_squared_error: 1.9002\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 4.3869 - root_mean_squared_error: 2.0945 - val_loss: 4.3430 - val_root_mean_squared_error: 2.0840\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 4.2962 - root_mean_squared_error: 2.0727 - val_loss: 3.6108 - val_root_mean_squared_error: 1.9002\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 4.2786 - root_mean_squared_error: 2.0685 - val_loss: 3.7483 - val_root_mean_squared_error: 1.9361\n",
      "Epoch 12/30\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 4.3271 - root_mean_squared_error: 2.0802 - val_loss: 3.5692 - val_root_mean_squared_error: 1.8892\n",
      "Epoch 13/30\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 4.3261 - root_mean_squared_error: 2.0799 - val_loss: 3.6955 - val_root_mean_squared_error: 1.9224\n",
      "Epoch 14/30\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 4.3010 - root_mean_squared_error: 2.0739 - val_loss: 4.0167 - val_root_mean_squared_error: 2.0042\n",
      "Epoch 15/30\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 4.3483 - root_mean_squared_error: 2.0853 - val_loss: 3.9059 - val_root_mean_squared_error: 1.9763\n",
      "Epoch 16/30\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 4.3208 - root_mean_squared_error: 2.0787 - val_loss: 3.7653 - val_root_mean_squared_error: 1.9405\n",
      "Epoch 17/30\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 4.2960 - root_mean_squared_error: 2.0727 - val_loss: 3.6725 - val_root_mean_squared_error: 1.9164\n",
      "Epoch 18/30\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 4.2345 - root_mean_squared_error: 2.0578 - val_loss: 3.5773 - val_root_mean_squared_error: 1.8914\n",
      "Epoch 19/30\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 4.2093 - root_mean_squared_error: 2.0516 - val_loss: 3.5411 - val_root_mean_squared_error: 1.8818\n",
      "Epoch 20/30\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 4.3681 - root_mean_squared_error: 2.0900 - val_loss: 3.8037 - val_root_mean_squared_error: 1.9503\n",
      "Epoch 21/30\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 4.2774 - root_mean_squared_error: 2.0682 - val_loss: 4.2235 - val_root_mean_squared_error: 2.0551\n",
      "Epoch 22/30\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 4.3653 - root_mean_squared_error: 2.0893 - val_loss: 3.6695 - val_root_mean_squared_error: 1.9156\n",
      "Epoch 23/30\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 4.2966 - root_mean_squared_error: 2.0728 - val_loss: 4.0442 - val_root_mean_squared_error: 2.0110\n",
      "Epoch 24/30\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 4.2774 - root_mean_squared_error: 2.0682 - val_loss: 3.8414 - val_root_mean_squared_error: 1.9599\n",
      "Epoch 25/30\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 4.3657 - root_mean_squared_error: 2.0894 - val_loss: 4.0413 - val_root_mean_squared_error: 2.0103\n",
      "Epoch 26/30\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 4.3393 - root_mean_squared_error: 2.0831 - val_loss: 3.6204 - val_root_mean_squared_error: 1.9027\n",
      "Epoch 27/30\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 4.3395 - root_mean_squared_error: 2.0831 - val_loss: 3.8322 - val_root_mean_squared_error: 1.9576\n",
      "Epoch 28/30\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 4.4195 - root_mean_squared_error: 2.1023 - val_loss: 4.6489 - val_root_mean_squared_error: 2.1561\n",
      "Epoch 29/30\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 4.4070 - root_mean_squared_error: 2.0993 - val_loss: 3.9371 - val_root_mean_squared_error: 1.9842\n",
      "Epoch 30/30\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 4.4545 - root_mean_squared_error: 2.1106 - val_loss: 3.7490 - val_root_mean_squared_error: 1.9362\n",
      "1041/1041 [==============================] - 3s 3ms/step - loss: 4.1388 - root_mean_squared_error: 2.0344\n",
      "\n",
      "training time 207.803757\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 4.138822555541992 with RMSE metric of 2.034409523010254\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 3.9430 - root_mean_squared_error: 1.9857\n",
      "Test set has a loss (MSE) of 3.9429988861083984 with RMSE metric of 1.9856985807418823\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - 8s 50ms/step - loss: 4.7349 - root_mean_squared_error: 2.1760 - val_loss: 2.5171 - val_root_mean_squared_error: 1.5865\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - 8s 52ms/step - loss: 2.8361 - root_mean_squared_error: 1.6841 - val_loss: 2.7130 - val_root_mean_squared_error: 1.6471\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - 7s 50ms/step - loss: 2.9435 - root_mean_squared_error: 1.7157 - val_loss: 2.2976 - val_root_mean_squared_error: 1.5158\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - 8s 50ms/step - loss: 2.8080 - root_mean_squared_error: 1.6757 - val_loss: 2.5539 - val_root_mean_squared_error: 1.5981\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - 8s 50ms/step - loss: 2.8138 - root_mean_squared_error: 1.6774 - val_loss: 6.8390 - val_root_mean_squared_error: 2.6151\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - 8s 51ms/step - loss: 2.9207 - root_mean_squared_error: 1.7090 - val_loss: 3.2119 - val_root_mean_squared_error: 1.7922\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - 8s 52ms/step - loss: 2.8191 - root_mean_squared_error: 1.6790 - val_loss: 2.4483 - val_root_mean_squared_error: 1.5647\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - 8s 52ms/step - loss: 2.7969 - root_mean_squared_error: 1.6724 - val_loss: 3.1694 - val_root_mean_squared_error: 1.7803\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - 8s 51ms/step - loss: 2.8511 - root_mean_squared_error: 1.6885 - val_loss: 2.1216 - val_root_mean_squared_error: 1.4566\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 2.7086 - root_mean_squared_error: 1.6458 - val_loss: 2.5922 - val_root_mean_squared_error: 1.6100\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 2.7173 - root_mean_squared_error: 1.6484 - val_loss: 3.4864 - val_root_mean_squared_error: 1.8672\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - 8s 51ms/step - loss: 2.8082 - root_mean_squared_error: 1.6758 - val_loss: 2.4023 - val_root_mean_squared_error: 1.5499\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - 7s 50ms/step - loss: 2.7388 - root_mean_squared_error: 1.6549 - val_loss: 3.0213 - val_root_mean_squared_error: 1.7382\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - 8s 51ms/step - loss: 2.7771 - root_mean_squared_error: 1.6665 - val_loss: 2.0594 - val_root_mean_squared_error: 1.4351\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - 8s 51ms/step - loss: 2.6978 - root_mean_squared_error: 1.6425 - val_loss: 2.0990 - val_root_mean_squared_error: 1.4488\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - 8s 52ms/step - loss: 2.6926 - root_mean_squared_error: 1.6409 - val_loss: 2.1783 - val_root_mean_squared_error: 1.4759\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - 7s 50ms/step - loss: 2.7684 - root_mean_squared_error: 1.6639 - val_loss: 2.4222 - val_root_mean_squared_error: 1.5563\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - 8s 50ms/step - loss: 2.7751 - root_mean_squared_error: 1.6659 - val_loss: 2.2224 - val_root_mean_squared_error: 1.4908\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - 7s 50ms/step - loss: 2.7714 - root_mean_squared_error: 1.6647 - val_loss: 2.2104 - val_root_mean_squared_error: 1.4868\n",
      "Epoch 20/30\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 2.8004 - root_mean_squared_error: 1.6734 - val_loss: 2.3727 - val_root_mean_squared_error: 1.5403\n",
      "Epoch 21/30\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 2.7611 - root_mean_squared_error: 1.6616 - val_loss: 2.1756 - val_root_mean_squared_error: 1.4750\n",
      "Epoch 22/30\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 2.7607 - root_mean_squared_error: 1.6615 - val_loss: 3.5289 - val_root_mean_squared_error: 1.8785\n",
      "Epoch 23/30\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 2.8915 - root_mean_squared_error: 1.7004 - val_loss: 4.2995 - val_root_mean_squared_error: 2.0735\n",
      "Epoch 24/30\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 2.9103 - root_mean_squared_error: 1.7060 - val_loss: 2.3115 - val_root_mean_squared_error: 1.5204\n",
      "Epoch 25/30\n",
      "150/150 [==============================] - 8s 51ms/step - loss: 2.8613 - root_mean_squared_error: 1.6915 - val_loss: 2.2669 - val_root_mean_squared_error: 1.5056\n",
      "Epoch 26/30\n",
      "150/150 [==============================] - 7s 50ms/step - loss: 2.8875 - root_mean_squared_error: 1.6993 - val_loss: 2.6582 - val_root_mean_squared_error: 1.6304\n",
      "Epoch 27/30\n",
      "150/150 [==============================] - 8s 51ms/step - loss: 2.9144 - root_mean_squared_error: 1.7072 - val_loss: 2.3216 - val_root_mean_squared_error: 1.5237\n",
      "Epoch 28/30\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 2.8419 - root_mean_squared_error: 1.6858 - val_loss: 2.6240 - val_root_mean_squared_error: 1.6199\n",
      "Epoch 29/30\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 2.9067 - root_mean_squared_error: 1.7049 - val_loss: 2.7435 - val_root_mean_squared_error: 1.6564\n",
      "Epoch 30/30\n",
      "150/150 [==============================] - 7s 50ms/step - loss: 2.8600 - root_mean_squared_error: 1.6912 - val_loss: 2.5573 - val_root_mean_squared_error: 1.5992\n",
      "1165/1165 [==============================] - 4s 3ms/step - loss: 2.7528 - root_mean_squared_error: 1.6591\n",
      "\n",
      "training time 232.270596\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 2.752774953842163 with RMSE metric of 1.6591488122940063\n",
      "447/447 [==============================] - 2s 4ms/step - loss: 3.3736 - root_mean_squared_error: 1.8367\n",
      "Test set has a loss (MSE) of 3.373575210571289 with RMSE metric of 1.8367295265197754\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "111/111 [==============================] - 6s 52ms/step - loss: 7.7658 - root_mean_squared_error: 2.7867 - val_loss: 4.7608 - val_root_mean_squared_error: 2.1819\n",
      "Epoch 2/30\n",
      "111/111 [==============================] - 6s 51ms/step - loss: 5.0308 - root_mean_squared_error: 2.2429 - val_loss: 4.6720 - val_root_mean_squared_error: 2.1615\n",
      "Epoch 3/30\n",
      "111/111 [==============================] - 7s 60ms/step - loss: 4.8532 - root_mean_squared_error: 2.2030 - val_loss: 4.7110 - val_root_mean_squared_error: 2.1705\n",
      "Epoch 4/30\n",
      "111/111 [==============================] - 9s 84ms/step - loss: 4.7978 - root_mean_squared_error: 2.1904 - val_loss: 4.8359 - val_root_mean_squared_error: 2.1991\n",
      "Epoch 5/30\n",
      "111/111 [==============================] - 11s 99ms/step - loss: 4.7968 - root_mean_squared_error: 2.1901 - val_loss: 4.6174 - val_root_mean_squared_error: 2.1488\n",
      "Epoch 6/30\n",
      "111/111 [==============================] - 14s 123ms/step - loss: 4.7017 - root_mean_squared_error: 2.1683 - val_loss: 4.6010 - val_root_mean_squared_error: 2.1450\n",
      "Epoch 7/30\n",
      "111/111 [==============================] - 13s 116ms/step - loss: 4.7324 - root_mean_squared_error: 2.1754 - val_loss: 4.6272 - val_root_mean_squared_error: 2.1511\n",
      "Epoch 8/30\n",
      "111/111 [==============================] - 9s 78ms/step - loss: 4.6725 - root_mean_squared_error: 2.1616 - val_loss: 4.6380 - val_root_mean_squared_error: 2.1536\n",
      "Epoch 9/30\n",
      "111/111 [==============================] - 7s 66ms/step - loss: 4.6817 - root_mean_squared_error: 2.1637 - val_loss: 4.6051 - val_root_mean_squared_error: 2.1460\n",
      "Epoch 10/30\n",
      "111/111 [==============================] - 8s 68ms/step - loss: 4.7876 - root_mean_squared_error: 2.1881 - val_loss: 4.6937 - val_root_mean_squared_error: 2.1665\n",
      "Epoch 11/30\n",
      "111/111 [==============================] - 7s 64ms/step - loss: 4.8286 - root_mean_squared_error: 2.1974 - val_loss: 4.7789 - val_root_mean_squared_error: 2.1861\n",
      "Epoch 12/30\n",
      "111/111 [==============================] - 5s 49ms/step - loss: 4.6714 - root_mean_squared_error: 2.1613 - val_loss: 4.7744 - val_root_mean_squared_error: 2.1850\n",
      "Epoch 13/30\n",
      "111/111 [==============================] - 6s 51ms/step - loss: 4.6982 - root_mean_squared_error: 2.1675 - val_loss: 4.7006 - val_root_mean_squared_error: 2.1681\n",
      "Epoch 14/30\n",
      "111/111 [==============================] - 6s 50ms/step - loss: 4.7043 - root_mean_squared_error: 2.1689 - val_loss: 4.7466 - val_root_mean_squared_error: 2.1787\n",
      "Epoch 15/30\n",
      "111/111 [==============================] - 6s 50ms/step - loss: 4.7581 - root_mean_squared_error: 2.1813 - val_loss: 4.4702 - val_root_mean_squared_error: 2.1143\n",
      "Epoch 16/30\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 4.7309 - root_mean_squared_error: 2.1751 - val_loss: 4.8493 - val_root_mean_squared_error: 2.2021\n",
      "Epoch 17/30\n",
      "111/111 [==============================] - 6s 51ms/step - loss: 4.7608 - root_mean_squared_error: 2.1819 - val_loss: 4.6857 - val_root_mean_squared_error: 2.1647\n",
      "Epoch 18/30\n",
      "111/111 [==============================] - 6s 51ms/step - loss: 4.7471 - root_mean_squared_error: 2.1788 - val_loss: 4.6328 - val_root_mean_squared_error: 2.1524\n",
      "Epoch 19/30\n",
      "111/111 [==============================] - 6s 52ms/step - loss: 4.7198 - root_mean_squared_error: 2.1725 - val_loss: 4.5314 - val_root_mean_squared_error: 2.1287\n",
      "Epoch 20/30\n",
      "111/111 [==============================] - 6s 50ms/step - loss: 4.7202 - root_mean_squared_error: 2.1726 - val_loss: 4.5287 - val_root_mean_squared_error: 2.1281\n",
      "Epoch 21/30\n",
      "111/111 [==============================] - 6s 50ms/step - loss: 4.7717 - root_mean_squared_error: 2.1844 - val_loss: 4.5064 - val_root_mean_squared_error: 2.1228\n",
      "Epoch 22/30\n",
      "111/111 [==============================] - 6s 51ms/step - loss: 4.7616 - root_mean_squared_error: 2.1821 - val_loss: 4.8652 - val_root_mean_squared_error: 2.2057\n",
      "Epoch 23/30\n",
      "111/111 [==============================] - 6s 50ms/step - loss: 4.7889 - root_mean_squared_error: 2.1884 - val_loss: 5.0163 - val_root_mean_squared_error: 2.2397\n",
      "Epoch 24/30\n",
      "111/111 [==============================] - 6s 50ms/step - loss: 4.7207 - root_mean_squared_error: 2.1727 - val_loss: 4.5542 - val_root_mean_squared_error: 2.1341\n",
      "Epoch 25/30\n",
      "111/111 [==============================] - 6s 50ms/step - loss: 4.7344 - root_mean_squared_error: 2.1759 - val_loss: 4.4982 - val_root_mean_squared_error: 2.1209\n",
      "Epoch 26/30\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 4.7525 - root_mean_squared_error: 2.1800 - val_loss: 4.7486 - val_root_mean_squared_error: 2.1791\n",
      "Epoch 27/30\n",
      "111/111 [==============================] - 6s 51ms/step - loss: 4.7899 - root_mean_squared_error: 2.1886 - val_loss: 4.5605 - val_root_mean_squared_error: 2.1355\n",
      "Epoch 28/30\n",
      "111/111 [==============================] - 5s 47ms/step - loss: 4.7538 - root_mean_squared_error: 2.1803 - val_loss: 4.6101 - val_root_mean_squared_error: 2.1471\n",
      "Epoch 29/30\n",
      "111/111 [==============================] - 6s 52ms/step - loss: 4.7562 - root_mean_squared_error: 2.1809 - val_loss: 4.5668 - val_root_mean_squared_error: 2.1370\n",
      "Epoch 30/30\n",
      "111/111 [==============================] - 5s 41ms/step - loss: 4.8187 - root_mean_squared_error: 2.1951 - val_loss: 4.6026 - val_root_mean_squared_error: 2.1454\n",
      "867/867 [==============================] - 3s 4ms/step - loss: 4.4217 - root_mean_squared_error: 2.1028\n",
      "\n",
      "training time 205.372948\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 4.4217424392700195 with RMSE metric of 2.1027939319610596\n",
      "406/406 [==============================] - 1s 3ms/step - loss: 3.7935 - root_mean_squared_error: 1.9477\n",
      "Test set has a loss (MSE) of 3.7935380935668945 with RMSE metric of 1.9477007389068604\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "81/81 [==============================] - 6s 70ms/step - loss: 12.3637 - root_mean_squared_error: 3.5162 - val_loss: 5.8873 - val_root_mean_squared_error: 2.4264\n",
      "Epoch 2/30\n",
      "81/81 [==============================] - 5s 59ms/step - loss: 6.8330 - root_mean_squared_error: 2.6140 - val_loss: 6.5740 - val_root_mean_squared_error: 2.5640\n",
      "Epoch 3/30\n",
      "81/81 [==============================] - 5s 59ms/step - loss: 6.9196 - root_mean_squared_error: 2.6305 - val_loss: 5.8002 - val_root_mean_squared_error: 2.4084\n",
      "Epoch 4/30\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 6.5114 - root_mean_squared_error: 2.5517 - val_loss: 5.4656 - val_root_mean_squared_error: 2.3379\n",
      "Epoch 5/30\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 6.3150 - root_mean_squared_error: 2.5130 - val_loss: 5.7903 - val_root_mean_squared_error: 2.4063\n",
      "Epoch 6/30\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 6.3516 - root_mean_squared_error: 2.5202 - val_loss: 5.4816 - val_root_mean_squared_error: 2.3413\n",
      "Epoch 7/30\n",
      "81/81 [==============================] - 6s 71ms/step - loss: 6.2482 - root_mean_squared_error: 2.4996 - val_loss: 5.4737 - val_root_mean_squared_error: 2.3396\n",
      "Epoch 8/30\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 6.3064 - root_mean_squared_error: 2.5112 - val_loss: 5.6623 - val_root_mean_squared_error: 2.3796\n",
      "Epoch 9/30\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 6.2221 - root_mean_squared_error: 2.4944 - val_loss: 6.4881 - val_root_mean_squared_error: 2.5472\n",
      "Epoch 10/30\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 6.3480 - root_mean_squared_error: 2.5195 - val_loss: 5.5444 - val_root_mean_squared_error: 2.3547\n",
      "Epoch 11/30\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 6.3432 - root_mean_squared_error: 2.5186 - val_loss: 5.7518 - val_root_mean_squared_error: 2.3983\n",
      "Epoch 12/30\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 6.2223 - root_mean_squared_error: 2.4945 - val_loss: 5.3793 - val_root_mean_squared_error: 2.3193\n",
      "Epoch 13/30\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 6.2339 - root_mean_squared_error: 2.4968 - val_loss: 5.2046 - val_root_mean_squared_error: 2.2814\n",
      "Epoch 14/30\n",
      "81/81 [==============================] - 5s 66ms/step - loss: 6.4229 - root_mean_squared_error: 2.5343 - val_loss: 6.1168 - val_root_mean_squared_error: 2.4732\n",
      "Epoch 15/30\n",
      "81/81 [==============================] - 5s 66ms/step - loss: 6.3362 - root_mean_squared_error: 2.5172 - val_loss: 5.3631 - val_root_mean_squared_error: 2.3158\n",
      "Epoch 16/30\n",
      "81/81 [==============================] - 5s 65ms/step - loss: 6.2570 - root_mean_squared_error: 2.5014 - val_loss: 6.1273 - val_root_mean_squared_error: 2.4753\n",
      "Epoch 17/30\n",
      "81/81 [==============================] - 5s 67ms/step - loss: 6.5122 - root_mean_squared_error: 2.5519 - val_loss: 5.5086 - val_root_mean_squared_error: 2.3470\n",
      "Epoch 18/30\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 6.3817 - root_mean_squared_error: 2.5262 - val_loss: 5.3839 - val_root_mean_squared_error: 2.3203\n",
      "Epoch 19/30\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 6.4414 - root_mean_squared_error: 2.5380 - val_loss: 5.6313 - val_root_mean_squared_error: 2.3730\n",
      "Epoch 20/30\n",
      "81/81 [==============================] - 5s 58ms/step - loss: 6.1987 - root_mean_squared_error: 2.4897 - val_loss: 5.3989 - val_root_mean_squared_error: 2.3235\n",
      "Epoch 21/30\n",
      "81/81 [==============================] - 5s 66ms/step - loss: 6.2033 - root_mean_squared_error: 2.4906 - val_loss: 5.3444 - val_root_mean_squared_error: 2.3118\n",
      "Epoch 22/30\n",
      "81/81 [==============================] - 5s 66ms/step - loss: 6.3063 - root_mean_squared_error: 2.5112 - val_loss: 5.3181 - val_root_mean_squared_error: 2.3061\n",
      "Epoch 23/30\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 6.3211 - root_mean_squared_error: 2.5142 - val_loss: 5.3939 - val_root_mean_squared_error: 2.3225\n",
      "Epoch 24/30\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 6.2698 - root_mean_squared_error: 2.5040 - val_loss: 5.3772 - val_root_mean_squared_error: 2.3189\n",
      "Epoch 25/30\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 6.3024 - root_mean_squared_error: 2.5105 - val_loss: 5.2055 - val_root_mean_squared_error: 2.2816\n",
      "Epoch 26/30\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 6.3206 - root_mean_squared_error: 2.5141 - val_loss: 5.4578 - val_root_mean_squared_error: 2.3362\n",
      "Epoch 27/30\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 6.2495 - root_mean_squared_error: 2.4999 - val_loss: 5.8312 - val_root_mean_squared_error: 2.4148\n",
      "Epoch 28/30\n",
      "81/81 [==============================] - 6s 71ms/step - loss: 6.2611 - root_mean_squared_error: 2.5022 - val_loss: 5.8248 - val_root_mean_squared_error: 2.4135\n",
      "Epoch 29/30\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 6.2430 - root_mean_squared_error: 2.4986 - val_loss: 5.3067 - val_root_mean_squared_error: 2.3036\n",
      "Epoch 30/30\n",
      "81/81 [==============================] - 6s 71ms/step - loss: 6.2181 - root_mean_squared_error: 2.4936 - val_loss: 5.4888 - val_root_mean_squared_error: 2.3428\n",
      "627/627 [==============================] - 2s 3ms/step - loss: 5.9210 - root_mean_squared_error: 2.4333\n",
      "\n",
      "training time 157.804097\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 5.921018600463867 with RMSE metric of 2.433314323425293\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 5.2115 - root_mean_squared_error: 2.2829\n",
      "Test set has a loss (MSE) of 5.211548328399658 with RMSE metric of 2.282881498336792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    ## Simple RNN Model w Features\n",
    "    ## Initialize\n",
    "    model_name = 'SimpleRNN w Features and optimized'\n",
    "    num_layers = 3\n",
    "    epochs_num = 30\n",
    "    batch_size_set = 200\n",
    "    optimizer_set = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    forecast_distance=6\n",
    "    number_readings=8\n",
    "\n",
    "    ## Get New Data\n",
    "    a=DataSampling(path=path)\n",
    "    a.samplingDF\n",
    "    X_train,X_test,y_train,y_test = a.SampleValidSequencesMulti(num_clients=4, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "\n",
    "    #SETUP THE STACK\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(SimpleRNN(150, activation='tanh', input_shape=(number_readings,2)))\n",
    "    model_rnn.add(Dropout(0.1))\n",
    "    #model_rnn.add(Dense(20))\n",
    "    model_rnn.add(Dense(10))\n",
    "    model_rnn.add(Dense(1))\n",
    "    #START THE RUN\n",
    "    print('\\nRunning RNN model...')\n",
    "    start = datetime.now()\n",
    "\n",
    "    model_rnn.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    hist = model_rnn.fit(X_train, y_train, epochs=epochs_num, validation_split=0.2, batch_size=batch_size_set)\n",
    "    train_loss, train_rmse = model_rnn.evaluate(X_train, y_train)\n",
    "    train_time = (datetime.now()-start).total_seconds()\n",
    "    print(\"\\ntraining time %s\" % train_time)\n",
    "\n",
    "    #PRINT RESULTS\n",
    "    print(f'RNN Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "    #Test set results\n",
    "    test_loss, test_rmse = model_rnn.evaluate(X_test, y_test)\n",
    "    print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "\n",
    "    #y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "    Execution_time.append(train_time)\n",
    "    train_rmse_results.append(train_rmse)\n",
    "    test_rmse_results.append(test_rmse)\n",
    "    run_id.append(model_name+str(datetime.now()))\n",
    "    sample_size.append(len(X_train))\n",
    "    epochs.append(epochs_num)\n",
    "    batch_size.append(batch_size_set)\n",
    "    optimizer.append(optimizer_set)\n",
    "    layers.append(num_layers)\n",
    "    forecast_distance_perf.append(forecast_distance)\n",
    "    prev_readings.append(number_readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(list(zip(Execution_time,train_rmse_results,test_rmse_results,run_id,sample_size,epochs,batch_size,optimizer,layers,forecast_distance_perf,\n",
    "prev_readings))\n",
    "    ,columns=['Execution_time','train_rmse_results','test_rmse_results','run_id','sample_size','epochs','batch_size','optimizer','layers','forecast_distance_perf',\n",
    "'prev_readings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Execution_time</th>\n",
       "      <th>train_rmse_results</th>\n",
       "      <th>test_rmse_results</th>\n",
       "      <th>run_id</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>layers</th>\n",
       "      <th>forecast_distance_perf</th>\n",
       "      <th>prev_readings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.953812</td>\n",
       "      <td>2.445894</td>\n",
       "      <td>2.670892</td>\n",
       "      <td>SimpleRNN optimized - personal 60 mins2022-08-...</td>\n",
       "      <td>7214</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.796242</td>\n",
       "      <td>2.703823</td>\n",
       "      <td>2.898907</td>\n",
       "      <td>SimpleRNN optimized - personal 60 mins2022-08-...</td>\n",
       "      <td>3747</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.703608</td>\n",
       "      <td>2.630223</td>\n",
       "      <td>2.363475</td>\n",
       "      <td>SimpleRNN optimized - personal 60 mins2022-08-...</td>\n",
       "      <td>2849</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.514791</td>\n",
       "      <td>2.616661</td>\n",
       "      <td>2.908566</td>\n",
       "      <td>SimpleRNN optimized - personal 60 mins2022-08-...</td>\n",
       "      <td>9809</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.778340</td>\n",
       "      <td>2.109617</td>\n",
       "      <td>2.645050</td>\n",
       "      <td>SimpleRNN optimized - personal 60 mins2022-08-...</td>\n",
       "      <td>1308</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106.816886</td>\n",
       "      <td>3.576433</td>\n",
       "      <td>3.521194</td>\n",
       "      <td>GRU w Optimized Params - personal 60 mins2022-...</td>\n",
       "      <td>12002</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.763534</td>\n",
       "      <td>2.470583</td>\n",
       "      <td>2.422383</td>\n",
       "      <td>GRU w Optimized Params - personal 60 mins2022-...</td>\n",
       "      <td>3094</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201.645284</td>\n",
       "      <td>2.387519</td>\n",
       "      <td>2.311772</td>\n",
       "      <td>GRU w Optimized Params - personal 60 mins2022-...</td>\n",
       "      <td>23251</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73.753674</td>\n",
       "      <td>2.493054</td>\n",
       "      <td>2.622719</td>\n",
       "      <td>GRU w Optimized Params - personal 60 mins2022-...</td>\n",
       "      <td>7600</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.464484</td>\n",
       "      <td>3.936814</td>\n",
       "      <td>4.247368</td>\n",
       "      <td>GRU w Optimized Params - personal 60 mins2022-...</td>\n",
       "      <td>4936</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>56.309241</td>\n",
       "      <td>3.075510</td>\n",
       "      <td>2.788577</td>\n",
       "      <td>SimpleRNN optimized - 60 mins2022-08-16 11:28:...</td>\n",
       "      <td>8764</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>99.650129</td>\n",
       "      <td>2.900796</td>\n",
       "      <td>3.047188</td>\n",
       "      <td>SimpleRNN optimized - 60 mins2022-08-16 11:29:...</td>\n",
       "      <td>13075</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>154.134169</td>\n",
       "      <td>3.149640</td>\n",
       "      <td>3.437407</td>\n",
       "      <td>SimpleRNN optimized - 60 mins2022-08-16 11:32:...</td>\n",
       "      <td>14452</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>142.024550</td>\n",
       "      <td>2.303403</td>\n",
       "      <td>2.405577</td>\n",
       "      <td>SimpleRNN optimized - 60 mins2022-08-16 11:35:...</td>\n",
       "      <td>18804</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>61.432781</td>\n",
       "      <td>2.359656</td>\n",
       "      <td>2.364169</td>\n",
       "      <td>SimpleRNN optimized - 60 mins2022-08-16 11:36:...</td>\n",
       "      <td>8916</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>175.085271</td>\n",
       "      <td>2.771837</td>\n",
       "      <td>2.794632</td>\n",
       "      <td>GRU w Optimized Params - 60 mins2022-08-16 11:...</td>\n",
       "      <td>21222</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>167.871598</td>\n",
       "      <td>2.311182</td>\n",
       "      <td>2.550949</td>\n",
       "      <td>GRU w Optimized Params - 60 mins2022-08-16 11:...</td>\n",
       "      <td>20797</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>238.902720</td>\n",
       "      <td>2.985069</td>\n",
       "      <td>3.205786</td>\n",
       "      <td>GRU w Optimized Params - 60 mins2022-08-16 11:...</td>\n",
       "      <td>26948</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>339.243854</td>\n",
       "      <td>3.165688</td>\n",
       "      <td>3.228429</td>\n",
       "      <td>GRU w Optimized Params - 60 mins2022-08-16 11:...</td>\n",
       "      <td>38133</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>166.275210</td>\n",
       "      <td>3.613153</td>\n",
       "      <td>3.510429</td>\n",
       "      <td>GRU w Optimized Params - 60 mins2022-08-16 11:...</td>\n",
       "      <td>18763</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Execution_time  train_rmse_results  test_rmse_results  \\\n",
       "0        43.953812            2.445894           2.670892   \n",
       "1        23.796242            2.703823           2.898907   \n",
       "2        21.703608            2.630223           2.363475   \n",
       "3        70.514791            2.616661           2.908566   \n",
       "4        11.778340            2.109617           2.645050   \n",
       "5       106.816886            3.576433           3.521194   \n",
       "6        30.763534            2.470583           2.422383   \n",
       "7       201.645284            2.387519           2.311772   \n",
       "8        73.753674            2.493054           2.622719   \n",
       "9        48.464484            3.936814           4.247368   \n",
       "10       56.309241            3.075510           2.788577   \n",
       "11       99.650129            2.900796           3.047188   \n",
       "12      154.134169            3.149640           3.437407   \n",
       "13      142.024550            2.303403           2.405577   \n",
       "14       61.432781            2.359656           2.364169   \n",
       "15      175.085271            2.771837           2.794632   \n",
       "16      167.871598            2.311182           2.550949   \n",
       "17      238.902720            2.985069           3.205786   \n",
       "18      339.243854            3.165688           3.228429   \n",
       "19      166.275210            3.613153           3.510429   \n",
       "\n",
       "                                               run_id  sample_size  epochs  \\\n",
       "0   SimpleRNN optimized - personal 60 mins2022-08-...         7214      30   \n",
       "1   SimpleRNN optimized - personal 60 mins2022-08-...         3747      30   \n",
       "2   SimpleRNN optimized - personal 60 mins2022-08-...         2849      30   \n",
       "3   SimpleRNN optimized - personal 60 mins2022-08-...         9809      30   \n",
       "4   SimpleRNN optimized - personal 60 mins2022-08-...         1308      30   \n",
       "5   GRU w Optimized Params - personal 60 mins2022-...        12002      30   \n",
       "6   GRU w Optimized Params - personal 60 mins2022-...         3094      30   \n",
       "7   GRU w Optimized Params - personal 60 mins2022-...        23251      30   \n",
       "8   GRU w Optimized Params - personal 60 mins2022-...         7600      30   \n",
       "9   GRU w Optimized Params - personal 60 mins2022-...         4936      30   \n",
       "10  SimpleRNN optimized - 60 mins2022-08-16 11:28:...         8764      30   \n",
       "11  SimpleRNN optimized - 60 mins2022-08-16 11:29:...        13075      30   \n",
       "12  SimpleRNN optimized - 60 mins2022-08-16 11:32:...        14452      30   \n",
       "13  SimpleRNN optimized - 60 mins2022-08-16 11:35:...        18804      30   \n",
       "14  SimpleRNN optimized - 60 mins2022-08-16 11:36:...         8916      30   \n",
       "15  GRU w Optimized Params - 60 mins2022-08-16 11:...        21222      30   \n",
       "16  GRU w Optimized Params - 60 mins2022-08-16 11:...        20797      30   \n",
       "17  GRU w Optimized Params - 60 mins2022-08-16 11:...        26948      30   \n",
       "18  GRU w Optimized Params - 60 mins2022-08-16 11:...        38133      30   \n",
       "19  GRU w Optimized Params - 60 mins2022-08-16 11:...        18763      30   \n",
       "\n",
       "    batch_size                                          optimizer  layers  \\\n",
       "0          200  <keras.optimizer_v2.adam.Adam object at 0x0000...       3   \n",
       "1          200  <keras.optimizer_v2.adam.Adam object at 0x0000...       3   \n",
       "2          200  <keras.optimizer_v2.adam.Adam object at 0x0000...       3   \n",
       "3          200  <keras.optimizer_v2.adam.Adam object at 0x0000...       3   \n",
       "4          200  <keras.optimizer_v2.adam.Adam object at 0x0000...       3   \n",
       "5          200  <keras.optimizer_v2.adam.Adam object at 0x0000...       4   \n",
       "6          200  <keras.optimizer_v2.adam.Adam object at 0x0000...       4   \n",
       "7          200  <keras.optimizer_v2.adam.Adam object at 0x0000...       4   \n",
       "8          200  <keras.optimizer_v2.adam.Adam object at 0x0000...       4   \n",
       "9          200  <keras.optimizer_v2.adam.Adam object at 0x0000...       4   \n",
       "10         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       3   \n",
       "11         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       3   \n",
       "12         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       3   \n",
       "13         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       3   \n",
       "14         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       3   \n",
       "15         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       4   \n",
       "16         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       4   \n",
       "17         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       4   \n",
       "18         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       4   \n",
       "19         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       4   \n",
       "\n",
       "    forecast_distance_perf  prev_readings  \n",
       "0                       12              8  \n",
       "1                       12              8  \n",
       "2                       12              8  \n",
       "3                       12              8  \n",
       "4                       12              8  \n",
       "5                       12              8  \n",
       "6                       12              8  \n",
       "7                       12              8  \n",
       "8                       12              8  \n",
       "9                       12              8  \n",
       "10                      12              8  \n",
       "11                      12              8  \n",
       "12                      12              8  \n",
       "13                      12              8  \n",
       "14                      12              8  \n",
       "15                      12              8  \n",
       "16                      12              8  \n",
       "17                      12              8  \n",
       "18                      12              8  \n",
       "19                      12              8  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(neurons=150, activation='relu',dropout_rate=0.1):\n",
    "    ## Simple RNN Model\n",
    "    ## Initialize\n",
    "    model_name = 'SimpleRNN - Personal'\n",
    "    optimizer_set = tf.keras.optimizers.Adam(learning_rate=0.01) #momentum - 0.9?\n",
    "    forecast_distance=6\n",
    "    number_readings=8\n",
    "\n",
    "    ## Get New Data\n",
    "    a=DataSampling(path=path)\n",
    "    a.samplingDF\n",
    "\n",
    "\n",
    "    #SETUP THE STACK\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(SimpleRNN(neurons, activation=activation, input_shape=(number_readings,1)))\n",
    "    model_rnn.add(Dropout(dropout_rate))\n",
    "    model_rnn.add(Dense(10))\n",
    "    model_rnn.add(Dense(1))\n",
    "\n",
    "    \n",
    "    model_rnn.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model_rnn\n",
    "\n",
    "a=DataSampling(path=path)\n",
    "a.samplingDF\n",
    "X_train,X_test,y_train,y_test = a.SampleValidSequences(num_clients=2, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "kModel=KerasRegressor(model=buildModel, verbose=0) ##epochs 30 for final\n",
    "\n",
    "#epochs=10,batch_size=200,\n",
    "\n",
    "epochs=[15,30,45] #30\n",
    "batch_size=[100,150,200] #200\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3] #0.01\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9] ##NA\n",
    "activation_set=['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'] #tanh,relu.softsign\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] #0.1 or 0.2\n",
    "neurons = [50, 100, 150, 200, 250] #150 or 200\n",
    "## Activation function / Number Neurons / Optimizer\n",
    "\n",
    "param_grid = dict(epochs=epochs,batch_size=batch_size)\n",
    "#param_grid = dict(epochs=epochs,batch_size=batch_size)\n",
    "#param_grid = dict(model__activation=activation_set)\n",
    "#param_grid = dict(model__dropout_rate=dropout_rate)\n",
    "#param_grid = dict(model__neurons=neurons)\n",
    "grid = GridSearchCV(estimator=kModel, param_grid=param_grid, n_jobs=-1, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_result = grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "35/35 [==============================] - 11s 193ms/step - loss: 44.5103 - root_mean_squared_error: 6.6716\n",
      "Epoch 2/15\n",
      "35/35 [==============================] - 7s 197ms/step - loss: 10.4126 - root_mean_squared_error: 3.2269\n",
      "Epoch 3/15\n",
      "35/35 [==============================] - 7s 189ms/step - loss: 6.8943 - root_mean_squared_error: 2.6257\n",
      "Epoch 4/15\n",
      "35/35 [==============================] - 7s 198ms/step - loss: 6.6842 - root_mean_squared_error: 2.5854\n",
      "Epoch 5/15\n",
      "35/35 [==============================] - 7s 191ms/step - loss: 6.6450 - root_mean_squared_error: 2.5778\n",
      "Epoch 6/15\n",
      "35/35 [==============================] - 9s 253ms/step - loss: 6.4227 - root_mean_squared_error: 2.5343\n",
      "Epoch 7/15\n",
      "35/35 [==============================] - 8s 227ms/step - loss: 6.4647 - root_mean_squared_error: 2.5426\n",
      "Epoch 8/15\n",
      "35/35 [==============================] - 7s 189ms/step - loss: 6.2003 - root_mean_squared_error: 2.4900\n",
      "Epoch 9/15\n",
      "35/35 [==============================] - 7s 193ms/step - loss: 6.3078 - root_mean_squared_error: 2.5115\n",
      "Epoch 10/15\n",
      "35/35 [==============================] - 7s 194ms/step - loss: 6.0263 - root_mean_squared_error: 2.4549\n",
      "Epoch 11/15\n",
      "35/35 [==============================] - 7s 193ms/step - loss: 6.1065 - root_mean_squared_error: 2.4711\n",
      "Epoch 12/15\n",
      "35/35 [==============================] - 7s 201ms/step - loss: 6.0047 - root_mean_squared_error: 2.4504\n",
      "Epoch 13/15\n",
      "35/35 [==============================] - 7s 189ms/step - loss: 6.2032 - root_mean_squared_error: 2.4906\n",
      "Epoch 14/15\n",
      "35/35 [==============================] - 7s 190ms/step - loss: 6.1638 - root_mean_squared_error: 2.4827\n",
      "Epoch 15/15\n",
      "35/35 [==============================] - 7s 199ms/step - loss: 6.0185 - root_mean_squared_error: 2.4533\n"
     ]
    }
   ],
   "source": [
    "def buildModelGRU(neurons=150, activation='tanh',dropout_rate=0.1):\n",
    "    ## Simple RNN Model\n",
    "    ## Initialize\n",
    "    model_name = 'GRU'\n",
    "    optimizer_set = tf.keras.optimizers.Adam(learning_rate=0.01) #momentum - 0.9?\n",
    "    forecast_distance=6\n",
    "    number_readings=8\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #SETUP THE STACK\n",
    "    model_gru = Sequential()\n",
    "    model_gru.add(GRU(neurons, activation=activation, input_shape=(number_readings,1), return_sequences=True))\n",
    "    model_gru.add(Dropout(dropout_rate))\n",
    "    model_gru.add(GRU(20, activation=activation))\n",
    "    model_gru.add(Dense(10))\n",
    "    model_gru.add(Dense(1))\n",
    "\n",
    "    \n",
    "    model_gru.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model_gru\n",
    "\n",
    "a=DataSampling(path=path)\n",
    "a.samplingDF\n",
    "X_train,X_test,y_train,y_test = a.SampleValidSequences(num_clients=1, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "kModel=KerasRegressor(model=buildModelGRU, verbose=1, epochs=15, batch_size=200) ##epochs 30 for final\n",
    "\n",
    "#epochs=10,batch_size=200,\n",
    "\n",
    "epochs=[30,45] #45\n",
    "batch_size=[200] #200\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3] #0.01\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9] ##NA\n",
    "activation_set=['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'] #tanh,relu.softsign\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.8] #0.1 or 0.2\n",
    "neurons = [50, 100, 150, 200] #150\n",
    "## Activation function / Number Neurons / Optimizer\n",
    "\n",
    "#param_grid = dict(epochs=epochs,batch_size=batch_size)\n",
    "#param_grid = dict(epochs=epochs,batch_size=batch_size)\n",
    "#param_grid = dict(model__activation=activation_set) #tanh\n",
    "param_grid = dict(model__dropout_rate=dropout_rate)\n",
    "#param_grid = dict(model__neurons=neurons)\n",
    "grid = GridSearchCV(estimator=kModel, param_grid=param_grid, n_jobs=-1, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_result = grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -6.230892 using {'model__dropout_rate': 0.1}\n",
      "-6.654261 (1.184336) with: {'model__dropout_rate': 0.0}\n",
      "-6.230892 (0.744142) with: {'model__dropout_rate': 0.1}\n",
      "-6.410074 (0.359668) with: {'model__dropout_rate': 0.2}\n",
      "-6.330997 (0.742406) with: {'model__dropout_rate': 0.3}\n",
      "-7.222174 (1.237266) with: {'model__dropout_rate': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='metrics_full.csv'\n",
    "metrics_file = os.path.join(path, filename)\n",
    "## Load all previously generate metrics\n",
    "all_history = pd.read_csv(metrics_file)\n",
    "all_history.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "## Concatenate all metrics\n",
    "full_metrics=pd.concat([all_history,metrics_df])\n",
    "full_metrics.to_csv(metrics_file)\n",
    "## Write complete DF back to original File\n",
    "#drop recorded results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "y_pred = model_gru.predict(X_test)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(range(len(y_pred[:300])),y_pred[:300], label='Prediction')\n",
    "plt.plot(y_test[:300], label='Actual')\n",
    "plt.xlabel('Time Series')\n",
    "plt.ylabel('Readings')\n",
    "plt.title('GRU Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charting and Results Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Execution_time</th>\n",
       "      <th>train_rmse_results</th>\n",
       "      <th>test_rmse_results</th>\n",
       "      <th>run_id</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>layers</th>\n",
       "      <th>forecast_distance_perf</th>\n",
       "      <th>prev_readings</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Personalised</th>\n",
       "      <th>Feature Engineered</th>\n",
       "      <th>Optimized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.817503</td>\n",
       "      <td>1.704730</td>\n",
       "      <td>1.759134</td>\n",
       "      <td>SimpleRNN2022-08-01 20:20:30.807480</td>\n",
       "      <td>54981</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.817503</td>\n",
       "      <td>1.704730</td>\n",
       "      <td>1.759134</td>\n",
       "      <td>SimpleRNN2022-08-01 20:20:30.807480</td>\n",
       "      <td>54981</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.681792</td>\n",
       "      <td>3.117003</td>\n",
       "      <td>3.205294</td>\n",
       "      <td>SimpleRNN2022-08-01 22:02:54.578203</td>\n",
       "      <td>24944</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.711645</td>\n",
       "      <td>2.168479</td>\n",
       "      <td>1.977262</td>\n",
       "      <td>SimpleRNN2022-08-01 22:04:24.851465</td>\n",
       "      <td>41414</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.764249</td>\n",
       "      <td>1.772849</td>\n",
       "      <td>1.806986</td>\n",
       "      <td>SimpleRNN2022-08-02 20:26:20.115776</td>\n",
       "      <td>43348</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Execution_time  train_rmse_results  test_rmse_results  \\\n",
       "0      230.817503            1.704730           1.759134   \n",
       "1      230.817503            1.704730           1.759134   \n",
       "2       65.681792            3.117003           3.205294   \n",
       "3       49.711645            2.168479           1.977262   \n",
       "4       49.764249            1.772849           1.806986   \n",
       "\n",
       "                                run_id  sample_size  epochs  batch_size  \\\n",
       "0  SimpleRNN2022-08-01 20:20:30.807480        54981       7          50   \n",
       "1  SimpleRNN2022-08-01 20:20:30.807480        54981       7          50   \n",
       "2  SimpleRNN2022-08-01 22:02:54.578203        24944       8         100   \n",
       "3  SimpleRNN2022-08-01 22:04:24.851465        41414       3         100   \n",
       "4  SimpleRNN2022-08-02 20:26:20.115776        43348      10          25   \n",
       "\n",
       "  optimizer  layers  forecast_distance_perf  prev_readings Model Type  \\\n",
       "0      adam       3                       6              8  SimpleRNN   \n",
       "1      adam       3                       6              8  SimpleRNN   \n",
       "2      adam       3                      12              8  SimpleRNN   \n",
       "3      adam       3                       6              8  SimpleRNN   \n",
       "4      adam       3                       6              6  SimpleRNN   \n",
       "\n",
       "  Personalised Feature Engineered Optimized  \n",
       "0           No                 No        No  \n",
       "1           No                 No        No  \n",
       "2           No                 No        No  \n",
       "3           No                 No        No  \n",
       "4           No                 No        No  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##import the result set\n",
    "\n",
    "filenameData='MRP_Analysis.csv'\n",
    "AnalysisFile= os.path.join(path, filenameData)\n",
    "analysis_DF = pd.read_csv(AnalysisFile)\n",
    "analysis_DF.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "#analysis_DF.reset_index(inplace=True)\n",
    "analysis_DF.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Execution_time</th>\n",
       "      <th>train_rmse_results</th>\n",
       "      <th>test_rmse_results</th>\n",
       "      <th>run_id</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>layers</th>\n",
       "      <th>forecast_distance_perf</th>\n",
       "      <th>prev_readings</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Personalised</th>\n",
       "      <th>Feature Engineered</th>\n",
       "      <th>Optimized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.817503</td>\n",
       "      <td>1.704730</td>\n",
       "      <td>1.759134</td>\n",
       "      <td>SimpleRNN2022-08-01 20:20:30.807480</td>\n",
       "      <td>54981</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.817503</td>\n",
       "      <td>1.704730</td>\n",
       "      <td>1.759134</td>\n",
       "      <td>SimpleRNN2022-08-01 20:20:30.807480</td>\n",
       "      <td>54981</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.711645</td>\n",
       "      <td>2.168479</td>\n",
       "      <td>1.977262</td>\n",
       "      <td>SimpleRNN2022-08-01 22:04:24.851465</td>\n",
       "      <td>41414</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.764249</td>\n",
       "      <td>1.772849</td>\n",
       "      <td>1.806986</td>\n",
       "      <td>SimpleRNN2022-08-02 20:26:20.115776</td>\n",
       "      <td>43348</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.432546</td>\n",
       "      <td>2.154079</td>\n",
       "      <td>2.177157</td>\n",
       "      <td>SimpleRNN2022-08-02 20:29:46.125627</td>\n",
       "      <td>56396</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Execution_time  train_rmse_results  test_rmse_results  \\\n",
       "0      230.817503            1.704730           1.759134   \n",
       "1      230.817503            1.704730           1.759134   \n",
       "3       49.711645            2.168479           1.977262   \n",
       "4       49.764249            1.772849           1.806986   \n",
       "5       17.432546            2.154079           2.177157   \n",
       "\n",
       "                                run_id  sample_size  epochs  batch_size  \\\n",
       "0  SimpleRNN2022-08-01 20:20:30.807480        54981       7          50   \n",
       "1  SimpleRNN2022-08-01 20:20:30.807480        54981       7          50   \n",
       "3  SimpleRNN2022-08-01 22:04:24.851465        41414       3         100   \n",
       "4  SimpleRNN2022-08-02 20:26:20.115776        43348      10          25   \n",
       "5  SimpleRNN2022-08-02 20:29:46.125627        56396       8         100   \n",
       "\n",
       "  optimizer  layers  forecast_distance_perf  prev_readings Model Type  \\\n",
       "0      adam       3                       6              8  SimpleRNN   \n",
       "1      adam       3                       6              8  SimpleRNN   \n",
       "3      adam       3                       6              8  SimpleRNN   \n",
       "4      adam       3                       6              6  SimpleRNN   \n",
       "5      adam       3                       6              6  SimpleRNN   \n",
       "\n",
       "  Personalised Feature Engineered Optimized  \n",
       "0           No                 No        No  \n",
       "1           No                 No        No  \n",
       "3           No                 No        No  \n",
       "4           No                 No        No  \n",
       "5           No                 No        No  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Filter for initial results\n",
    "initModelsDF = analysis_DF[ (analysis_DF['Optimized']=='No') \n",
    "                            & (analysis_DF['forecast_distance_perf']==6)\n",
    "                            & (analysis_DF['Personalised']=='No')\n",
    "                            & (analysis_DF['Feature Engineered']=='No')\n",
    "                            ]\n",
    "initModelsDF.head()\n",
    "\n",
    "#analysis_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bensa\\AppData\\Local\\Temp\\ipykernel_18096\\398905946.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  initModelsDF.groupby('Model Type')['test_rmse_results','Execution_time'].aggregate(['mean','max','min'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">test_rmse_results</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Execution_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN and RNN</th>\n",
       "      <td>2.018090</td>\n",
       "      <td>2.040774</td>\n",
       "      <td>1.995407</td>\n",
       "      <td>45.021899</td>\n",
       "      <td>57.233281</td>\n",
       "      <td>32.810517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>1.581093</td>\n",
       "      <td>1.749079</td>\n",
       "      <td>1.450752</td>\n",
       "      <td>23.514280</td>\n",
       "      <td>42.203948</td>\n",
       "      <td>10.283791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>2.534181</td>\n",
       "      <td>3.940736</td>\n",
       "      <td>1.664413</td>\n",
       "      <td>92.498006</td>\n",
       "      <td>193.892447</td>\n",
       "      <td>41.534590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleRNN</th>\n",
       "      <td>2.008983</td>\n",
       "      <td>3.086725</td>\n",
       "      <td>1.508259</td>\n",
       "      <td>173.805685</td>\n",
       "      <td>854.531749</td>\n",
       "      <td>11.064166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            test_rmse_results                     Execution_time              \\\n",
       "                         mean       max       min           mean         max   \n",
       "Model Type                                                                     \n",
       "CNN and RNN          2.018090  2.040774  1.995407      45.021899   57.233281   \n",
       "GRU                  1.581093  1.749079  1.450752      23.514280   42.203948   \n",
       "LSTM                 2.534181  3.940736  1.664413      92.498006  193.892447   \n",
       "SimpleRNN            2.008983  3.086725  1.508259     173.805685  854.531749   \n",
       "\n",
       "                        \n",
       "                   min  \n",
       "Model Type              \n",
       "CNN and RNN  32.810517  \n",
       "GRU          10.283791  \n",
       "LSTM         41.534590  \n",
       "SimpleRNN    11.064166  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initModelsDF.groupby('Model Type')['test_rmse_results','Execution_time'].aggregate(['mean','max','min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAHeCAYAAACbqHxCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAm90lEQVR4nO3de3hUhZ248XdICIRciLRRaREEkborj7XAYtEKFn0EtSiUa6KgBVFZCkowBZUi3kCKaNdgRKytkFaootVAtq76wOLjqlBYLwtqqQGRIBcB05ALkMv8/uA4bX5cHDWTifB+/iLnTGa+MyTz5pyZcyYUDofDSJJOeM3iPYAkqWkwCJIkwCBIkgIGQZIEGARJUsAgSJIASIz3AF9HXV0dtbW+a1aSvozmzROOuPwbHYTa2jClpZXxHkOSvlEyM9OOuNxdRpIkwCBIkgIx2WVUW1vLtGnT2Lx5M6FQiLvuuosuXbpE1q9YsYJHHnmExMREBg8ezLBhw9i/fz+5ubns2bOHlJQUZs+eTZs2bWIxniTpCGKyhbBy5UoAlixZwi233MJDDz0UWVddXc2sWbP47W9/S0FBAX/84x/ZvXs3ixcvpkuXLjz11FMMHDiQ/Pz8WIwmSTqKmAThkksu4Z577gHgk08+IT09PbKuuLiY9u3b07p1a5KSkujevTt/+ctfWLduHRdeeCEAvXv35o033ojFaJKko4jZu4wSExOZMmUKL7/8Mg8//HBkeXl5OWlp/3iFOyUlhfLy8nrLU1JS2Ldv3xfeRkJCiIyMVg0/vCSdgGL6ttPZs2dz6623MmzYMIqKimjVqhWpqalUVFRELlNRUUFaWlq95RUVFfW2Ko7Gt51K0pfXqG87ff7553nssccASE5OJhQK0azZoZs644wz2LJlC6WlpRw8eJC1a9fygx/8gG7durFq1SoAXn31Vbp37x6L0SRJRxGKxQfkVFZWctttt7F7925qamoYO3YsVVVVVFZWMnz48Mi7jMLhMIMHD+bqq6+mqqqKKVOm8Omnn9K8eXPmzp1LZmbmMW+nurrWLQRJ+pKOtoUQkyA0FoMgSV+eRypLko7JIEiSAIMgSQoYBEkSYBAkSQGDIEkCDIIkKfCN/sQ0SbGzZs0brF79erzHoKzs7wCkp7eO6xznnXc+PXv2iusMseYWgqQmraysjLKysniPcULwSGVJTVpe3lwAJkyYHOdJjh8eqSxJOiaDIEkCDIIkKWAQJEmAQZAkBQyCJAkwCJKkgEGQJAEGQZIUMAiSJMAgSJICBkGSBBgESVLAIEiSAIMgSQoYBEkSYBAkSQGDIEkCDIIkKWAQJEmAQZAkBQyCJAkwCJKkgEGQJAEGQZIUMAiSJMAgSJICBkGSBBgESVLAIEiSAIMgSQoYBEkSYBAkSQGDIEkCDIIkKWAQJEmAQZAkBQyCJAmAxFhcaXV1Nbfffjvbtm3j4MGDjBs3josvvhiATz/9lJycnMhl33//fSZPnsyIESPo3bs3p59+OgDnnnsukydPjsV4kqQjiEkQCgsLycjIYM6cOZSWljJw4MBIEDIzMykoKADgrbfe4qGHHmLYsGF8/PHHnH322cyfPz8WI0mSvkBMgtC/f3/69esHQDgcJiEh4bDLhMNh7rnnHh544AESEhLYsGEDO3fuZOTIkbRs2ZLbbruNTp06xWI8SdIRxCQIKSkpAJSXlzNx4kRuueWWwy6zYsUKzjzzzMiTfmZmJjfccAOXXXYZa9euJTc3l2efffaYt5OQECIjo1WDzy+p6UhMPPRSp7/rsReTIABs376d8ePHk52dzYABAw5bX1hYyKhRoyJfd+3aNbIl0aNHD3bt2kU4HCYUCh31Nmprw5SWVjb88JKajJqaOgB/1xtQZmbaEZfH5F1Gu3fvZvTo0eTm5jJkyJAjXmb9+vV069Yt8vW8efNYuHAhAB988AFt27Y9ZgwkSQ0rJlsI8+fPp6ysjPz8fPLz8wEYOnQoVVVVDB8+nL1795KamlrvCf+GG24gNzeXVatWkZCQwKxZs2IxmiTpKELhcDgc7yG+qurqWjcjpeNcXt5cACZM8G3oDaVRdxlJkr55DIIkCTAIkqSAQZAkAQZBkhQwCJIkwCBIkgIGQZIEGARJUsAgSJIAgyBJChgESRJgECRJAYMgSQIMgiQpYBAkSYBBkCQFDIIkCTAIkqSAQZAkAQZBkhQwCJIkwCBIkgIGQZIEGARJUsAgSJIAgyBJChgESRJgECRJAYMgSQIMgiQpYBAkSYBBkCQFDIIkCTAIkqSAQZAkAQZBkhQwCJIkwCBIkgIGQZIEGARJUsAgSJIAgyBJChgESRJgECRJAYMgSQIMgiQpYBAkSQAkxuJKq6uruf3229m2bRsHDx5k3LhxXHzxxZH1Tz75JM888wxt2rQB4K677uI73/kOubm57Nmzh5SUFGbPnh1ZL0mKvZgEobCwkIyMDObMmUNpaSkDBw6sF4T169cze/ZsunbtGln2u9/9ji5dujBhwgSKiorIz89n2rRpsRhPknQEMdll1L9/f26++WYAwuEwCQkJ9dZv2LCBBQsWkJWVxWOPPQbAunXruPDCCwHo3bs3b7zxRixGkyQdRUy2EFJSUgAoLy9n4sSJ3HLLLfXWX3HFFWRnZ5OamsrPf/5zVq5cSXl5OWlpaZHv37dv3xfeTkJCiIyMVg0+v6SmIzHx0N+t/q7HXkyCALB9+3bGjx9PdnY2AwYMiCwPh8Nce+21kSf/Pn368N5775GamkpFRQUAFRUVpKenf+Ft1NaGKS2tjM0dkNQk1NTUAfi73oAyM9OOuDwmu4x2797N6NGjyc3NZciQIfXWlZeX85Of/ISKigrC4TCrV6+ma9eudOvWjVWrVgHw6quv0r1791iMJkk6iphsIcyfP5+ysjLy8/PJz88HYOjQoVRVVTF8+HAmTZrEqFGjSEpKolevXvTp04eePXsyZcoUsrKyaN68OXPnzo3FaJKkowiFw+FwvIf4qqqra92MlI5zeXmH/jicMGFynCc5fjTqLiNJ0jePQZAkAQZBkhQwCJIkwCBIkgIGQZIEGARJUsAgSJIAgyBJChgESRJgECRJAYMgSQIMgiQpYBAkSYBBkCQFDIIkCTAIkqSAQZAkAQZBkhQwCJIkwCBIkgIGQZIEGARJUsAgSJIAgyBJChgESRJgECRJAYMgSQIMgiQpYBAkSYBBkCQFDIIkCTAIkqSAQZAkAQZBkhQwCJIkwCBIkgIGQZIEGARJUsAgSJIAgyBJChgESRJgECRJAYMgSQIMgiQpYBAkSYBBkCQFDIIkCYDEhr7C6upqbr/9drZt28bBgwcZN24cF198cWT98uXLWbhwIQkJCXTp0oUZM2bQrFkzBg0aRGpqKgDt2rVj1qxZDT2aJOkYGjwIhYWFZGRkMGfOHEpLSxk4cGAkCPv37+fXv/41y5YtIzk5mZycHFauXMmPfvQjwuEwBQUFDT2OJClKDR6E/v37069fPwDC4TAJCQmRdUlJSSxZsoTk5GQAampqaNGiBR988AFVVVWMHj2ampoacnJyOPfccxt6NEnSMTR4EFJSUgAoLy9n4sSJ3HLLLZF1zZo149vf/jYABQUFVFZWcsEFF7Bx40bGjBnD0KFD+eijjxg7diwvvvgiiYkNPp4k6Shi8oy7fft2xo8fT3Z2NgMGDKi3rq6ujjlz5rB582by8vIIhUJ07NiRDh06RP6dkZHBp59+Stu2bY95OwkJITIyWsXiLkhx9Yc//J6PP94S7zGahG3btgLw6KMPxXmSpqF9+w5cffU1MbnuBg/C7t27GT16NNOnT6dXr16HrZ8+fTpJSUnk5+fTrNmhNzktXbqUjRs3MmPGDHbu3El5eTmZmZlfeFu1tWFKSysb+i5Icbdp02ZKNv+N76Y2j/cocZdGLQDV2zfFeZL421ZeTU1N3dd+3svMTDvi8gYPwvz58ykrKyM/P5/8/HwAhg4dSlVVFV27dmXp0qX06NGDa6+9FoBRo0YxZMgQbrvtNrKysgiFQsycOdPdRTrhfTe1ORPOOTneY6gJyXt3V0yvv8GfdadNm8a0adOOuv6DDz444vK5c+c29CjfCGvWvMHq1a/HdYaysr8DkJ7eOq5zAJx33vn07Hn4lqWk2Iv6wLTy8nIqKip4/vnn+fvf/x7LmdTIysrKKCsri/cYkuIsqi2ESZMmcdFFF/HWW29RV1fHyy+/zCOPPBLr2U4IPXv2ivtfxHl5h7bOJkyYHNc5JMVXVFsIu3bt4qqrrqK4uJi7776bioqKWM8lSWpkUQWhurqal156ic6dO7N3716DIEnHoaiCMHbsWIqKirjxxhspKChg/PjxsZ5LktTIogpCaWkp//Ef/8Gpp57KzTffzMcffxzruSRJjeyYLyovX76cFStWsHr1at58803g0JHGGzduZNSoUY0yoCSpcRwzCBdeeCEnn3wypaWlDB8+HDh0PqLTTjutUYaTJDWeYwZh7969ZGZm8stf/rLe8spKTxchScebYwZh+vTphEIhwuFwveWhUIhFixbFdDBJUuM6ZhD8wBpJOnFEdaRy3759CYVCka/T0tJ4/vnnYzWTJCkOogrCiy++CBz6BLT169dHvpYkHT+iOg4hKSmJpKQkWrRoQffu3XnvvfdiPZckqZFFtYUwd+7cyC6jXbt2RT7YRpJ0/IgqCJ06dYr8+6yzzuLCCy+M2UCSpPiIKgj9+vWjrKyMhIQEnn76ab7//e+Tlnbkj2CTJH0zRbXvZ+LEiWzYsIE5c+bQvHlzpk+fHuu5JEmNLKog7N+/n759+7Jjxw5uuOEGamtrYz2XJKmRRf15CAsXLuTss8/mww8/pKqqKtZzSZIaWVRBmDJlCrt27WLcuHG8+eab3HHHHbGeS5LUyKJ6Ublbt27s37+fP//5z/To0YOOHTvGei5JUiOLKggPPvggO3bsoLi4mKSkJBYsWMCDDz4Y69kkSY0oql1G69at41e/+hWtWrVi0KBBlJSUxHouSVIjiyoItbW1HDhwgFAoRG1trUcqS9JxKKpdRtdddx0//elP2bt3L0OHDuVnP/tZrOeSJDWyqIKQkZHBU089xZYtW2jXrh1t2rSJ9VySpEYW1b6fvLw8WrduzTnnnGMMJOk4FdUWQigUYvz48XTs2DHy+kFOTk5MB5MkNa6ogjB48OAjLj948CBJSUkNOpAkKT6iCsKgQYOOuPz6669n0aJFDTqQJCk+vtb7R8PhcEPNIUmKs68VhM8/RU2S9M3nEWaSJMBdRpKkwNcKQufOnRtqDklSnEX1LqONGzcyY8YMysrKuPLKKznzzDP58Y9/zJ133hnr+SRJjSSqLYT77ruPWbNmcdJJJzFkyBDy8vJiPZckqZFFvcuoQ4cOhEIh2rRpQ0pKSixnkiTFQVRBaN26NUuWLKGqqoqioiLS09NjPZckqZFFFYSZM2dSUlLCSSedxPr167nvvvtiPZckqZFF9aJyamoqN954I6FQiFdeecUD0iTpOBRVECZNmsRFF13EW2+9RV1dHS+//DKPPPJIrGeTJDWiqHYZ7dq1i6uuuori4mLuvvtuKioqYj2XJKmRRRWE6upqXnrpJTp37szevXsNgiQdh6IKwvXXX09RURE33ngjBQUF/Pu//3us55IkNbKoXkO49NJLOf/88zlw4ADXXHNNrGeSJMVBVEGYMmUK69atIy0tjXA4TCgU4k9/+lOsZ5MkNaKogrBp0yZeeeWVWM8iSYqjqIJwzjnnsGnTJjp16hTVlVZXV3P77bezbds2Dh48yLhx47j44osj61esWMEjjzxCYmIigwcPZtiwYezfv5/c3Fz27NlDSkoKs2fPpk2bNl/tXkmSvrSoD0wbMmQIrVq1iix77bXXjnr5wsJCMjIymDNnDqWlpQwcODAShOrqambNmsXSpUtJTk4mKyuLvn37smzZMrp06cKECRMoKioiPz+fadOmfc27J0mKVlRBWL16NWvWrCExMaqL079/f/r16wcc+hCdhISEyLri4mLat29P69atAejevTt/+ctfWLduHddffz0AvXv3Jj8//0vdEUnS1xPVM3yHDh3Ys2cPp5xySlRX+vnZUMvLy5k4cSK33HJLZF15eTlpaWn1LlteXl5veUpKCvv27fvC20lICJGR0eoLL6djS0w89O5jH8umIzGxGdXxHkJNUmJis5j9rkYVhLfeeou+ffty0kknRZYda5cRwPbt2xk/fjzZ2dkMGDAgsjw1NbXegW0VFRWkpaXVW15RURHVGVVra8OUllZGcxd0DDU1dQA+lk3I5/8n0v+vpqbua/+uZmamHXF5VEG466676NWrV9Q3tnv3bkaPHs306dMP+74zzjiDLVu2UFpaSqtWrVi7di1jxozhk08+YdWqVZxzzjm8+uqrdO/ePerbkyR9fVEFYd68eV8qCPPnz6esrIz8/PzIawFDhw6lqqqK4cOHM3XqVMaMGUM4HGbw4MGccsopZGVlMWXKFLKysmjevDlz5879avdIkvSVRBWEUCjE+PHj6dixI82aHdrfnJOTc9TLT5s27ZjvEOrbty99+/attyw5OZmHH344mnEkSTEQVRAGDx58xOUHDx4kKSmpQQeSJMVHVEEYNGjQEZdff/31LFq0qEEHkiTFR1RnOz2acDjcUHNIkuLsawXBj9KUpONHdIceS2pUZWVllJVXk/furniPoiZkW3k16S3KYnb97jKSJAFRbiHs2LGDU089NfL152c+7dy5c8wGk05k6enppB3Yy4RzTo73KGpC8t7dRSiKszh8VccMwsaNG9m5cycPPPAAubm5ANTW1vLggw/ywgsvcOedd8ZsMElS4zpmEMrKyvjP//xP9uzZQ1FREXDoheTs7OxGGU6S1HiOGYQePXrQo0cPNmzYwNlnnw1AXV1d5GhlSdLxI6rXEIqLi/noo484ePAgc+bMYcyYMYwZMybWs8XUc8/9kW3bSuI9RpNQUrIVgLw8zx8F8N3vtuOnPx0e7zGkRhdVEBYtWsTjjz9OTk4O//3f/83o0aO/8UHYtq2E4i2baN7myKeBPZHUJh06nuTjfZ/GeZL4q977xZ/DIR2vogpCixYtgEMfXJOUlERNTU1Mh2oszduk8a1Lz4v3GGpC9ry0Ot4jSHET1YsB7du3Z/jw4QwePJh58+bxve99L9ZzSZIaWVRbCLNmzaKiooKUlBS6du1KZmZmrOeSJDWyqILwt7/9jTvvvJOysjKuvPJKzjzzTH784x/HejZJUiOKapfRvffey6xZszjppJMYMmQIeXl5sZ5LktTIoj6goEOHDoRCIdq0aUNKSkosZ5IkxUFUQWjdujVLliyhqqqKoqIiWrduHeu5JEmNLKogdOnShW3bttGmTRvWr19PmzZtYj2XJKmRHfNF5WeeeYalS5dSXFzMGWecAcDatWuPm+MQJEn/cMwgXHXVVfTq1YvHHnuMm266CYBmzZrxrW99q1GGkyQ1nmMGISkpiXbt2nHPPfc01jySpDjxtKWSJMAgSJICBkGSBBgESVLAIEiSAIMgSQoYBEkSYBAkSQGDIEkCDIIkKWAQJEmAQZAkBQyCJAkwCJKkgEGQJAEGQZIUMAiSJMAgSJICBkGSBBgESVLAIEiSAIMgSQoYBEkSYBAkSQGDIEkCIDFWV/zOO+/wwAMPUFBQEFn26aefkpOTE/n6/fffZ/LkyYwYMYLevXtz+umnA3DuuecyefLkWI0mSTqCmATh8ccfp7CwkOTk5HrLMzMzI4F46623eOihhxg2bBgff/wxZ599NvPnz4/FOJKkKMRkl1H79u3Jy8s76vpwOMw999zDjBkzSEhIYMOGDezcuZORI0cyduxYNm3aFIuxJEnHEJMthH79+lFSUnLU9StWrODMM8+kU6dOwKEthxtuuIHLLruMtWvXkpuby7PPPvuFt5OQECIjo9VXmjEx0ZdPdGSJic2+8s9VQ85QHdcJ1FTF8uczZq8hHEthYSGjRo2KfN21a1cSEhIA6NGjB7t27SIcDhMKhY55PbW1YUpLK7/SDDU1dV/p+3T8q6mp+8o/Vw05g3QkDfHzmZmZdsTlcfkzef369XTr1i3y9bx581i4cCEAH3zwAW3btv3CGEiSGlajbCEsW7aMyspKhg8fzt69e0lNTa33hH/DDTeQm5vLqlWrSEhIYNasWY0xliTpn8QsCO3atePpp58GYMCAAZHlbdq04YUXXqh32datW7NgwYJYjSJJioKvrEqSAIMgSQoYBEkSYBAkSQGDIEkCDIIkKWAQJEmAQZAkBQyCJAmI08ntmoKysjKqP9vHnpdWx3sUNSHVe/dRFm4R7zGkuHALQZIEnMBbCOnp6ZSGDvCtS8+L9yhqQva8tJr0tPR4jyHFhVsIkiTAIEiSAgZBkgQYBElSwCBIkgCDIEkKGARJEmAQJEmBE/bANKmp21ZeTd67u+I9RtztO1gLQFpSQpwnib9t5dW0y4zd9RsEqQn67nfbxXuEJqOsZCsA6ZmnxXmS+GuXGdufDYMgNUE//enweI/QZOTlzQVgwoTJcZ7k+OdrCJIkwCBIkgIGQZIEGARJUsAgSJIAgyBJChgESRJgECRJAYMgSQIMgiQpYBAkSYBBkCQFDIIkCTjBz3ZavXcfe15aHe8x4q626gAACckt4jxJ/FXv3QdpMTzhvNSEnbBB8Hzz/1Dy90Pnm293sk+EpGX6s6ET1gkbBM83/w+eb14S+BqCJClgECRJgEGQJAUMgiQJMAiSpIBBkCQBBkGSFDAIkiTAIEiSAjELwjvvvMPIkSMPW/7kk09yxRVXMHLkSEaOHMmmTZvYv38/EyZMIDs7m7Fjx7J3795YjSVJOoqYnLri8ccfp7CwkOTk5MPWrV+/ntmzZ9O1a9fIst/97nd06dKFCRMmUFRURH5+PtOmTYvFaJKko4jJFkL79u3Jy8s74roNGzawYMECsrKyeOyxxwBYt24dF154IQC9e/fmjTfeiMVYkqRjiMkWQr9+/SgpKTniuiuuuILs7GxSU1P5+c9/zsqVKykvLyctLQ2AlJQU9u3bF9XtJCSEyMho1WBzn6gSEw/9XeBjqabIn8/G06hnOw2Hw1x77bWRJ/8+ffrw3nvvkZqaSkVFBQAVFRWkp6dHdX21tWFKSytjNu+JoqamDsDHUk2SP58NLzMz7YjLG/VdRuXl5fzkJz+hoqKCcDjM6tWr6dq1K926dWPVqlUAvPrqq3Tv3r0xx5Ik0UhbCMuWLaOyspLhw4czadIkRo0aRVJSEr169aJPnz707NmTKVOmkJWVRfPmzZk7d25jjCVJ+icxC0K7du14+umnARgwYEBk+cCBAxk4cGC9yyYnJ/Pwww/HahRJUhQ8ME2SBBgESVLAIEiSAIMgSQoYBEkSYBAkSQGDIEkCDIIkKWAQJEmAQZAkBQyCJAkwCJKkgEGQJAEGQZIUMAiSJMAgSJICBkGSBBgESVLAIEiSAIMgSQoYBEkSYBAkSQGDIEkCDIIkKWAQJEmAQZAkBQyCJAkwCJKkgEGQJAEGQZIUMAiSJMAgSJICBkGSBBgESVIgMd4DSGqa1qx5g9WrX4/3GJSUbAUgL29uXOc477zz6dmzV1xniDWDIKlJS09Pj/cIJwyDIOmIevbsddz/Raz6fA1BkgQYBElSwCBIkgCDIEkKGARJEmAQJEkBgyBJAgyCJClgECRJgEGQJAUMgiQJiOG5jN555x0eeOABCgoK6i1fvnw5CxcuJCEhgS5dujBjxgyaNWvGoEGDSE1NBaBdu3bMmjUrVqNJko4gJkF4/PHHKSwsJDk5ud7y/fv38+tf/5ply5aRnJxMTk4OK1eu5Ec/+hHhcPiweEiSGk9Mdhm1b9+evLy8w5YnJSWxZMmSSChqampo0aIFH3zwAVVVVYwePZpRo0bx9ttvx2IsSdIxxGQLoV+/fpSUlBy2vFmzZnz7298GoKCggMrKSi644AI2btzImDFjGDp0KB999BFjx47lxRdfJDHx2OMlJITIyGgVi7twQklMPPR3gY+ldGJr9M9DqKurY86cOWzevJm8vDxCoRAdO3akQ4cOkX9nZGTw6aef0rZt22NeV21tmNLSykaa/PhVU1MH4GMpnSAyM9OOuLzR32U0ffp0Dhw4QH5+fmTX0dKlS7n//vsB2LlzJ+Xl5WRmZjb2aJJ0QmuULYRly5ZRWVlJ165dWbp0KT169ODaa68FYNSoUQwZMoTbbruNrKwsQqEQM2fO/MLdRZKkhhUKh8PheA/xVVVX17qbowF8/uHlEyZMjvMkkhpDk9llJElqmgyCJAkwCJKkgEGQJAEGQZIUMAiSJMAgSJICBkGSBBgESVLAI5XjbM2aN1i9+vW4zlBSshWAdu1Oi+scAOeddz49e/aK9xjSce1oRyp7wiCRnp4e7xEkNQFuIUjSCcZzGUmSjskgSJIAgyBJChgESRJgECRJAYMgSQIMgiQpYBAkSYBBkCQFDIIkCTAIkqSAQZAkAQZBkhQwCJIkwCBIkgIGQZIEGARJUsAgSJKAb/hHaEqSGo5bCJIkwCBIkgIGQZIEGARJUsAgSJIAgyBJCiTGewDF3tatW5kzZw47duygZcuWtGzZktzcXF588UWWL1/OySefDEBpaSmXX34548aN47nnnmPTpk3ceuutkeuZNGkSI0aM4LzzzovXXVETtGDBAl5//XVqamoIhUJMmTKFF154gZ/97Gd85zvf+UrXOXXqVC6//HJ69+59xPUjR46kqqqK5ORk6urqKCsr49Zbb6VPnz5MnTqV8vJy5s2bF7n8BRdcwP/8z//w3HPPMW/ePAoLC0lNTQX8uf5nBuE4V1VVxbhx47jnnnv4wQ9+AMC7777L3XffTc+ePbnuuuvIysoC4ODBg1x++eUMGzYsniPrG+TDDz9kxYoVLF68mFAoxPvvv8+UKVMoLCyM+W3Pnj2bM844A4BNmzYxceJE+vTpA8C6det4/vnnGThw4GHfV1VVxcyZM5k5c2bMZ/ymcZfRcW7lypX88Ic/jMQA4JxzzmHRokWHXfazzz6jpqaGFi1aNOaI+gZLS0vjk08+YenSpezcuZN/+Zd/YenSpYwcOZLi4mLy8vK49dZbGTNmDIMHD+a5557jpptuol+/frz99tuUlJQwePBgbrrpJgYNGsRDDz1U7/qrq6u5/fbbufrqq8nKymL16tVHnOOTTz4hPT098nVOTg55eXns2LHjsMsOHDiQTZs2sXLlyoZ9MI4DbiEc50pKSmjfvn3k63HjxlFeXs6uXbvo0aMHy5cvp6ioiO3bt3PKKadw7733RjaljyQUCjXG2PqGOOWUU3j00Uf5/e9/zyOPPELLli2ZNGlSvcu0bNmSJ554ggULFrBq1Srmz5/Ps88+S1FREddeey3btm3jiSeeIC0tjezsbDZs2BD53meeeYaTTjqJmTNn8tlnn3HNNddQVFQEwJQpU0hMTOSTTz7h3HPPZdasWfXmuvnmm7njjjt44okn6s2TkJDA/fffz9ixYzn33HNj9+B8AxmE49ypp57K+vXrI18/+uijAAwbNoza2trILqP169eTk5PD6aefDhz6JT548GC966qsrKRly5aNNruavi1btpCamhp5Mv6///s/xo4dS2ZmZuQy//qv/woc2pro3LkzAK1bt+bAgQMAnHXWWWRkZACHtl43b94c+d6NGzeybt063n33XQBqamrYu3cv8I9dRkuWLGH58uW0bdu23mxXXnklr7zyCk899dRhc59++umMGjWKu+66yz9y/om7jI5zF198MW+88QZvv/12ZNmWLVvYsWNHvV+Erl27MnbsWHJycqirq+Oss87i9ddfp6KiAjj0gvPf/va3yD5bCeCvf/0rd999d+SPh44dO5Kenk5CQkLkMl/0hFtcXExVVRW1tbW8++67kWgAdOrUiSuuuIKCggIef/xx+vfvH4nH50aMGEHbtm0P290EMGPGDH77299Gfo7/2TXXXMNnn33Gm2+++WXu8nHNLYTjXEpKCo8++ihz587lgQceoKamhoSEBG677TY+/PDDepcdOnQof/7zn1m8eDFXX3012dnZZGdnk5KSQk1NDXfccQcpKSlxuidqii699FKKi4sZMmQIrVq1IhwO84tf/IKFCxdGfR3Nmzfn5ptvZvfu3fTv35+zzjorsm7EiBFMmzaNa665hvLycrKzs2nW7PC/Y++44w6uvPJKrrrqqnrL27Rpw9SpUxk/fvxh3xMKhZg1axYDBgz4Evf4+ObZTiXFTUlJCTk5OTz99NPxHkW4y0iSFHALQZIEuIUgSQoYBEkSYBAkSQGDoBPK6tWr+d73vhc52vVzAwYMYOrUqVFdx4EDB+jbt+8xb+P/P1r3/vvvZ+TIkfTv35+LLrqIkSNHMnHixC9/B6QY8jgEnXA6depEUVERV1xxBXDo4KqqqqqY3ubnsTnSWWSlpsIg6IRz1llnsXnzZvbt20daWhqFhYUMGDCA7du3A1BYWMjChQtJSkri9NNPjxyJe+utt1JWVlbv3FB//etfuffeewHIyMj4UmfQ3LdvH4MGDeK//uu/SEhIYM6cOZx99tksXryYjh07snnzZsLhMA899BCZmZnMnTuXtWvXUldXx3XXXcdll13WsA+MTnjuMtIJ6dJLL+Wll14iHA7z7rvvRs4G+9lnn5GXl8fChQtZvHgxaWlp/PGPf2TJkiV06dKFP/zhD4wYMSJyPb/85S+58847KSgooHfv3vzmN7+Jeoa0tDS6d+/Oa6+9Rm1tLa+++iqXXHIJAN26daOgoIDLLruMxx57jFWrVlFSUsLixYtZtGgR8+fPp6ysrGEfFJ3w3ELQCWnAgAHMmDGD0047jR49ekSWb926lc6dO0fO+Ppv//ZvvPbaa9TV1UXOtf/973+fxMRDvzrFxcXcddddwKFTNX9+csBoDR06lIKCAurq6jj//PNJSkoC4Ic//CFwKAwrVqzglFNOYcOGDYwcORI4dJK3bdu21Tvls/R1uYWgE9Jpp51GZWUlBQUFXHnllZHl7dq1o7i4mMrKSgDWrFlDx44dOeOMMyInCHzvvfeoqakBDp3Mbfbs2RQUFJCbm8tFF130pebo0aMHW7duZenSpQwZMiSy/PMz1P7v//4vnTt3plOnTpx33nkUFBSwcOFCLrvsMk477bSv8QhIh3MLQSesyy+/nBdeeIGOHTuydetW4NDJ0CZMmMCoUaNo1qwZ7du3j7wA/Itf/IKsrCw6depE8+bNgUNn05wyZUrk4yPvu+8+du3a9aXmGDBgAC+++CJnnnlmZNmf/vQnnnzySZKTk/nVr35FRkYGa9asITs7m8rKSi655JJjfm6F9FV46gopzn7zm9+QkZER2UIYOXIkM2bM8FTjanRuIUhxNHXqVHbt2sX8+fPjPYrkFoIk6RBfVJYkAQZBkhQwCJIkwCBIkgIGQZIEGARJUuD/AVgZ5QE2kIWXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot of Tuned RNN and GRU w optimized parameters and a 30 minute interval\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,8))\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "sns.boxplot(data=analysis_DF[(analysis_DF['Optimized']=='Yes') & (analysis_DF['forecast_distance_perf']==6)], x='Model Type', y='test_rmse_results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7c2045393b2e3298fba416c7980a67b423cc5ff7d51bff314d8a0df9b998066"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7c2045393b2e3298fba416c7980a67b423cc5ff7d51bff314d8a0df9b998066"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
