{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import label\n",
    "from statistics import mode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, SimpleRNN, Dropout, Flatten\n",
    "from datetime import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=DataSampling()\n",
    "a.samplingDF\n",
    "X_train,X_test,y_train,y_test = a.SampleValidSequences(num_clients=3, test_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14772 8364 14772 8364\n"
     ]
    }
   ],
   "source": [
    "print (len(X_train),len(X_test),len(y_train),len(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next -- build out table of metrics and the runner\n",
    "Write the metrics to a CSV for storage\n",
    "Use an init for the first metric build\n",
    "\n",
    "Run a few test runs to see what else we need to record.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment Plans\n",
    "\n",
    "Build out models to compare performance on\n",
    "Look at hyperparameter tuning\n",
    "ONce models are adequately baked, then move to A and B below\n",
    "\n",
    "A Experiment on using different patients inputs and keeping track of metrics\n",
    "B Experiment on using feature engineering and build out metrics further\n",
    "\n",
    "\n",
    "Implement Data cleaning from development to the data helper functions\n",
    "Add in ability to look at a per patient basis\n",
    "Perhaps start with overall data size, and then with a % set to train v test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running RNN model...\n",
      "a\n",
      "b\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 21:34:51.655673: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-26 21:34:52.032159: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - ETA: 0s - loss: 4.8813 - root_mean_squared_error: 2.2094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 21:34:58.608473: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 7s 40ms/step - loss: 4.8813 - root_mean_squared_error: 2.2094 - val_loss: 2.7963 - val_root_mean_squared_error: 1.6722\n",
      "Epoch 2/7\n",
      "119/119 [==============================] - 4s 36ms/step - loss: 2.9894 - root_mean_squared_error: 1.7290 - val_loss: 2.5942 - val_root_mean_squared_error: 1.6106\n",
      "Epoch 3/7\n",
      "119/119 [==============================] - 4s 35ms/step - loss: 2.6580 - root_mean_squared_error: 1.6303 - val_loss: 2.2571 - val_root_mean_squared_error: 1.5024\n",
      "Epoch 4/7\n",
      "119/119 [==============================] - 4s 35ms/step - loss: 2.5426 - root_mean_squared_error: 1.5945 - val_loss: 2.3045 - val_root_mean_squared_error: 1.5181\n",
      "Epoch 5/7\n",
      "119/119 [==============================] - 4s 35ms/step - loss: 2.4903 - root_mean_squared_error: 1.5781 - val_loss: 2.1819 - val_root_mean_squared_error: 1.4771\n",
      "Epoch 6/7\n",
      "119/119 [==============================] - 4s 38ms/step - loss: 2.4612 - root_mean_squared_error: 1.5688 - val_loss: 2.2746 - val_root_mean_squared_error: 1.5082\n",
      "Epoch 7/7\n",
      "119/119 [==============================] - 4s 37ms/step - loss: 2.4723 - root_mean_squared_error: 1.5724 - val_loss: 2.1175 - val_root_mean_squared_error: 1.4552\n",
      "462/462 [==============================] - 4s 9ms/step - loss: 2.3452 - root_mean_squared_error: 1.5314\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 2.345233201980591 with RMSE metric of 1.5314154624938965\n",
      "\n",
      "training time 37.343157\n",
      "262/262 [==============================] - 3s 10ms/step - loss: 2.3389 - root_mean_squared_error: 1.5293\n",
      "Test set has a loss (MSE) of 2.3388512134552 with RMSE metric of 1.5293303728103638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 21:35:31.950188: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#SETUP THE STACK\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(50, activation='relu', input_shape=(8,1)))\n",
    "model_rnn.add(Dense(10))\n",
    "model_rnn.add(Dense(1))\n",
    "#START THE RUN\n",
    "print('\\nRunning RNN model...')\n",
    "start = datetime.now()\n",
    "\n",
    "model_rnn.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "hist = model_rnn.fit(X_train, y_train, epochs=7, validation_split=0.2, batch_size=100)\n",
    "train_loss, train_rmse = model_rnn.evaluate(X_train, y_train)\n",
    "print(\"\\ntraining time %s\" % (datetime.now()-start).total_seconds())\n",
    "\n",
    "#PRINT RESULTS\n",
    "print(f'RNN Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "#Test set results\n",
    "test_loss, test_rmse = model_rnn.evaluate(X_test, y_test)\n",
    "print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "\n",
    "y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "## Record the results\n",
    "Execution_time = []\n",
    "train_rmse = []\n",
    "test_rmse=[]\n",
    "run_id = []\n",
    "sample_size=[]\n",
    "epochs = []\n",
    "batch_size=[]\n",
    "optimizer=[]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def root_mean_error(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.math.squared_difference(y_true, y_pred)))\n",
    "\n",
    "\n",
    "class RunModel:\n",
    "\n",
    "    def __init__(self,X_train, X_test, y_train, y_test):\n",
    "        #self.X_train = (tf.convert_to_tensor(X_train) - tf.math.reduce_min(tf.convert_to_tensor(X_train))) / (tf.math.reduce_max(tf.convert_to_tensor(X_train)) - tf.math.reduce_min(tf.convert_to_tensor(X_train)))\n",
    "        #self.y_train = (tf.convert_to_tensor(y_train) - tf.math.reduce_min(tf.convert_to_tensor(y_train))) / (tf.math.reduce_max(tf.convert_to_tensor(y_train)) - tf.math.reduce_min(tf.convert_to_tensor(y_train)))\n",
    "        #self.X_test = (tf.convert_to_tensor(X_test) - tf.math.reduce_min(tf.convert_to_tensor(X_test))) / (tf.math.reduce_max(tf.convert_to_tensor(X_test)) - tf.math.reduce_min(tf.convert_to_tensor(X_test)))\n",
    "        #self.y_test = (tf.convert_to_tensor(y_test) - tf.math.reduce_min(tf.convert_to_tensor(y_test))) / (tf.math.reduce_max(tf.convert_to_tensor(y_test)) - tf.math.reduce_min(tf.convert_to_tensor(y_test)))\n",
    "        self.X_train = np.array(X_train)\n",
    "        self.y_train = np.array(y_train)\n",
    "        self.X_test = np.array(X_test)\n",
    "        self.y_test = np.array(y_test)\n",
    "        self.metric_df = pd.DataFrame()\n",
    "\n",
    "    def rnn_model(self):\n",
    "        model_rnn = Sequential()\n",
    "        model_rnn.add(SimpleRNN(50, activation='relu', input_shape=(8,1)))\n",
    "        model_rnn.add(Dense(10))\n",
    "        model_rnn.add(Dense(1))\n",
    "        print('\\nRunning RNN model...')\n",
    "        model_rnn.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "        hist = model_rnn.fit(self.X_train, self.y_train, epochs=7, validation_split=0.2, batch_size=100)\n",
    "        \n",
    "        train_loss, train_rmse = model_rnn.evaluate(self.X_train, self.y_train)\n",
    "        print(f'RNN Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "\n",
    "        test_loss, test_rmse = model_rnn.evaluate(self.X_test, self.y_test)\n",
    "        print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "        y_pred = model_rnn.predict(self.X_test)\n",
    "        plt.plot(range(len(y_pred)),y_pred, label='Prediction')\n",
    "        plt.plot(self.y_test, label='Actual')\n",
    "        plt.xlabel('Time Series')\n",
    "        plt.ylabel('Readings')\n",
    "        plt.title('Simple RNN MODEL')\n",
    "        plt.legend()\n",
    "        plt.savefig('Model Fig - SimpleRNN.png')\n",
    "        plt.clf()\n",
    "        model_rnn.summary()\n",
    "        self.metric_df['RNN RMSE'] = hist.history['val_root_mean_squared_error']\n",
    "\n",
    "\n",
    "\n",
    "    def lstm_model(self):\n",
    "        model_lstm = Sequential()\n",
    "        model_lstm.add(LSTM(128, activation='relu', input_shape=(8, 1),return_sequences=True))\n",
    "        model_lstm.add(Dropout(0.3))\n",
    "        model_lstm.add(LSTM(64, activation='relu'))\n",
    "        model_lstm.add(Dropout(0.3))\n",
    "        model_lstm.add(Dense(20, activation='relu'))\n",
    "        model_lstm.add(Dense(10, activation='relu'))\n",
    "        model_lstm.add(Dense(1))\n",
    "        print('\\nRunning the LSTM model...')\n",
    "        model_lstm.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "        hist = model_lstm.fit(self.X_train, self.y_train, epochs=7, validation_split=0.2, batch_size=100)\n",
    "        \n",
    "        train_loss, train_rmse = model_lstm.evaluate(self.X_train, self.y_train)\n",
    "        print(f'LSTM Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "\n",
    "        test_loss, test_rmse = model_lstm.evaluate(self.X_test, self.y_test)\n",
    "        print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "        y_pred = model_lstm.predict(self.X_test)\n",
    "        plt.plot(range(len(y_pred)),y_pred, label='Prediction')\n",
    "        plt.plot(self.y_test, label='Actual')\n",
    "        plt.xlabel('Time Series')\n",
    "        plt.ylabel('Readings')\n",
    "        plt.title('LSTM MODEL')\n",
    "        plt.legend()\n",
    "        plt.savefig('Model Fig - LSTM.png')\n",
    "        plt.clf()\n",
    "        model_lstm.summary()\n",
    "        self.metric_df['LSTM RMSE'] = hist.history['val_root_mean_squared_error']\n",
    "\n",
    "\n",
    "    def gru_model(self):\n",
    "        model_gru = Sequential()\n",
    "        model_gru.add(GRU(50, activation='relu', input_shape=(8,1)))\n",
    "        model_gru.add(Dense(1))\n",
    "        print('\\nRunning GRU model...')\n",
    "        model_gru.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "        hist = model_gru.fit(self.X_train, self.y_train, epochs=7, validation_split=0.2, batch_size=100)\n",
    "        \n",
    "        train_loss, train_rmse = model_gru.evaluate(self.X_train, self.y_train)\n",
    "        print(f'GRU Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "\n",
    "        test_loss, test_rmse = model_gru.evaluate(self.X_test, self.y_test)\n",
    "        print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "        y_pred = model_gru.predict(self.X_test)\n",
    "        plt.plot(range(len(y_pred)),y_pred, label='Prediction')\n",
    "        plt.plot(self.y_test, label='Actual')\n",
    "        plt.xlabel('Time Series')\n",
    "        plt.ylabel('Readings')\n",
    "        plt.title('GRU MODEL')\n",
    "        plt.legend()\n",
    "        plt.savefig('Model Fig - GRU.png')\n",
    "        plt.clf()\n",
    "        model_gru.summary()\n",
    "        self.metric_df['GRU RMSE'] = hist.history['val_root_mean_squared_error']\n",
    "\n",
    "\n",
    "    def cnn_lstm_model(self):\n",
    "        model_cnn_lstm = Sequential()\n",
    "        model_cnn_lstm.add(tf.keras.layers.Conv1D(32, 2, activation='relu', input_shape=(8,1)))\n",
    "        model_cnn_lstm.add(tf.keras.layers.MaxPooling1D((1)))\n",
    "        model_cnn_lstm.add(LSTM(10, activation='relu', return_sequences=True))\n",
    "        model_cnn_lstm.add(Flatten())\n",
    "        model_cnn_lstm.add(Dense(1))\n",
    "        print('\\nRunning the CNN+LSTM model...')\n",
    "        model_cnn_lstm.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "        hist = model_cnn_lstm.fit(self.X_train, self.y_train, epochs=7, validation_split=0.2, batch_size=100)\n",
    "        \n",
    "        train_loss, train_rmse = model_cnn_lstm.evaluate(self.X_train, self.y_train)\n",
    "        print(f'CNN+LSTM Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "\n",
    "        test_loss, test_rmse = model_cnn_lstm.evaluate(self.X_test, self.y_test)\n",
    "        print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "        y_pred = model_cnn_lstm.predict(self.X_test)\n",
    "        print(y_pred.shape)\n",
    "        plt.plot(range(len(y_pred)),y_pred, label='Prediction')\n",
    "        plt.plot(self.y_test, label='Actual')\n",
    "        plt.xlabel('Time Series')\n",
    "        plt.ylabel('Readings')\n",
    "        plt.title('CNN+LSTM MODEL')\n",
    "        plt.legend()\n",
    "        plt.savefig('Model Fig - CNN+LSTM.png')\n",
    "        plt.clf()\n",
    "        model_cnn_lstm.summary()\n",
    "        self.metric_df['CNN+LSTM RMSE'] = hist.history['val_root_mean_squared_error']\n",
    "\n",
    "\n",
    "    def main(self):\n",
    "        self.rnn_model()\n",
    "        self.lstm_model()\n",
    "        self.gru_model()\n",
    "        self.cnn_lstm_model()\n",
    "        self.metric_df.plot(xlabel='Epochs', ylabel='RMSE', legend=True)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def seriesToTimeSeries(self, X, step_length=8,forecast_dist=6):\n",
    "    y=[]\n",
    "    reshapedX = []\n",
    "    for i in range(len(X)-forecast_dist-step_length):\n",
    "        y.append(X[i+step_length+forecast_dist])\n",
    "        reshapedX.append(X[i:i+step_length])\n",
    "    return reshapedX,y\n",
    "\n",
    "def shapeSeriesFromDF(df,indexForSelection):\n",
    "    \n",
    "    an_X = df[df['series_id']==indexForSelection[0]].ValueMMOL.tolist()\n",
    "    an_X, y = seriesToTimeSeries(an_X)\n",
    "    X_=an_X\n",
    "    y_=y\n",
    "\n",
    "    for i in indexForSelection[1:]:\n",
    "        an_X = df[df['series_id']==i].ValueMMOL.tolist()\n",
    "        an_X, y = seriesToTimeSeries(an_X)\n",
    "        \n",
    "        X_ = X_+an_X\n",
    "        y_ = y_+y\n",
    "    return X_,y_\n",
    "\n",
    "\n",
    "\n",
    "def SampleValidSequences(self, num_clients=8, test_split=0.3,seed=1):\n",
    "    samplingDF = self.samplingDF\n",
    "    ## cleaning up the data -- Resetting data types\n",
    "    \n",
    "    random.seed(seed)\n",
    "    \n",
    "    new_df = samplingDF.groupby('series_id').count()\n",
    "    ct_df = samplingDF.groupby('PtID').count()\n",
    "\n",
    "    client_list = ct_df.index.to_numpy()\n",
    "    cl_ind = client_list[random.sample(range(0,len(client_list)),num_clients)] ##clientids to use for the training\n",
    "\n",
    "    cl_df = samplingDF[samplingDF.PtID.isin(cl_ind)] ## list of all samples relative to these clients\n",
    "\n",
    "    series_select = cl_df.groupby('series_id').count()\n",
    "    series_select = series_select.sample(frac=1)\n",
    "    series_select = series_select.index.to_list()\n",
    "\n",
    "    index_cut = int((1-test_split) * len(series_select))\n",
    "    train_index = series_select[0:index_cut]\n",
    "    test_index=series_select[index_cut:]\n",
    "\n",
    "    training_df = samplingDF[samplingDF.series_id.isin(train_index)]\n",
    "    testing_df = samplingDF[samplingDF.series_id.isin(test_index)]\n",
    "\n",
    "    ## build training dataset\n",
    "    X_train,y_train = shapeSeriesFromDF(training_df,train_index)\n",
    "    X_test,y_test = shapeSeriesFromDF(testing_df,test_index)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "seriesToTimeSeries() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/bsw/Documents/MRPLocal/CODE/MRPDeepLearningWithCGM/experiment_development.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bsw/Documents/MRPLocal/CODE/MRPDeepLearningWithCGM/experiment_development.ipynb#ch0000019?line=0'>1</a>\u001b[0m x,y\u001b[39m=\u001b[39mshapeSeriesFromDF(a\u001b[39m.\u001b[39;49msamplingDF,[\u001b[39m1\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m45\u001b[39;49m])\n",
      "\u001b[1;32m/Users/bsw/Documents/MRPLocal/CODE/MRPDeepLearningWithCGM/experiment_development.ipynb Cell 11'\u001b[0m in \u001b[0;36mshapeSeriesFromDF\u001b[0;34m(df, indexForSelection)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bsw/Documents/MRPLocal/CODE/MRPDeepLearningWithCGM/experiment_development.ipynb#ch0000013?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshapeSeriesFromDF\u001b[39m(df,indexForSelection):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bsw/Documents/MRPLocal/CODE/MRPDeepLearningWithCGM/experiment_development.ipynb#ch0000013?line=10'>11</a>\u001b[0m     an_X \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mseries_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39mindexForSelection[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39mValueMMOL\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bsw/Documents/MRPLocal/CODE/MRPDeepLearningWithCGM/experiment_development.ipynb#ch0000013?line=11'>12</a>\u001b[0m     an_X, y \u001b[39m=\u001b[39m seriesToTimeSeries(an_X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bsw/Documents/MRPLocal/CODE/MRPDeepLearningWithCGM/experiment_development.ipynb#ch0000013?line=12'>13</a>\u001b[0m     X_\u001b[39m=\u001b[39man_X\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bsw/Documents/MRPLocal/CODE/MRPDeepLearningWithCGM/experiment_development.ipynb#ch0000013?line=13'>14</a>\u001b[0m     y_\u001b[39m=\u001b[39my\n",
      "\u001b[0;31mTypeError\u001b[0m: seriesToTimeSeries() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "x,y=shapeSeriesFromDF(a.samplingDF,[1,3,45])  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33a4eb190a92b8893ca76062e2d07ed51e6f44f0cea0d0fca300e97f94ad9939"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7c2045393b2e3298fba416c7980a67b423cc5ff7d51bff314d8a0df9b998066"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
