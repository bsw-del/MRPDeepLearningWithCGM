{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import label\n",
    "from statistics import mode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, SimpleRNN, Dropout, Flatten\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from datetime import *\n",
    "from os import *\n",
    "from dataprep import *\n",
    "#path='C:\\Users\\bensa\\OneDrive - Microsoft\\Documents\\MRPLocal\\Data'\n",
    "path= 'C:\\\\Users\\\\bensa\\\\OneDrive - Microsoft\\\\Documents\\\\MRPLocal\\\\Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next -- build out table of metrics and the runner\n",
    "Write the metrics to a CSV for storage\n",
    "Use an init for the first metric build\n",
    "\n",
    "Run a few test runs to see what else we need to record.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment Plans\n",
    "\n",
    "Build out models to compare performance on\n",
    "Look at hyperparameter tuning\n",
    "ONce models are adequately baked, then move to A and B below\n",
    "\n",
    "A Experiment on using different patients inputs and keeping track of metrics\n",
    "B Experiment on using feature engineering and build out metrics further\n",
    "\n",
    "\n",
    "Implement Data cleaning from development to the data helper functions\n",
    "Add in ability to look at a per patient basis\n",
    "Perhaps start with overall data size, and then with a % set to train v test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Record the results\n",
    "Execution_time = []\n",
    "train_rmse_results = []\n",
    "test_rmse_results=[]\n",
    "run_id = []\n",
    "sample_size=[]\n",
    "epochs = []\n",
    "batch_size=[]\n",
    "optimizer=[]\n",
    "layers=[]\n",
    "forecast_distance_perf=[]\n",
    "prev_readings=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "154/154 [==============================] - 18s 111ms/step - loss: 5.5255 - root_mean_squared_error: 2.3506 - val_loss: 3.1540 - val_root_mean_squared_error: 1.7759\n",
      "Epoch 2/30\n",
      "154/154 [==============================] - 14s 92ms/step - loss: 3.9398 - root_mean_squared_error: 1.9849 - val_loss: 3.8332 - val_root_mean_squared_error: 1.9579\n",
      "Epoch 3/30\n",
      "154/154 [==============================] - 14s 94ms/step - loss: 3.7998 - root_mean_squared_error: 1.9493 - val_loss: 2.9313 - val_root_mean_squared_error: 1.7121\n",
      "Epoch 4/30\n",
      "154/154 [==============================] - 14s 89ms/step - loss: 3.8478 - root_mean_squared_error: 1.9616 - val_loss: 3.7753 - val_root_mean_squared_error: 1.9430\n",
      "Epoch 5/30\n",
      "154/154 [==============================] - 15s 101ms/step - loss: 3.8021 - root_mean_squared_error: 1.9499 - val_loss: 2.9574 - val_root_mean_squared_error: 1.7197\n",
      "Epoch 6/30\n",
      "154/154 [==============================] - 15s 96ms/step - loss: 3.7463 - root_mean_squared_error: 1.9355 - val_loss: 2.9068 - val_root_mean_squared_error: 1.7049\n",
      "Epoch 7/30\n",
      "154/154 [==============================] - 14s 90ms/step - loss: 3.7604 - root_mean_squared_error: 1.9392 - val_loss: 3.1546 - val_root_mean_squared_error: 1.7761\n",
      "Epoch 8/30\n",
      "154/154 [==============================] - 15s 98ms/step - loss: 3.7362 - root_mean_squared_error: 1.9329 - val_loss: 2.9276 - val_root_mean_squared_error: 1.7110\n",
      "Epoch 9/30\n",
      "154/154 [==============================] - 14s 94ms/step - loss: 3.8173 - root_mean_squared_error: 1.9538 - val_loss: 3.5706 - val_root_mean_squared_error: 1.8896\n",
      "Epoch 10/30\n",
      "154/154 [==============================] - 12s 76ms/step - loss: 3.8035 - root_mean_squared_error: 1.9503 - val_loss: 2.9014 - val_root_mean_squared_error: 1.7033\n",
      "Epoch 11/30\n",
      "154/154 [==============================] - 13s 88ms/step - loss: 3.7079 - root_mean_squared_error: 1.9256 - val_loss: 3.0338 - val_root_mean_squared_error: 1.7418\n",
      "Epoch 12/30\n",
      "154/154 [==============================] - 13s 81ms/step - loss: 3.8034 - root_mean_squared_error: 1.9502 - val_loss: 3.2986 - val_root_mean_squared_error: 1.8162\n",
      "Epoch 13/30\n",
      "154/154 [==============================] - 15s 97ms/step - loss: 3.8091 - root_mean_squared_error: 1.9517 - val_loss: 2.9647 - val_root_mean_squared_error: 1.7218\n",
      "Epoch 14/30\n",
      "154/154 [==============================] - 15s 97ms/step - loss: 3.8052 - root_mean_squared_error: 1.9507 - val_loss: 2.9045 - val_root_mean_squared_error: 1.7043\n",
      "Epoch 15/30\n",
      "154/154 [==============================] - 13s 82ms/step - loss: 3.8435 - root_mean_squared_error: 1.9605 - val_loss: 3.1433 - val_root_mean_squared_error: 1.7729\n",
      "Epoch 16/30\n",
      "154/154 [==============================] - 14s 88ms/step - loss: 3.8468 - root_mean_squared_error: 1.9613 - val_loss: 3.3899 - val_root_mean_squared_error: 1.8412\n",
      "Epoch 17/30\n",
      "154/154 [==============================] - 14s 92ms/step - loss: 3.7935 - root_mean_squared_error: 1.9477 - val_loss: 3.1373 - val_root_mean_squared_error: 1.7712\n",
      "Epoch 18/30\n",
      "154/154 [==============================] - 15s 99ms/step - loss: 3.7990 - root_mean_squared_error: 1.9491 - val_loss: 2.9847 - val_root_mean_squared_error: 1.7276\n",
      "Epoch 19/30\n",
      "154/154 [==============================] - 15s 97ms/step - loss: 3.8257 - root_mean_squared_error: 1.9559 - val_loss: 3.2504 - val_root_mean_squared_error: 1.8029\n",
      "Epoch 20/30\n",
      "154/154 [==============================] - 16s 104ms/step - loss: 3.8593 - root_mean_squared_error: 1.9645 - val_loss: 3.0676 - val_root_mean_squared_error: 1.7515\n",
      "Epoch 21/30\n",
      "154/154 [==============================] - 14s 91ms/step - loss: 3.9012 - root_mean_squared_error: 1.9752 - val_loss: 3.0839 - val_root_mean_squared_error: 1.7561\n",
      "Epoch 22/30\n",
      "154/154 [==============================] - 15s 100ms/step - loss: 3.8947 - root_mean_squared_error: 1.9735 - val_loss: 3.0412 - val_root_mean_squared_error: 1.7439\n",
      "Epoch 23/30\n",
      "154/154 [==============================] - 15s 97ms/step - loss: 3.8256 - root_mean_squared_error: 1.9559 - val_loss: 2.9423 - val_root_mean_squared_error: 1.7153\n",
      "Epoch 24/30\n",
      "154/154 [==============================] - 10s 64ms/step - loss: 3.8733 - root_mean_squared_error: 1.9681 - val_loss: 3.0050 - val_root_mean_squared_error: 1.7335\n",
      "Epoch 25/30\n",
      "154/154 [==============================] - 26s 168ms/step - loss: 3.9022 - root_mean_squared_error: 1.9754 - val_loss: 2.9681 - val_root_mean_squared_error: 1.7228\n",
      "Epoch 26/30\n",
      "154/154 [==============================] - 15s 99ms/step - loss: 3.9645 - root_mean_squared_error: 1.9911 - val_loss: 2.9980 - val_root_mean_squared_error: 1.7315\n",
      "Epoch 27/30\n",
      "154/154 [==============================] - 14s 91ms/step - loss: 4.0105 - root_mean_squared_error: 2.0026 - val_loss: 2.9734 - val_root_mean_squared_error: 1.7244\n",
      "Epoch 28/30\n",
      "154/154 [==============================] - 15s 100ms/step - loss: 3.9244 - root_mean_squared_error: 1.9810 - val_loss: 3.0699 - val_root_mean_squared_error: 1.7521\n",
      "Epoch 29/30\n",
      "154/154 [==============================] - 16s 104ms/step - loss: 3.9952 - root_mean_squared_error: 1.9988 - val_loss: 3.0745 - val_root_mean_squared_error: 1.7534\n",
      "Epoch 30/30\n",
      "154/154 [==============================] - 15s 97ms/step - loss: 3.9829 - root_mean_squared_error: 1.9957 - val_loss: 3.1078 - val_root_mean_squared_error: 1.7629\n",
      "1370/1370 [==============================] - 9s 7ms/step - loss: 3.4797 - root_mean_squared_error: 1.8654\n",
      "\n",
      "training time 452.095921\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 3.479733467102051 with RMSE metric of 1.8654043674468994\n",
      "636/636 [==============================] - 4s 6ms/step - loss: 3.2748 - root_mean_squared_error: 1.8097\n",
      "Test set has a loss (MSE) of 3.274848699569702 with RMSE metric of 1.8096543550491333\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "24/24 [==============================] - 3s 95ms/step - loss: 18.8082 - root_mean_squared_error: 4.3368 - val_loss: 4.6862 - val_root_mean_squared_error: 2.1648\n",
      "Epoch 2/30\n",
      "24/24 [==============================] - 2s 95ms/step - loss: 7.4764 - root_mean_squared_error: 2.7343 - val_loss: 5.0064 - val_root_mean_squared_error: 2.2375\n",
      "Epoch 3/30\n",
      "24/24 [==============================] - 2s 88ms/step - loss: 6.4740 - root_mean_squared_error: 2.5444 - val_loss: 4.4157 - val_root_mean_squared_error: 2.1014\n",
      "Epoch 4/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 5.9928 - root_mean_squared_error: 2.4480 - val_loss: 4.7839 - val_root_mean_squared_error: 2.1872\n",
      "Epoch 5/30\n",
      "24/24 [==============================] - 2s 68ms/step - loss: 6.1013 - root_mean_squared_error: 2.4701 - val_loss: 5.0899 - val_root_mean_squared_error: 2.2561\n",
      "Epoch 6/30\n",
      "24/24 [==============================] - 3s 108ms/step - loss: 5.7780 - root_mean_squared_error: 2.4037 - val_loss: 3.7447 - val_root_mean_squared_error: 1.9351\n",
      "Epoch 7/30\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.6705 - root_mean_squared_error: 2.3813 - val_loss: 4.2885 - val_root_mean_squared_error: 2.0709\n",
      "Epoch 8/30\n",
      "24/24 [==============================] - 2s 104ms/step - loss: 5.1790 - root_mean_squared_error: 2.2757 - val_loss: 3.5351 - val_root_mean_squared_error: 1.8802\n",
      "Epoch 9/30\n",
      "24/24 [==============================] - 3s 107ms/step - loss: 4.9309 - root_mean_squared_error: 2.2206 - val_loss: 4.4393 - val_root_mean_squared_error: 2.1070\n",
      "Epoch 10/30\n",
      "24/24 [==============================] - 3s 109ms/step - loss: 5.3977 - root_mean_squared_error: 2.3233 - val_loss: 4.1536 - val_root_mean_squared_error: 2.0380\n",
      "Epoch 11/30\n",
      "24/24 [==============================] - 2s 102ms/step - loss: 5.2016 - root_mean_squared_error: 2.2807 - val_loss: 3.6309 - val_root_mean_squared_error: 1.9055\n",
      "Epoch 12/30\n",
      "24/24 [==============================] - 2s 104ms/step - loss: 4.9325 - root_mean_squared_error: 2.2209 - val_loss: 5.0109 - val_root_mean_squared_error: 2.2385\n",
      "Epoch 13/30\n",
      "24/24 [==============================] - 3s 108ms/step - loss: 4.9565 - root_mean_squared_error: 2.2263 - val_loss: 4.4265 - val_root_mean_squared_error: 2.1039\n",
      "Epoch 14/30\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 5.1468 - root_mean_squared_error: 2.2687 - val_loss: 3.6846 - val_root_mean_squared_error: 1.9195\n",
      "Epoch 15/30\n",
      "24/24 [==============================] - 3s 108ms/step - loss: 4.9638 - root_mean_squared_error: 2.2280 - val_loss: 6.6608 - val_root_mean_squared_error: 2.5808\n",
      "Epoch 16/30\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 5.5842 - root_mean_squared_error: 2.3631 - val_loss: 4.1868 - val_root_mean_squared_error: 2.0462\n",
      "Epoch 17/30\n",
      "24/24 [==============================] - 3s 108ms/step - loss: 5.0563 - root_mean_squared_error: 2.2486 - val_loss: 3.5004 - val_root_mean_squared_error: 1.8709\n",
      "Epoch 18/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 5.0371 - root_mean_squared_error: 2.2443 - val_loss: 3.2396 - val_root_mean_squared_error: 1.7999\n",
      "Epoch 19/30\n",
      "24/24 [==============================] - 3s 112ms/step - loss: 4.7595 - root_mean_squared_error: 2.1816 - val_loss: 4.2950 - val_root_mean_squared_error: 2.0724\n",
      "Epoch 20/30\n",
      "24/24 [==============================] - 3s 108ms/step - loss: 4.7598 - root_mean_squared_error: 2.1817 - val_loss: 3.2071 - val_root_mean_squared_error: 1.7908\n",
      "Epoch 21/30\n",
      "24/24 [==============================] - 3s 114ms/step - loss: 4.7840 - root_mean_squared_error: 2.1872 - val_loss: 3.8906 - val_root_mean_squared_error: 1.9725\n",
      "Epoch 22/30\n",
      "24/24 [==============================] - 2s 100ms/step - loss: 4.7345 - root_mean_squared_error: 2.1759 - val_loss: 3.3236 - val_root_mean_squared_error: 1.8231\n",
      "Epoch 23/30\n",
      "24/24 [==============================] - 2s 106ms/step - loss: 4.9696 - root_mean_squared_error: 2.2293 - val_loss: 3.5517 - val_root_mean_squared_error: 1.8846\n",
      "Epoch 24/30\n",
      "24/24 [==============================] - 3s 107ms/step - loss: 4.9367 - root_mean_squared_error: 2.2219 - val_loss: 3.2452 - val_root_mean_squared_error: 1.8015\n",
      "Epoch 25/30\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 4.6550 - root_mean_squared_error: 2.1576 - val_loss: 3.9364 - val_root_mean_squared_error: 1.9840\n",
      "Epoch 26/30\n",
      "24/24 [==============================] - 3s 108ms/step - loss: 4.9340 - root_mean_squared_error: 2.2213 - val_loss: 3.0822 - val_root_mean_squared_error: 1.7556\n",
      "Epoch 27/30\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 4.6289 - root_mean_squared_error: 2.1515 - val_loss: 3.8426 - val_root_mean_squared_error: 1.9602\n",
      "Epoch 28/30\n",
      "24/24 [==============================] - 3s 114ms/step - loss: 4.5997 - root_mean_squared_error: 2.1447 - val_loss: 3.3435 - val_root_mean_squared_error: 1.8285\n",
      "Epoch 29/30\n",
      "24/24 [==============================] - 2s 104ms/step - loss: 4.6036 - root_mean_squared_error: 2.1456 - val_loss: 3.1742 - val_root_mean_squared_error: 1.7816\n",
      "Epoch 30/30\n",
      "24/24 [==============================] - 2s 85ms/step - loss: 4.6257 - root_mean_squared_error: 2.1508 - val_loss: 3.1735 - val_root_mean_squared_error: 1.7814\n",
      "208/208 [==============================] - 1s 7ms/step - loss: 3.8176 - root_mean_squared_error: 1.9539\n",
      "\n",
      "training time 73.980828\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 3.817596435546875 with RMSE metric of 1.9538670778274536\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 3.3195 - root_mean_squared_error: 1.8220\n",
      "Test set has a loss (MSE) of 3.319530963897705 with RMSE metric of 1.8219579458236694\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 6s 108ms/step - loss: 9.1300 - root_mean_squared_error: 3.0216 - val_loss: 4.6609 - val_root_mean_squared_error: 2.1589\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 5.1683 - root_mean_squared_error: 2.2734 - val_loss: 3.7545 - val_root_mean_squared_error: 1.9377\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 5s 105ms/step - loss: 4.5613 - root_mean_squared_error: 2.1357 - val_loss: 3.8254 - val_root_mean_squared_error: 1.9559\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 5s 112ms/step - loss: 4.4052 - root_mean_squared_error: 2.0989 - val_loss: 4.5286 - val_root_mean_squared_error: 2.1281\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 5s 109ms/step - loss: 4.6253 - root_mean_squared_error: 2.1507 - val_loss: 3.6044 - val_root_mean_squared_error: 1.8985\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 5s 112ms/step - loss: 4.4688 - root_mean_squared_error: 2.1139 - val_loss: 3.8510 - val_root_mean_squared_error: 1.9624\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 5s 108ms/step - loss: 4.0941 - root_mean_squared_error: 2.0234 - val_loss: 3.8389 - val_root_mean_squared_error: 1.9593\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 5s 101ms/step - loss: 4.2955 - root_mean_squared_error: 2.0725 - val_loss: 4.0637 - val_root_mean_squared_error: 2.0159\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 5s 100ms/step - loss: 4.1258 - root_mean_squared_error: 2.0312 - val_loss: 4.4159 - val_root_mean_squared_error: 2.1014\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 5s 110ms/step - loss: 4.1992 - root_mean_squared_error: 2.0492 - val_loss: 3.6670 - val_root_mean_squared_error: 1.9149\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 5s 111ms/step - loss: 4.2713 - root_mean_squared_error: 2.0667 - val_loss: 3.5587 - val_root_mean_squared_error: 1.8865\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 4s 85ms/step - loss: 4.2260 - root_mean_squared_error: 2.0557 - val_loss: 3.6048 - val_root_mean_squared_error: 1.8986\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 4s 96ms/step - loss: 4.0779 - root_mean_squared_error: 2.0194 - val_loss: 3.9771 - val_root_mean_squared_error: 1.9943\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 5s 99ms/step - loss: 4.0500 - root_mean_squared_error: 2.0125 - val_loss: 3.5772 - val_root_mean_squared_error: 1.8913\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 4.0676 - root_mean_squared_error: 2.0168 - val_loss: 3.6138 - val_root_mean_squared_error: 1.9010\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 5s 112ms/step - loss: 4.0660 - root_mean_squared_error: 2.0164 - val_loss: 3.9132 - val_root_mean_squared_error: 1.9782\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 5s 113ms/step - loss: 3.9890 - root_mean_squared_error: 1.9973 - val_loss: 3.5773 - val_root_mean_squared_error: 1.8914\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 5s 113ms/step - loss: 3.9784 - root_mean_squared_error: 1.9946 - val_loss: 3.8030 - val_root_mean_squared_error: 1.9501\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 5s 107ms/step - loss: 4.2222 - root_mean_squared_error: 2.0548 - val_loss: 3.7419 - val_root_mean_squared_error: 1.9344\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 5s 114ms/step - loss: 4.1266 - root_mean_squared_error: 2.0314 - val_loss: 3.6083 - val_root_mean_squared_error: 1.8996\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 5s 109ms/step - loss: 4.0805 - root_mean_squared_error: 2.0200 - val_loss: 3.6686 - val_root_mean_squared_error: 1.9154\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 5s 98ms/step - loss: 4.0422 - root_mean_squared_error: 2.0105 - val_loss: 3.5461 - val_root_mean_squared_error: 1.8831\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 5s 102ms/step - loss: 4.1198 - root_mean_squared_error: 2.0297 - val_loss: 3.5948 - val_root_mean_squared_error: 1.8960\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 5s 110ms/step - loss: 4.2941 - root_mean_squared_error: 2.0722 - val_loss: 3.9749 - val_root_mean_squared_error: 1.9937\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 4.0127 - root_mean_squared_error: 2.0032 - val_loss: 3.7740 - val_root_mean_squared_error: 1.9427\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 5s 99ms/step - loss: 3.9224 - root_mean_squared_error: 1.9805 - val_loss: 3.6195 - val_root_mean_squared_error: 1.9025\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 5s 107ms/step - loss: 3.9159 - root_mean_squared_error: 1.9789 - val_loss: 3.9919 - val_root_mean_squared_error: 1.9980\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 5s 102ms/step - loss: 4.1116 - root_mean_squared_error: 2.0277 - val_loss: 3.8077 - val_root_mean_squared_error: 1.9513\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 5s 101ms/step - loss: 4.0154 - root_mean_squared_error: 2.0038 - val_loss: 3.7298 - val_root_mean_squared_error: 1.9313\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 5s 113ms/step - loss: 3.9027 - root_mean_squared_error: 1.9755 - val_loss: 3.7065 - val_root_mean_squared_error: 1.9252\n",
      "418/418 [==============================] - 3s 6ms/step - loss: 3.8046 - root_mean_squared_error: 1.9505\n",
      "\n",
      "training time 150.352125\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 3.8046157360076904 with RMSE metric of 1.9505424499511719\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 4.7223 - root_mean_squared_error: 2.1731\n",
      "Test set has a loss (MSE) of 4.722255706787109 with RMSE metric of 2.1730751991271973\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "221/221 [==============================] - 24s 103ms/step - loss: 5.2375 - root_mean_squared_error: 2.2886 - val_loss: 4.3845 - val_root_mean_squared_error: 2.0939\n",
      "Epoch 2/30\n",
      "221/221 [==============================] - 22s 101ms/step - loss: 4.0841 - root_mean_squared_error: 2.0209 - val_loss: 4.0201 - val_root_mean_squared_error: 2.0050\n",
      "Epoch 3/30\n",
      "221/221 [==============================] - 23s 105ms/step - loss: 4.0555 - root_mean_squared_error: 2.0138 - val_loss: 4.4048 - val_root_mean_squared_error: 2.0988\n",
      "Epoch 4/30\n",
      "221/221 [==============================] - 17s 79ms/step - loss: 4.0246 - root_mean_squared_error: 2.0061 - val_loss: 3.9576 - val_root_mean_squared_error: 1.9894\n",
      "Epoch 5/30\n",
      "221/221 [==============================] - 16s 72ms/step - loss: 3.9906 - root_mean_squared_error: 1.9976 - val_loss: 4.0626 - val_root_mean_squared_error: 2.0156\n",
      "Epoch 6/30\n",
      "221/221 [==============================] - 20s 89ms/step - loss: 3.9834 - root_mean_squared_error: 1.9958 - val_loss: 4.2926 - val_root_mean_squared_error: 2.0719\n",
      "Epoch 7/30\n",
      "221/221 [==============================] - 22s 98ms/step - loss: 3.9451 - root_mean_squared_error: 1.9862 - val_loss: 4.0769 - val_root_mean_squared_error: 2.0191\n",
      "Epoch 8/30\n",
      "221/221 [==============================] - 21s 95ms/step - loss: 4.0344 - root_mean_squared_error: 2.0086 - val_loss: 4.0326 - val_root_mean_squared_error: 2.0081\n",
      "Epoch 9/30\n",
      "221/221 [==============================] - 23s 106ms/step - loss: 3.9695 - root_mean_squared_error: 1.9924 - val_loss: 4.1545 - val_root_mean_squared_error: 2.0383\n",
      "Epoch 10/30\n",
      "221/221 [==============================] - 24s 107ms/step - loss: 4.0212 - root_mean_squared_error: 2.0053 - val_loss: 4.1151 - val_root_mean_squared_error: 2.0286\n",
      "Epoch 11/30\n",
      "221/221 [==============================] - 24s 109ms/step - loss: 4.0171 - root_mean_squared_error: 2.0043 - val_loss: 4.1938 - val_root_mean_squared_error: 2.0479\n",
      "Epoch 12/30\n",
      "221/221 [==============================] - 23s 102ms/step - loss: 4.1211 - root_mean_squared_error: 2.0301 - val_loss: 4.1449 - val_root_mean_squared_error: 2.0359\n",
      "Epoch 13/30\n",
      "221/221 [==============================] - 27s 123ms/step - loss: 4.0404 - root_mean_squared_error: 2.0101 - val_loss: 4.0531 - val_root_mean_squared_error: 2.0132\n",
      "Epoch 14/30\n",
      "221/221 [==============================] - 17s 75ms/step - loss: 4.0589 - root_mean_squared_error: 2.0147 - val_loss: 4.2676 - val_root_mean_squared_error: 2.0658\n",
      "Epoch 15/30\n",
      "221/221 [==============================] - 22s 100ms/step - loss: 4.0513 - root_mean_squared_error: 2.0128 - val_loss: 4.1744 - val_root_mean_squared_error: 2.0431\n",
      "Epoch 16/30\n",
      "221/221 [==============================] - 23s 103ms/step - loss: 4.0818 - root_mean_squared_error: 2.0204 - val_loss: 4.2643 - val_root_mean_squared_error: 2.0650\n",
      "Epoch 17/30\n",
      "221/221 [==============================] - 24s 110ms/step - loss: 4.1111 - root_mean_squared_error: 2.0276 - val_loss: 4.1130 - val_root_mean_squared_error: 2.0281\n",
      "Epoch 18/30\n",
      "221/221 [==============================] - 23s 103ms/step - loss: 4.0422 - root_mean_squared_error: 2.0105 - val_loss: 4.1812 - val_root_mean_squared_error: 2.0448\n",
      "Epoch 19/30\n",
      "221/221 [==============================] - 23s 105ms/step - loss: 4.1095 - root_mean_squared_error: 2.0272 - val_loss: 4.3211 - val_root_mean_squared_error: 2.0787\n",
      "Epoch 20/30\n",
      "221/221 [==============================] - 23s 103ms/step - loss: 4.1094 - root_mean_squared_error: 2.0272 - val_loss: 3.9877 - val_root_mean_squared_error: 1.9969\n",
      "Epoch 21/30\n",
      "221/221 [==============================] - 17s 78ms/step - loss: 4.0548 - root_mean_squared_error: 2.0136 - val_loss: 3.9640 - val_root_mean_squared_error: 1.9910\n",
      "Epoch 22/30\n",
      "221/221 [==============================] - 22s 102ms/step - loss: 4.0615 - root_mean_squared_error: 2.0153 - val_loss: 4.0242 - val_root_mean_squared_error: 2.0060\n",
      "Epoch 23/30\n",
      "221/221 [==============================] - 23s 106ms/step - loss: 4.1960 - root_mean_squared_error: 2.0484 - val_loss: 4.2276 - val_root_mean_squared_error: 2.0561\n",
      "Epoch 24/30\n",
      "221/221 [==============================] - 23s 103ms/step - loss: 4.1493 - root_mean_squared_error: 2.0370 - val_loss: 4.1253 - val_root_mean_squared_error: 2.0311\n",
      "Epoch 25/30\n",
      "221/221 [==============================] - 23s 105ms/step - loss: 4.1637 - root_mean_squared_error: 2.0405 - val_loss: 4.3759 - val_root_mean_squared_error: 2.0919\n",
      "Epoch 26/30\n",
      "221/221 [==============================] - 24s 107ms/step - loss: 4.1501 - root_mean_squared_error: 2.0372 - val_loss: 4.1686 - val_root_mean_squared_error: 2.0417\n",
      "Epoch 27/30\n",
      "221/221 [==============================] - 21s 95ms/step - loss: 4.2404 - root_mean_squared_error: 2.0592 - val_loss: 5.2592 - val_root_mean_squared_error: 2.2933\n",
      "Epoch 28/30\n",
      "221/221 [==============================] - 23s 105ms/step - loss: 4.2054 - root_mean_squared_error: 2.0507 - val_loss: 4.1922 - val_root_mean_squared_error: 2.0475\n",
      "Epoch 29/30\n",
      "221/221 [==============================] - 19s 87ms/step - loss: 4.2760 - root_mean_squared_error: 2.0679 - val_loss: 4.3996 - val_root_mean_squared_error: 2.0975\n",
      "Epoch 30/30\n",
      "221/221 [==============================] - 23s 105ms/step - loss: 4.2353 - root_mean_squared_error: 2.0580 - val_loss: 4.3977 - val_root_mean_squared_error: 2.0971\n",
      "1971/1971 [==============================] - 12s 6ms/step - loss: 4.1424 - root_mean_squared_error: 2.0353\n",
      "\n",
      "training time 670.765977\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 4.14235258102417 with RMSE metric of 2.0352771282196045\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 4.2428 - root_mean_squared_error: 2.0598\n",
      "Test set has a loss (MSE) of 4.2428412437438965 with RMSE metric of 2.0598158836364746\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "61/61 [==============================] - 8s 109ms/step - loss: 9.6823 - root_mean_squared_error: 3.1116 - val_loss: 2.5702 - val_root_mean_squared_error: 1.6032\n",
      "Epoch 2/30\n",
      "61/61 [==============================] - 6s 91ms/step - loss: 3.4246 - root_mean_squared_error: 1.8506 - val_loss: 2.4398 - val_root_mean_squared_error: 1.5620\n",
      "Epoch 3/30\n",
      "61/61 [==============================] - 7s 110ms/step - loss: 3.5609 - root_mean_squared_error: 1.8870 - val_loss: 2.5950 - val_root_mean_squared_error: 1.6109\n",
      "Epoch 4/30\n",
      "61/61 [==============================] - 7s 109ms/step - loss: 3.2566 - root_mean_squared_error: 1.8046 - val_loss: 2.3452 - val_root_mean_squared_error: 1.5314\n",
      "Epoch 5/30\n",
      "61/61 [==============================] - 6s 105ms/step - loss: 3.1635 - root_mean_squared_error: 1.7786 - val_loss: 2.3734 - val_root_mean_squared_error: 1.5406\n",
      "Epoch 6/30\n",
      "61/61 [==============================] - 7s 109ms/step - loss: 3.1469 - root_mean_squared_error: 1.7739 - val_loss: 2.5384 - val_root_mean_squared_error: 1.5932\n",
      "Epoch 7/30\n",
      "61/61 [==============================] - 6s 104ms/step - loss: 3.2392 - root_mean_squared_error: 1.7998 - val_loss: 2.3738 - val_root_mean_squared_error: 1.5407\n",
      "Epoch 8/30\n",
      "61/61 [==============================] - 7s 111ms/step - loss: 3.0539 - root_mean_squared_error: 1.7475 - val_loss: 2.4002 - val_root_mean_squared_error: 1.5492\n",
      "Epoch 9/30\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 3.1335 - root_mean_squared_error: 1.7702 - val_loss: 2.5331 - val_root_mean_squared_error: 1.5916\n",
      "Epoch 10/30\n",
      "61/61 [==============================] - 6s 94ms/step - loss: 3.1088 - root_mean_squared_error: 1.7632 - val_loss: 2.3402 - val_root_mean_squared_error: 1.5298\n",
      "Epoch 11/30\n",
      "61/61 [==============================] - 6s 105ms/step - loss: 3.0080 - root_mean_squared_error: 1.7344 - val_loss: 2.3333 - val_root_mean_squared_error: 1.5275\n",
      "Epoch 12/30\n",
      "61/61 [==============================] - 6s 105ms/step - loss: 3.0336 - root_mean_squared_error: 1.7417 - val_loss: 2.6814 - val_root_mean_squared_error: 1.6375\n",
      "Epoch 13/30\n",
      "61/61 [==============================] - 6s 97ms/step - loss: 3.0555 - root_mean_squared_error: 1.7480 - val_loss: 2.3255 - val_root_mean_squared_error: 1.5249\n",
      "Epoch 14/30\n",
      "61/61 [==============================] - 7s 108ms/step - loss: 3.1976 - root_mean_squared_error: 1.7882 - val_loss: 2.5242 - val_root_mean_squared_error: 1.5888\n",
      "Epoch 15/30\n",
      "61/61 [==============================] - 6s 93ms/step - loss: 3.0198 - root_mean_squared_error: 1.7377 - val_loss: 2.3063 - val_root_mean_squared_error: 1.5186\n",
      "Epoch 16/30\n",
      "61/61 [==============================] - 6s 100ms/step - loss: 3.0156 - root_mean_squared_error: 1.7365 - val_loss: 2.3906 - val_root_mean_squared_error: 1.5461\n",
      "Epoch 17/30\n",
      "61/61 [==============================] - 6s 102ms/step - loss: 3.0680 - root_mean_squared_error: 1.7516 - val_loss: 2.8382 - val_root_mean_squared_error: 1.6847\n",
      "Epoch 18/30\n",
      "61/61 [==============================] - 7s 114ms/step - loss: 3.0289 - root_mean_squared_error: 1.7404 - val_loss: 2.7748 - val_root_mean_squared_error: 1.6658\n",
      "Epoch 19/30\n",
      "61/61 [==============================] - 6s 103ms/step - loss: 3.0433 - root_mean_squared_error: 1.7445 - val_loss: 2.4397 - val_root_mean_squared_error: 1.5620\n",
      "Epoch 20/30\n",
      "61/61 [==============================] - 6s 93ms/step - loss: 3.0444 - root_mean_squared_error: 1.7448 - val_loss: 2.4479 - val_root_mean_squared_error: 1.5646\n",
      "Epoch 21/30\n",
      "61/61 [==============================] - 6s 103ms/step - loss: 2.9470 - root_mean_squared_error: 1.7167 - val_loss: 2.3718 - val_root_mean_squared_error: 1.5401\n",
      "Epoch 22/30\n",
      "61/61 [==============================] - 6s 97ms/step - loss: 2.8971 - root_mean_squared_error: 1.7021 - val_loss: 2.2805 - val_root_mean_squared_error: 1.5101\n",
      "Epoch 23/30\n",
      "61/61 [==============================] - 5s 90ms/step - loss: 2.9321 - root_mean_squared_error: 1.7123 - val_loss: 2.3732 - val_root_mean_squared_error: 1.5405\n",
      "Epoch 24/30\n",
      "61/61 [==============================] - 6s 100ms/step - loss: 3.0685 - root_mean_squared_error: 1.7517 - val_loss: 2.4289 - val_root_mean_squared_error: 1.5585\n",
      "Epoch 25/30\n",
      "61/61 [==============================] - 5s 88ms/step - loss: 3.1014 - root_mean_squared_error: 1.7611 - val_loss: 2.3484 - val_root_mean_squared_error: 1.5325\n",
      "Epoch 26/30\n",
      "61/61 [==============================] - 6s 91ms/step - loss: 3.0104 - root_mean_squared_error: 1.7350 - val_loss: 2.4443 - val_root_mean_squared_error: 1.5634\n",
      "Epoch 27/30\n",
      "61/61 [==============================] - 6s 102ms/step - loss: 3.0720 - root_mean_squared_error: 1.7527 - val_loss: 2.4300 - val_root_mean_squared_error: 1.5589\n",
      "Epoch 28/30\n",
      "61/61 [==============================] - 6s 99ms/step - loss: 3.0681 - root_mean_squared_error: 1.7516 - val_loss: 2.3257 - val_root_mean_squared_error: 1.5250\n",
      "Epoch 29/30\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 2.9983 - root_mean_squared_error: 1.7316 - val_loss: 2.3221 - val_root_mean_squared_error: 1.5239\n",
      "Epoch 30/30\n",
      "61/61 [==============================] - 5s 90ms/step - loss: 3.1052 - root_mean_squared_error: 1.7621 - val_loss: 2.4159 - val_root_mean_squared_error: 1.5543\n",
      "545/545 [==============================] - 3s 6ms/step - loss: 2.6230 - root_mean_squared_error: 1.6196\n",
      "\n",
      "training time 186.820372\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 2.622957468032837 with RMSE metric of 1.6195547580718994\n",
      "319/319 [==============================] - 2s 6ms/step - loss: 2.3411 - root_mean_squared_error: 1.5301\n",
      "Test set has a loss (MSE) of 2.3410727977752686 with RMSE metric of 1.5300564765930176\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "69/69 [==============================] - 8s 97ms/step - loss: 8.4951 - root_mean_squared_error: 2.9146 - val_loss: 3.7625 - val_root_mean_squared_error: 1.9397\n",
      "Epoch 2/30\n",
      "69/69 [==============================] - 7s 108ms/step - loss: 4.5857 - root_mean_squared_error: 2.1414 - val_loss: 3.6771 - val_root_mean_squared_error: 1.9176\n",
      "Epoch 3/30\n",
      "69/69 [==============================] - 7s 104ms/step - loss: 4.3423 - root_mean_squared_error: 2.0838 - val_loss: 3.4073 - val_root_mean_squared_error: 1.8459\n",
      "Epoch 4/30\n",
      "69/69 [==============================] - 7s 103ms/step - loss: 4.1020 - root_mean_squared_error: 2.0253 - val_loss: 4.3362 - val_root_mean_squared_error: 2.0824\n",
      "Epoch 5/30\n",
      "69/69 [==============================] - 7s 104ms/step - loss: 4.3079 - root_mean_squared_error: 2.0756 - val_loss: 4.0112 - val_root_mean_squared_error: 2.0028\n",
      "Epoch 6/30\n",
      "69/69 [==============================] - 7s 103ms/step - loss: 4.2719 - root_mean_squared_error: 2.0669 - val_loss: 3.4985 - val_root_mean_squared_error: 1.8704\n",
      "Epoch 7/30\n",
      "69/69 [==============================] - 7s 96ms/step - loss: 4.0729 - root_mean_squared_error: 2.0182 - val_loss: 3.5281 - val_root_mean_squared_error: 1.8783\n",
      "Epoch 8/30\n",
      "69/69 [==============================] - 6s 94ms/step - loss: 4.0281 - root_mean_squared_error: 2.0070 - val_loss: 3.4233 - val_root_mean_squared_error: 1.8502\n",
      "Epoch 9/30\n",
      "69/69 [==============================] - 6s 91ms/step - loss: 3.9518 - root_mean_squared_error: 1.9879 - val_loss: 3.3505 - val_root_mean_squared_error: 1.8304\n",
      "Epoch 10/30\n",
      "69/69 [==============================] - 7s 101ms/step - loss: 3.9688 - root_mean_squared_error: 1.9922 - val_loss: 3.4335 - val_root_mean_squared_error: 1.8530\n",
      "Epoch 11/30\n",
      "69/69 [==============================] - 6s 87ms/step - loss: 3.9766 - root_mean_squared_error: 1.9941 - val_loss: 3.7405 - val_root_mean_squared_error: 1.9340\n",
      "Epoch 12/30\n",
      "69/69 [==============================] - 7s 102ms/step - loss: 3.9358 - root_mean_squared_error: 1.9839 - val_loss: 3.7649 - val_root_mean_squared_error: 1.9403\n",
      "Epoch 13/30\n",
      "69/69 [==============================] - 7s 102ms/step - loss: 4.0330 - root_mean_squared_error: 2.0082 - val_loss: 3.7518 - val_root_mean_squared_error: 1.9369\n",
      "Epoch 14/30\n",
      "69/69 [==============================] - 7s 104ms/step - loss: 3.9701 - root_mean_squared_error: 1.9925 - val_loss: 3.2504 - val_root_mean_squared_error: 1.8029\n",
      "Epoch 15/30\n",
      "69/69 [==============================] - 6s 89ms/step - loss: 4.0518 - root_mean_squared_error: 2.0129 - val_loss: 4.3133 - val_root_mean_squared_error: 2.0769\n",
      "Epoch 16/30\n",
      "69/69 [==============================] - 5s 74ms/step - loss: 4.0907 - root_mean_squared_error: 2.0226 - val_loss: 3.5587 - val_root_mean_squared_error: 1.8864\n",
      "Epoch 17/30\n",
      "69/69 [==============================] - 6s 88ms/step - loss: 4.0139 - root_mean_squared_error: 2.0035 - val_loss: 3.2424 - val_root_mean_squared_error: 1.8007\n",
      "Epoch 18/30\n",
      "69/69 [==============================] - 7s 102ms/step - loss: 3.9451 - root_mean_squared_error: 1.9862 - val_loss: 3.3391 - val_root_mean_squared_error: 1.8273\n",
      "Epoch 19/30\n",
      "69/69 [==============================] - 7s 102ms/step - loss: 3.9312 - root_mean_squared_error: 1.9827 - val_loss: 3.4512 - val_root_mean_squared_error: 1.8577\n",
      "Epoch 20/30\n",
      "69/69 [==============================] - 7s 103ms/step - loss: 3.8188 - root_mean_squared_error: 1.9542 - val_loss: 3.3252 - val_root_mean_squared_error: 1.8235\n",
      "Epoch 21/30\n",
      "69/69 [==============================] - 7s 97ms/step - loss: 3.9085 - root_mean_squared_error: 1.9770 - val_loss: 3.4840 - val_root_mean_squared_error: 1.8665\n",
      "Epoch 22/30\n",
      "69/69 [==============================] - 7s 104ms/step - loss: 3.9221 - root_mean_squared_error: 1.9804 - val_loss: 3.3785 - val_root_mean_squared_error: 1.8381\n",
      "Epoch 23/30\n",
      "69/69 [==============================] - 7s 105ms/step - loss: 3.9292 - root_mean_squared_error: 1.9822 - val_loss: 3.3695 - val_root_mean_squared_error: 1.8356\n",
      "Epoch 24/30\n",
      "69/69 [==============================] - 7s 105ms/step - loss: 3.9154 - root_mean_squared_error: 1.9787 - val_loss: 3.2209 - val_root_mean_squared_error: 1.7947\n",
      "Epoch 25/30\n",
      "69/69 [==============================] - 7s 100ms/step - loss: 3.9905 - root_mean_squared_error: 1.9976 - val_loss: 3.6051 - val_root_mean_squared_error: 1.8987\n",
      "Epoch 26/30\n",
      "69/69 [==============================] - 7s 108ms/step - loss: 3.9181 - root_mean_squared_error: 1.9794 - val_loss: 3.4207 - val_root_mean_squared_error: 1.8495\n",
      "Epoch 27/30\n",
      "69/69 [==============================] - 7s 103ms/step - loss: 4.0418 - root_mean_squared_error: 2.0104 - val_loss: 3.4641 - val_root_mean_squared_error: 1.8612\n",
      "Epoch 28/30\n",
      "69/69 [==============================] - 7s 106ms/step - loss: 3.9008 - root_mean_squared_error: 1.9750 - val_loss: 3.5350 - val_root_mean_squared_error: 1.8802\n",
      "Epoch 29/30\n",
      "69/69 [==============================] - 7s 105ms/step - loss: 3.9182 - root_mean_squared_error: 1.9794 - val_loss: 3.2701 - val_root_mean_squared_error: 1.8083\n",
      "Epoch 30/30\n",
      "69/69 [==============================] - 6s 92ms/step - loss: 3.9049 - root_mean_squared_error: 1.9761 - val_loss: 3.3100 - val_root_mean_squared_error: 1.8193\n",
      "612/612 [==============================] - 4s 6ms/step - loss: 3.4938 - root_mean_squared_error: 1.8692\n",
      "\n",
      "training time 209.625444\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 3.4938125610351562 with RMSE metric of 1.8691742420196533\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 3.4025 - root_mean_squared_error: 1.8446\n",
      "Test set has a loss (MSE) of 3.4025485515594482 with RMSE metric of 1.8445998430252075\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 5.5267 - root_mean_squared_error: 2.3509 - val_loss: 3.0296 - val_root_mean_squared_error: 1.7406\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 4.0585 - root_mean_squared_error: 2.0146 - val_loss: 3.5560 - val_root_mean_squared_error: 1.8857\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 4.0491 - root_mean_squared_error: 2.0122 - val_loss: 2.9588 - val_root_mean_squared_error: 1.7201\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 3.9201 - root_mean_squared_error: 1.9799 - val_loss: 3.2450 - val_root_mean_squared_error: 1.8014\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 4.0177 - root_mean_squared_error: 2.0044 - val_loss: 3.0753 - val_root_mean_squared_error: 1.7536\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - 9s 61ms/step - loss: 3.9449 - root_mean_squared_error: 1.9862 - val_loss: 3.1025 - val_root_mean_squared_error: 1.7614\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - 120s 804ms/step - loss: 3.8668 - root_mean_squared_error: 1.9664 - val_loss: 3.0289 - val_root_mean_squared_error: 1.7404\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.8387 - root_mean_squared_error: 1.9593 - val_loss: 2.9957 - val_root_mean_squared_error: 1.7308\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 3.9140 - root_mean_squared_error: 1.9784 - val_loss: 2.9540 - val_root_mean_squared_error: 1.7187\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 3.9104 - root_mean_squared_error: 1.9775 - val_loss: 2.9012 - val_root_mean_squared_error: 1.7033\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 3.8876 - root_mean_squared_error: 1.9717 - val_loss: 2.8818 - val_root_mean_squared_error: 1.6976\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 3.9450 - root_mean_squared_error: 1.9862 - val_loss: 3.2646 - val_root_mean_squared_error: 1.8068\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 3.9168 - root_mean_squared_error: 1.9791 - val_loss: 3.0246 - val_root_mean_squared_error: 1.7391\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 3.9108 - root_mean_squared_error: 1.9776 - val_loss: 3.1845 - val_root_mean_squared_error: 1.7845\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 3.9270 - root_mean_squared_error: 1.9817 - val_loss: 2.8391 - val_root_mean_squared_error: 1.6850\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - 16s 108ms/step - loss: 3.9171 - root_mean_squared_error: 1.9792 - val_loss: 2.9719 - val_root_mean_squared_error: 1.7239\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 3.9445 - root_mean_squared_error: 1.9861 - val_loss: 3.1122 - val_root_mean_squared_error: 1.7642\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - 11s 76ms/step - loss: 3.9249 - root_mean_squared_error: 1.9811 - val_loss: 2.8905 - val_root_mean_squared_error: 1.7001\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 3.9332 - root_mean_squared_error: 1.9832 - val_loss: 2.9472 - val_root_mean_squared_error: 1.7167\n",
      "Epoch 20/30\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.0422 - root_mean_squared_error: 2.0105 - val_loss: 2.8599 - val_root_mean_squared_error: 1.6911\n",
      "Epoch 21/30\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 3.9613 - root_mean_squared_error: 1.9903 - val_loss: 2.9830 - val_root_mean_squared_error: 1.7271\n",
      "Epoch 22/30\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 3.9958 - root_mean_squared_error: 1.9990 - val_loss: 2.9705 - val_root_mean_squared_error: 1.7235\n",
      "Epoch 23/30\n",
      "150/150 [==============================] - 12s 77ms/step - loss: 4.0884 - root_mean_squared_error: 2.0220 - val_loss: 3.0028 - val_root_mean_squared_error: 1.7329\n",
      "Epoch 24/30\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 4.1078 - root_mean_squared_error: 2.0268 - val_loss: 3.2554 - val_root_mean_squared_error: 1.8043\n",
      "Epoch 25/30\n",
      "150/150 [==============================] - 12s 77ms/step - loss: 4.0593 - root_mean_squared_error: 2.0148 - val_loss: 3.1861 - val_root_mean_squared_error: 1.7850\n",
      "Epoch 26/30\n",
      "150/150 [==============================] - 12s 79ms/step - loss: 4.0049 - root_mean_squared_error: 2.0012 - val_loss: 2.9323 - val_root_mean_squared_error: 1.7124\n",
      "Epoch 27/30\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 4.0733 - root_mean_squared_error: 2.0182 - val_loss: 3.0478 - val_root_mean_squared_error: 1.7458\n",
      "Epoch 28/30\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 4.1380 - root_mean_squared_error: 2.0342 - val_loss: 2.9766 - val_root_mean_squared_error: 1.7253\n",
      "Epoch 29/30\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.1167 - root_mean_squared_error: 2.0290 - val_loss: 3.0610 - val_root_mean_squared_error: 1.7496\n",
      "Epoch 30/30\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 4.0976 - root_mean_squared_error: 2.0242 - val_loss: 2.9620 - val_root_mean_squared_error: 1.7210\n",
      "1338/1338 [==============================] - 7s 6ms/step - loss: 3.4459 - root_mean_squared_error: 1.8563\n",
      "\n",
      "training time 499.816143\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 3.445885181427002 with RMSE metric of 1.8563095331192017\n",
      "483/483 [==============================] - 3s 6ms/step - loss: 4.6534 - root_mean_squared_error: 2.1572\n",
      "Test set has a loss (MSE) of 4.653364181518555 with RMSE metric of 2.157165765762329\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "57/57 [==============================] - 5s 76ms/step - loss: 7.3186 - root_mean_squared_error: 2.7053 - val_loss: 5.7968 - val_root_mean_squared_error: 2.4077\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 4s 64ms/step - loss: 3.4398 - root_mean_squared_error: 1.8547 - val_loss: 2.6842 - val_root_mean_squared_error: 1.6383\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 4s 70ms/step - loss: 3.2272 - root_mean_squared_error: 1.7964 - val_loss: 3.6346 - val_root_mean_squared_error: 1.9065\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 4s 69ms/step - loss: 2.9419 - root_mean_squared_error: 1.7152 - val_loss: 2.5738 - val_root_mean_squared_error: 1.6043\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 4s 76ms/step - loss: 2.7940 - root_mean_squared_error: 1.6715 - val_loss: 2.8747 - val_root_mean_squared_error: 1.6955\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 4s 78ms/step - loss: 3.2386 - root_mean_squared_error: 1.7996 - val_loss: 3.5055 - val_root_mean_squared_error: 1.8723\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 4s 69ms/step - loss: 2.9596 - root_mean_squared_error: 1.7203 - val_loss: 3.8527 - val_root_mean_squared_error: 1.9628\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 4s 67ms/step - loss: 2.9236 - root_mean_squared_error: 1.7099 - val_loss: 2.7371 - val_root_mean_squared_error: 1.6544\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 4s 72ms/step - loss: 2.8077 - root_mean_squared_error: 1.6756 - val_loss: 2.9118 - val_root_mean_squared_error: 1.7064\n",
      "Epoch 10/30\n",
      "57/57 [==============================] - 4s 70ms/step - loss: 2.8387 - root_mean_squared_error: 1.6848 - val_loss: 3.7487 - val_root_mean_squared_error: 1.9362\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 4s 71ms/step - loss: 2.8693 - root_mean_squared_error: 1.6939 - val_loss: 3.1569 - val_root_mean_squared_error: 1.7768\n",
      "Epoch 12/30\n",
      "57/57 [==============================] - 4s 76ms/step - loss: 2.8179 - root_mean_squared_error: 1.6786 - val_loss: 3.7388 - val_root_mean_squared_error: 1.9336\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 5s 91ms/step - loss: 2.8222 - root_mean_squared_error: 1.6799 - val_loss: 2.4240 - val_root_mean_squared_error: 1.5569\n",
      "Epoch 14/30\n",
      "57/57 [==============================] - 4s 64ms/step - loss: 2.8266 - root_mean_squared_error: 1.6812 - val_loss: 2.6825 - val_root_mean_squared_error: 1.6378\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 4s 71ms/step - loss: 2.7517 - root_mean_squared_error: 1.6588 - val_loss: 2.6858 - val_root_mean_squared_error: 1.6388\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 4s 75ms/step - loss: 2.8596 - root_mean_squared_error: 1.6910 - val_loss: 3.1705 - val_root_mean_squared_error: 1.7806\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 4s 78ms/step - loss: 2.9338 - root_mean_squared_error: 1.7128 - val_loss: 2.6309 - val_root_mean_squared_error: 1.6220\n",
      "Epoch 18/30\n",
      "57/57 [==============================] - 4s 67ms/step - loss: 2.7424 - root_mean_squared_error: 1.6560 - val_loss: 2.6302 - val_root_mean_squared_error: 1.6218\n",
      "Epoch 19/30\n",
      "57/57 [==============================] - 4s 77ms/step - loss: 2.7056 - root_mean_squared_error: 1.6449 - val_loss: 2.4644 - val_root_mean_squared_error: 1.5698\n",
      "Epoch 20/30\n",
      "57/57 [==============================] - 5s 81ms/step - loss: 2.7976 - root_mean_squared_error: 1.6726 - val_loss: 2.6064 - val_root_mean_squared_error: 1.6144\n",
      "Epoch 21/30\n",
      "57/57 [==============================] - 4s 69ms/step - loss: 2.8008 - root_mean_squared_error: 1.6736 - val_loss: 2.9932 - val_root_mean_squared_error: 1.7301\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 4s 69ms/step - loss: 2.9617 - root_mean_squared_error: 1.7210 - val_loss: 3.6569 - val_root_mean_squared_error: 1.9123\n",
      "Epoch 23/30\n",
      "57/57 [==============================] - 4s 78ms/step - loss: 3.0491 - root_mean_squared_error: 1.7462 - val_loss: 2.7316 - val_root_mean_squared_error: 1.6528\n",
      "Epoch 24/30\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 2.7778 - root_mean_squared_error: 1.6667 - val_loss: 2.7208 - val_root_mean_squared_error: 1.6495\n",
      "Epoch 25/30\n",
      "57/57 [==============================] - 4s 64ms/step - loss: 2.9344 - root_mean_squared_error: 1.7130 - val_loss: 2.8793 - val_root_mean_squared_error: 1.6969\n",
      "Epoch 26/30\n",
      "57/57 [==============================] - 4s 65ms/step - loss: 2.7131 - root_mean_squared_error: 1.6471 - val_loss: 2.6324 - val_root_mean_squared_error: 1.6225\n",
      "Epoch 27/30\n",
      "57/57 [==============================] - 5s 80ms/step - loss: 2.8180 - root_mean_squared_error: 1.6787 - val_loss: 2.5159 - val_root_mean_squared_error: 1.5862\n",
      "Epoch 28/30\n",
      "57/57 [==============================] - 4s 77ms/step - loss: 2.7952 - root_mean_squared_error: 1.6719 - val_loss: 2.6190 - val_root_mean_squared_error: 1.6183\n",
      "Epoch 29/30\n",
      "57/57 [==============================] - 4s 76ms/step - loss: 2.7842 - root_mean_squared_error: 1.6686 - val_loss: 3.0501 - val_root_mean_squared_error: 1.7465\n",
      "Epoch 30/30\n",
      "57/57 [==============================] - 4s 73ms/step - loss: 2.9076 - root_mean_squared_error: 1.7052 - val_loss: 2.8019 - val_root_mean_squared_error: 1.6739\n",
      "501/501 [==============================] - 2s 4ms/step - loss: 2.7990 - root_mean_squared_error: 1.6730\n",
      "\n",
      "training time 127.983765\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 2.799013614654541 with RMSE metric of 1.6730252504348755\n",
      "192/192 [==============================] - 1s 4ms/step - loss: 3.1314 - root_mean_squared_error: 1.7696\n",
      "Test set has a loss (MSE) of 3.1314218044281006 with RMSE metric of 1.7695823907852173\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "322/322 [==============================] - 24s 71ms/step - loss: 4.4573 - root_mean_squared_error: 2.1112 - val_loss: 3.1163 - val_root_mean_squared_error: 1.7653\n",
      "Epoch 2/30\n",
      "322/322 [==============================] - 24s 76ms/step - loss: 3.6481 - root_mean_squared_error: 1.9100 - val_loss: 3.4953 - val_root_mean_squared_error: 1.8696\n",
      "Epoch 3/30\n",
      "322/322 [==============================] - 23s 71ms/step - loss: 3.4593 - root_mean_squared_error: 1.8599 - val_loss: 2.9348 - val_root_mean_squared_error: 1.7131\n",
      "Epoch 4/30\n",
      "322/322 [==============================] - 21s 64ms/step - loss: 3.4689 - root_mean_squared_error: 1.8625 - val_loss: 2.7625 - val_root_mean_squared_error: 1.6621\n",
      "Epoch 5/30\n",
      "322/322 [==============================] - 47s 146ms/step - loss: 3.4782 - root_mean_squared_error: 1.8650 - val_loss: 2.9663 - val_root_mean_squared_error: 1.7223\n",
      "Epoch 6/30\n",
      "322/322 [==============================] - 27s 84ms/step - loss: 3.4943 - root_mean_squared_error: 1.8693 - val_loss: 3.2683 - val_root_mean_squared_error: 1.8078\n",
      "Epoch 7/30\n",
      "322/322 [==============================] - 24s 74ms/step - loss: 3.4740 - root_mean_squared_error: 1.8639 - val_loss: 2.8684 - val_root_mean_squared_error: 1.6936\n",
      "Epoch 8/30\n",
      "322/322 [==============================] - 23s 72ms/step - loss: 3.5061 - root_mean_squared_error: 1.8725 - val_loss: 2.8643 - val_root_mean_squared_error: 1.6924\n",
      "Epoch 9/30\n",
      "322/322 [==============================] - 23s 72ms/step - loss: 3.5422 - root_mean_squared_error: 1.8821 - val_loss: 2.8525 - val_root_mean_squared_error: 1.6889\n",
      "Epoch 10/30\n",
      "322/322 [==============================] - 23s 71ms/step - loss: 3.5345 - root_mean_squared_error: 1.8800 - val_loss: 2.9733 - val_root_mean_squared_error: 1.7243\n",
      "Epoch 11/30\n",
      "322/322 [==============================] - 25s 77ms/step - loss: 3.5301 - root_mean_squared_error: 1.8789 - val_loss: 2.8238 - val_root_mean_squared_error: 1.6804\n",
      "Epoch 12/30\n",
      "322/322 [==============================] - 27s 85ms/step - loss: 3.5096 - root_mean_squared_error: 1.8734 - val_loss: 3.0044 - val_root_mean_squared_error: 1.7333\n",
      "Epoch 13/30\n",
      "322/322 [==============================] - 24s 74ms/step - loss: 3.5743 - root_mean_squared_error: 1.8906 - val_loss: 2.8363 - val_root_mean_squared_error: 1.6841\n",
      "Epoch 14/30\n",
      "322/322 [==============================] - 25s 77ms/step - loss: 3.6120 - root_mean_squared_error: 1.9005 - val_loss: 3.0033 - val_root_mean_squared_error: 1.7330\n",
      "Epoch 15/30\n",
      "322/322 [==============================] - 24s 74ms/step - loss: 3.6412 - root_mean_squared_error: 1.9082 - val_loss: 2.9487 - val_root_mean_squared_error: 1.7172\n",
      "Epoch 16/30\n",
      "322/322 [==============================] - 26s 81ms/step - loss: 3.6421 - root_mean_squared_error: 1.9084 - val_loss: 2.8512 - val_root_mean_squared_error: 1.6885\n",
      "Epoch 17/30\n",
      "322/322 [==============================] - 24s 75ms/step - loss: 3.6607 - root_mean_squared_error: 1.9133 - val_loss: 2.8950 - val_root_mean_squared_error: 1.7015\n",
      "Epoch 18/30\n",
      "322/322 [==============================] - 24s 74ms/step - loss: 3.6773 - root_mean_squared_error: 1.9176 - val_loss: 3.0412 - val_root_mean_squared_error: 1.7439\n",
      "Epoch 19/30\n",
      "322/322 [==============================] - 25s 77ms/step - loss: 3.6731 - root_mean_squared_error: 1.9165 - val_loss: 3.3425 - val_root_mean_squared_error: 1.8283\n",
      "Epoch 20/30\n",
      "322/322 [==============================] - 29s 90ms/step - loss: 3.9282 - root_mean_squared_error: 1.9820 - val_loss: 3.1693 - val_root_mean_squared_error: 1.7803\n",
      "Epoch 21/30\n",
      "322/322 [==============================] - 25s 77ms/step - loss: 3.8312 - root_mean_squared_error: 1.9573 - val_loss: 3.3389 - val_root_mean_squared_error: 1.8273\n",
      "Epoch 22/30\n",
      "322/322 [==============================] - 34s 105ms/step - loss: 3.9270 - root_mean_squared_error: 1.9817 - val_loss: 3.0933 - val_root_mean_squared_error: 1.7588\n",
      "Epoch 23/30\n",
      "322/322 [==============================] - 33s 102ms/step - loss: 3.9237 - root_mean_squared_error: 1.9808 - val_loss: 3.2224 - val_root_mean_squared_error: 1.7951\n",
      "Epoch 24/30\n",
      "322/322 [==============================] - 34s 105ms/step - loss: 3.8774 - root_mean_squared_error: 1.9691 - val_loss: 3.1137 - val_root_mean_squared_error: 1.7646\n",
      "Epoch 25/30\n",
      "322/322 [==============================] - 34s 107ms/step - loss: 3.8701 - root_mean_squared_error: 1.9673 - val_loss: 3.0840 - val_root_mean_squared_error: 1.7561\n",
      "Epoch 26/30\n",
      "322/322 [==============================] - 32s 101ms/step - loss: 3.8390 - root_mean_squared_error: 1.9593 - val_loss: 3.0485 - val_root_mean_squared_error: 1.7460\n",
      "Epoch 27/30\n",
      "322/322 [==============================] - 34s 107ms/step - loss: 3.8573 - root_mean_squared_error: 1.9640 - val_loss: 3.6026 - val_root_mean_squared_error: 1.8981\n",
      "Epoch 28/30\n",
      "322/322 [==============================] - 33s 101ms/step - loss: 3.9082 - root_mean_squared_error: 1.9769 - val_loss: 3.2724 - val_root_mean_squared_error: 1.8090\n",
      "Epoch 29/30\n",
      "322/322 [==============================] - 33s 101ms/step - loss: 3.8595 - root_mean_squared_error: 1.9646 - val_loss: 3.6428 - val_root_mean_squared_error: 1.9086\n",
      "Epoch 30/30\n",
      "322/322 [==============================] - 34s 106ms/step - loss: 3.9590 - root_mean_squared_error: 1.9897 - val_loss: 3.0969 - val_root_mean_squared_error: 1.7598\n",
      "2871/2871 [==============================] - 18s 6ms/step - loss: 3.3426 - root_mean_squared_error: 1.8283\n",
      "\n",
      "training time 854.531749\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 3.342599391937256 with RMSE metric of 1.8282777070999146\n",
      "1119/1119 [==============================] - 7s 6ms/step - loss: 3.5606 - root_mean_squared_error: 1.8870\n",
      "Test set has a loss (MSE) of 3.5606496334075928 with RMSE metric of 1.8869683742523193\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/30\n",
      "95/95 [==============================] - 11s 103ms/step - loss: 8.6108 - root_mean_squared_error: 2.9344 - val_loss: 6.6273 - val_root_mean_squared_error: 2.5744\n",
      "Epoch 2/30\n",
      "95/95 [==============================] - 9s 95ms/step - loss: 6.2614 - root_mean_squared_error: 2.5023 - val_loss: 5.8808 - val_root_mean_squared_error: 2.4250\n",
      "Epoch 3/30\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 5.9429 - root_mean_squared_error: 2.4378 - val_loss: 5.6364 - val_root_mean_squared_error: 2.3741\n",
      "Epoch 4/30\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 5.9161 - root_mean_squared_error: 2.4323 - val_loss: 5.8277 - val_root_mean_squared_error: 2.4141\n",
      "Epoch 5/30\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 5.9150 - root_mean_squared_error: 2.4321 - val_loss: 5.7126 - val_root_mean_squared_error: 2.3901\n",
      "Epoch 6/30\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 6.0281 - root_mean_squared_error: 2.4552 - val_loss: 5.6366 - val_root_mean_squared_error: 2.3742\n",
      "Epoch 7/30\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 5.8586 - root_mean_squared_error: 2.4204 - val_loss: 6.2296 - val_root_mean_squared_error: 2.4959\n",
      "Epoch 8/30\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 5.7886 - root_mean_squared_error: 2.4060 - val_loss: 5.6251 - val_root_mean_squared_error: 2.3717\n",
      "Epoch 9/30\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 5.8367 - root_mean_squared_error: 2.4159 - val_loss: 5.5962 - val_root_mean_squared_error: 2.3656\n",
      "Epoch 10/30\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 5.8800 - root_mean_squared_error: 2.4249 - val_loss: 5.5166 - val_root_mean_squared_error: 2.3487\n",
      "Epoch 11/30\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 5.9557 - root_mean_squared_error: 2.4404 - val_loss: 5.9682 - val_root_mean_squared_error: 2.4430\n",
      "Epoch 12/30\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 5.7368 - root_mean_squared_error: 2.3952 - val_loss: 5.5520 - val_root_mean_squared_error: 2.3563\n",
      "Epoch 13/30\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 5.6910 - root_mean_squared_error: 2.3856 - val_loss: 5.6282 - val_root_mean_squared_error: 2.3724\n",
      "Epoch 14/30\n",
      "95/95 [==============================] - 9s 97ms/step - loss: 5.7350 - root_mean_squared_error: 2.3948 - val_loss: 5.5206 - val_root_mean_squared_error: 2.3496\n",
      "Epoch 15/30\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 5.7877 - root_mean_squared_error: 2.4058 - val_loss: 5.6644 - val_root_mean_squared_error: 2.3800\n",
      "Epoch 16/30\n",
      "95/95 [==============================] - 9s 100ms/step - loss: 5.7469 - root_mean_squared_error: 2.3973 - val_loss: 5.6420 - val_root_mean_squared_error: 2.3753\n",
      "Epoch 17/30\n",
      "95/95 [==============================] - 8s 80ms/step - loss: 5.7283 - root_mean_squared_error: 2.3934 - val_loss: 5.7244 - val_root_mean_squared_error: 2.3926\n",
      "Epoch 18/30\n",
      "95/95 [==============================] - 8s 83ms/step - loss: 5.8429 - root_mean_squared_error: 2.4172 - val_loss: 5.5637 - val_root_mean_squared_error: 2.3588\n",
      "Epoch 19/30\n",
      "95/95 [==============================] - 7s 71ms/step - loss: 5.8085 - root_mean_squared_error: 2.4101 - val_loss: 5.5054 - val_root_mean_squared_error: 2.3464\n",
      "Epoch 20/30\n",
      "95/95 [==============================] - 7s 72ms/step - loss: 5.7404 - root_mean_squared_error: 2.3959 - val_loss: 5.5432 - val_root_mean_squared_error: 2.3544\n",
      "Epoch 21/30\n",
      "95/95 [==============================] - 7s 74ms/step - loss: 5.8692 - root_mean_squared_error: 2.4226 - val_loss: 6.0243 - val_root_mean_squared_error: 2.4544\n",
      "Epoch 22/30\n",
      "95/95 [==============================] - 7s 74ms/step - loss: 5.8604 - root_mean_squared_error: 2.4208 - val_loss: 5.5090 - val_root_mean_squared_error: 2.3471\n",
      "Epoch 23/30\n",
      "95/95 [==============================] - 7s 71ms/step - loss: 5.8012 - root_mean_squared_error: 2.4086 - val_loss: 5.5122 - val_root_mean_squared_error: 2.3478\n",
      "Epoch 24/30\n",
      "95/95 [==============================] - 6s 69ms/step - loss: 5.6716 - root_mean_squared_error: 2.3815 - val_loss: 5.7480 - val_root_mean_squared_error: 2.3975\n",
      "Epoch 25/30\n",
      "95/95 [==============================] - 7s 74ms/step - loss: 5.8333 - root_mean_squared_error: 2.4152 - val_loss: 6.0189 - val_root_mean_squared_error: 2.4533\n",
      "Epoch 26/30\n",
      "95/95 [==============================] - 8s 79ms/step - loss: 5.8677 - root_mean_squared_error: 2.4223 - val_loss: 6.0467 - val_root_mean_squared_error: 2.4590\n",
      "Epoch 27/30\n",
      "95/95 [==============================] - 7s 76ms/step - loss: 5.7381 - root_mean_squared_error: 2.3954 - val_loss: 5.5079 - val_root_mean_squared_error: 2.3469\n",
      "Epoch 28/30\n",
      "95/95 [==============================] - 7s 79ms/step - loss: 5.7169 - root_mean_squared_error: 2.3910 - val_loss: 5.5808 - val_root_mean_squared_error: 2.3624\n",
      "Epoch 29/30\n",
      "95/95 [==============================] - 7s 76ms/step - loss: 5.9061 - root_mean_squared_error: 2.4303 - val_loss: 5.6622 - val_root_mean_squared_error: 2.3795\n",
      "Epoch 30/30\n",
      "95/95 [==============================] - 8s 88ms/step - loss: 5.8595 - root_mean_squared_error: 2.4206 - val_loss: 5.5406 - val_root_mean_squared_error: 2.3538\n",
      "848/848 [==============================] - 6s 7ms/step - loss: 5.4848 - root_mean_squared_error: 2.3420\n",
      "\n",
      "training time 267.681484\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 5.484818935394287 with RMSE metric of 2.3419690132141113\n",
      "372/372 [==============================] - 3s 7ms/step - loss: 6.0600 - root_mean_squared_error: 2.4617\n",
      "Test set has a loss (MSE) of 6.059990406036377 with RMSE metric of 2.461704730987549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (10):\n",
    "    ## Simple RNN Model\n",
    "    ## Initialize\n",
    "    model_name = 'SimpleRNN'\n",
    "    num_layers = 3\n",
    "    epochs_num = 30\n",
    "    batch_size_set = 200\n",
    "    optimizer_set = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    forecast_distance=6\n",
    "    number_readings=8\n",
    "\n",
    "    ## Get New Data\n",
    "    a=DataSampling(path=path)\n",
    "    a.samplingDF\n",
    "    X_train,X_test,y_train,y_test = a.SampleValidSequences(num_clients=3, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "\n",
    "    #SETUP THE STACK\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(SimpleRNN(150, activation='tanh', input_shape=(number_readings,1)))\n",
    "    model_rnn.add(Dropout(0.1))\n",
    "    model_rnn.add(Dense(10))\n",
    "    model_rnn.add(Dense(1))\n",
    "    #START THE RUN\n",
    "    print('\\nRunning RNN model...')\n",
    "    start = datetime.now()\n",
    "\n",
    "    model_rnn.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    hist = model_rnn.fit(X_train, y_train, epochs=epochs_num, validation_split=0.3, batch_size=batch_size_set)\n",
    "    train_loss, train_rmse = model_rnn.evaluate(X_train, y_train)\n",
    "    train_time = (datetime.now()-start).total_seconds()\n",
    "    print(\"\\ntraining time %s\" % train_time)\n",
    "\n",
    "    #PRINT RESULTS\n",
    "    print(f'RNN Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "    #Test set results\n",
    "    test_loss, test_rmse = model_rnn.evaluate(X_test, y_test)\n",
    "    print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "\n",
    "    #y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "    Execution_time.append(train_time)\n",
    "    train_rmse_results.append(train_rmse)\n",
    "    test_rmse_results.append(test_rmse)\n",
    "    run_id.append(model_name+str(datetime.now()))\n",
    "    sample_size.append(len(X_train))\n",
    "    epochs.append(epochs_num)\n",
    "    batch_size.append(batch_size_set)\n",
    "    optimizer.append(optimizer_set)\n",
    "    layers.append(num_layers)\n",
    "    forecast_distance_perf.append(forecast_distance)\n",
    "    prev_readings.append(number_readings)\n",
    "\n",
    "## determine why this is pushing out lists instead of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running LSTM model...\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 4s 96ms/step - loss: 42.9958 - root_mean_squared_error: 6.5571 - val_loss: 29.9209 - val_root_mean_squared_error: 5.4700\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 14.4209 - root_mean_squared_error: 3.7975 - val_loss: 12.4249 - val_root_mean_squared_error: 3.5249\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 9.3560 - root_mean_squared_error: 3.0588 - val_loss: 16.2381 - val_root_mean_squared_error: 4.0297\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 43ms/step - loss: 8.2417 - root_mean_squared_error: 2.8708 - val_loss: 9.3973 - val_root_mean_squared_error: 3.0655\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 7.3981 - root_mean_squared_error: 2.7200 - val_loss: 9.3159 - val_root_mean_squared_error: 3.0522\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 6.7376 - root_mean_squared_error: 2.5957 - val_loss: 8.7871 - val_root_mean_squared_error: 2.9643\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 6.3326 - root_mean_squared_error: 2.5165 - val_loss: 7.6956 - val_root_mean_squared_error: 2.7741\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 5.5694 - root_mean_squared_error: 2.3600 - val_loss: 6.3314 - val_root_mean_squared_error: 2.5162\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 5.5220 - root_mean_squared_error: 2.3499 - val_loss: 6.2760 - val_root_mean_squared_error: 2.5052\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 5.1472 - root_mean_squared_error: 2.2688 - val_loss: 5.8425 - val_root_mean_squared_error: 2.4171\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 4.7295 - root_mean_squared_error: 2.1747 - val_loss: 5.6525 - val_root_mean_squared_error: 2.3775\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 4.8396 - root_mean_squared_error: 2.1999 - val_loss: 5.7000 - val_root_mean_squared_error: 2.3875\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 4.7664 - root_mean_squared_error: 2.1832 - val_loss: 6.5858 - val_root_mean_squared_error: 2.5663\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 4.5999 - root_mean_squared_error: 2.1447 - val_loss: 5.6242 - val_root_mean_squared_error: 2.3715\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 4.3275 - root_mean_squared_error: 2.0803 - val_loss: 6.8561 - val_root_mean_squared_error: 2.6184\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 4.5184 - root_mean_squared_error: 2.1257 - val_loss: 5.5807 - val_root_mean_squared_error: 2.3624\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 4.3674 - root_mean_squared_error: 2.0898 - val_loss: 5.9502 - val_root_mean_squared_error: 2.4393\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 4.6133 - root_mean_squared_error: 2.1479 - val_loss: 5.3939 - val_root_mean_squared_error: 2.3225\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 4.3385 - root_mean_squared_error: 2.0829 - val_loss: 6.6694 - val_root_mean_squared_error: 2.5825\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 4.3450 - root_mean_squared_error: 2.0845 - val_loss: 5.3073 - val_root_mean_squared_error: 2.3038\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 3.8971 - root_mean_squared_error: 1.9741\n",
      "\n",
      "training time 13.531632\n",
      "LSTM Model: \n",
      "Training set has a loss (MSE) of 3.8970932960510254 with RMSE metric of 1.974105715751648\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 2.9502 - root_mean_squared_error: 1.7176\n",
      "Test set has a loss (MSE) of 2.9502344131469727 with RMSE metric of 1.7176246643066406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## LSTM Model\n",
    "## Initialize\n",
    "model_name = 'LSTM - Personal'\n",
    "num_layers = 4\n",
    "epochs_num = 20\n",
    "batch_size_set = 100\n",
    "optimizer_set = 'adam'\n",
    "forecast_distance=6\n",
    "number_readings=8\n",
    "\n",
    "## Get New Data\n",
    "a=DataSampling(path=path)\n",
    "a.samplingDF\n",
    "X_train,X_test,y_train,y_test = a.SampleValidSequences(num_clients=1, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "\n",
    "#SETUP THE STACK\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(150, activation='relu', input_shape=(number_readings, 1),return_sequences=True))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(LSTM(64, activation='relu'))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(10, activation='relu'))\n",
    "model_lstm.add(Dense(1))\n",
    "\n",
    "#START THE RUN\n",
    "print('\\nRunning LSTM model...')\n",
    "start = datetime.now()\n",
    "\n",
    "model_lstm.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "hist = model_lstm.fit(X_train, y_train, epochs=epochs_num, validation_split=0.2, batch_size=batch_size_set)\n",
    "train_loss, train_rmse = model_lstm.evaluate(X_train, y_train)\n",
    "train_time = (datetime.now()-start).total_seconds()\n",
    "print(\"\\ntraining time %s\" % train_time)\n",
    "\n",
    "#PRINT RESULTS\n",
    "print(f'LSTM Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "#Test set results\n",
    "test_loss, test_rmse = model_lstm.evaluate(X_test, y_test)\n",
    "print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "\n",
    "#y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "Execution_time.append(train_time)\n",
    "train_rmse_results.append(train_rmse)\n",
    "test_rmse_results.append(test_rmse)\n",
    "run_id.append(model_name+str(datetime.now()))\n",
    "sample_size.append(len(X_train))\n",
    "epochs.append(epochs_num)\n",
    "batch_size.append(batch_size_set)\n",
    "optimizer.append(optimizer_set)\n",
    "layers.append(num_layers)\n",
    "forecast_distance_perf.append(forecast_distance)\n",
    "prev_readings.append(number_readings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GRU model...\n",
      "Epoch 1/6\n",
      "39/39 [==============================] - 4s 36ms/step - loss: 86.1960 - root_mean_squared_error: 9.2842 - val_loss: 10.3675 - val_root_mean_squared_error: 3.2199\n",
      "Epoch 2/6\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 5.6330 - root_mean_squared_error: 2.3734 - val_loss: 5.5414 - val_root_mean_squared_error: 2.3540\n",
      "Epoch 3/6\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 4.2514 - root_mean_squared_error: 2.0619 - val_loss: 5.0508 - val_root_mean_squared_error: 2.2474\n",
      "Epoch 4/6\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 3.8411 - root_mean_squared_error: 1.9599 - val_loss: 4.4892 - val_root_mean_squared_error: 2.1188\n",
      "Epoch 5/6\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 3.3979 - root_mean_squared_error: 1.8433 - val_loss: 4.0740 - val_root_mean_squared_error: 2.0184\n",
      "Epoch 6/6\n",
      "39/39 [==============================] - 1s 19ms/step - loss: 3.1036 - root_mean_squared_error: 1.7617 - val_loss: 3.4300 - val_root_mean_squared_error: 1.8520\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2.9581 - root_mean_squared_error: 1.7199\n",
      "\n",
      "training time 8.162106\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 2.9580957889556885 with RMSE metric of 1.7199115753173828\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 3.1399 - root_mean_squared_error: 1.7720\n",
      "Test set has a loss (MSE) of 3.1399407386779785 with RMSE metric of 1.771987795829773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## GRU Model\n",
    "## Initialize\n",
    "model_name = 'GRU - Personal'\n",
    "num_layers = 4\n",
    "epochs_num = 6\n",
    "batch_size_set = 100\n",
    "optimizer_set = 'adam'\n",
    "forecast_distance=6\n",
    "number_readings=8\n",
    "\n",
    "## Get New Data\n",
    "a=DataSampling(path=path)\n",
    "a.samplingDF\n",
    "X_train,X_test,y_train,y_test = a.SampleValidSequences(num_clients=1, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "#SETUP THE STACK\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(60, activation='relu', input_shape=(number_readings,1), return_sequences=True))\n",
    "model_gru.add(GRU(20, activation='relu'))\n",
    "model_gru.add(Dense(10))\n",
    "model_gru.add(Dense(1))\n",
    "\n",
    "\n",
    "#START THE RUN\n",
    "print('\\nRunning GRU model...')\n",
    "start = datetime.now()\n",
    "\n",
    "model_gru.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "hist = model_gru.fit(X_train, y_train, epochs=epochs_num, validation_split=0.2, batch_size=batch_size_set)\n",
    "train_loss, train_rmse = model_gru.evaluate(X_train, y_train)\n",
    "train_time = (datetime.now()-start).total_seconds()\n",
    "print(\"\\ntraining time %s\" % train_time)\n",
    "\n",
    "#PRINT RESULTS\n",
    "print(f'GRU Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "#Test set results\n",
    "test_loss, test_rmse = model_gru.evaluate(X_test, y_test)\n",
    "print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "\n",
    "#y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "Execution_time.append(train_time)\n",
    "train_rmse_results.append(train_rmse)\n",
    "test_rmse_results.append(test_rmse)\n",
    "run_id.append(model_name+str(datetime.now()))\n",
    "sample_size.append(len(X_train))\n",
    "epochs.append(epochs_num)\n",
    "batch_size.append(batch_size_set)\n",
    "optimizer.append(optimizer_set)\n",
    "layers.append(num_layers)\n",
    "forecast_distance_perf.append(forecast_distance)\n",
    "prev_readings.append(number_readings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running CNN RNN model...\n",
      "Epoch 1/15\n",
      "403/403 [==============================] - 5s 9ms/step - loss: 7.2989 - root_mean_squared_error: 2.7016 - val_loss: 5.0363 - val_root_mean_squared_error: 2.2442\n",
      "Epoch 2/15\n",
      "403/403 [==============================] - 3s 8ms/step - loss: 4.4570 - root_mean_squared_error: 2.1112 - val_loss: 4.7884 - val_root_mean_squared_error: 2.1882\n",
      "Epoch 3/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 4.2042 - root_mean_squared_error: 2.0504 - val_loss: 4.4610 - val_root_mean_squared_error: 2.1121\n",
      "Epoch 4/15\n",
      "403/403 [==============================] - 3s 8ms/step - loss: 4.0461 - root_mean_squared_error: 2.0115 - val_loss: 4.8105 - val_root_mean_squared_error: 2.1933\n",
      "Epoch 5/15\n",
      "403/403 [==============================] - 3s 8ms/step - loss: 3.9426 - root_mean_squared_error: 1.9856 - val_loss: 4.4112 - val_root_mean_squared_error: 2.1003\n",
      "Epoch 6/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 3.9215 - root_mean_squared_error: 1.9803 - val_loss: 5.1797 - val_root_mean_squared_error: 2.2759\n",
      "Epoch 7/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 3.9605 - root_mean_squared_error: 1.9901 - val_loss: 4.2381 - val_root_mean_squared_error: 2.0587\n",
      "Epoch 8/15\n",
      "403/403 [==============================] - 3s 7ms/step - loss: 3.8840 - root_mean_squared_error: 1.9708 - val_loss: 4.2738 - val_root_mean_squared_error: 2.0673\n",
      "Epoch 9/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 3.8923 - root_mean_squared_error: 1.9729 - val_loss: 4.3412 - val_root_mean_squared_error: 2.0836\n",
      "Epoch 10/15\n",
      "403/403 [==============================] - 3s 9ms/step - loss: 3.8652 - root_mean_squared_error: 1.9660 - val_loss: 4.4712 - val_root_mean_squared_error: 2.1145\n",
      "Epoch 11/15\n",
      "403/403 [==============================] - 3s 8ms/step - loss: 3.8434 - root_mean_squared_error: 1.9605 - val_loss: 5.2143 - val_root_mean_squared_error: 2.2835\n",
      "Epoch 12/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 3.8549 - root_mean_squared_error: 1.9634 - val_loss: 4.2543 - val_root_mean_squared_error: 2.0626\n",
      "Epoch 13/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 3.8309 - root_mean_squared_error: 1.9573 - val_loss: 4.2381 - val_root_mean_squared_error: 2.0587\n",
      "Epoch 14/15\n",
      "403/403 [==============================] - 4s 9ms/step - loss: 3.8506 - root_mean_squared_error: 1.9623 - val_loss: 4.3139 - val_root_mean_squared_error: 2.0770\n",
      "Epoch 15/15\n",
      "403/403 [==============================] - 3s 8ms/step - loss: 3.7934 - root_mean_squared_error: 1.9477 - val_loss: 4.2299 - val_root_mean_squared_error: 2.0567\n",
      "786/786 [==============================] - 4s 5ms/step - loss: 4.2848 - root_mean_squared_error: 2.0700\n",
      "\n",
      "training time 57.233281\n",
      "CNN RNN Model: \n",
      "Training set has a loss (MSE) of 4.284834861755371 with RMSE metric of 2.069984197616577\n",
      "322/322 [==============================] - 1s 4ms/step - loss: 4.1648 - root_mean_squared_error: 2.0408\n",
      "Test set has a loss (MSE) of 4.164759159088135 with RMSE metric of 2.04077410697937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## CNN RNN\n",
    "## Initialize\n",
    "model_name = 'CNN - RNN'\n",
    "num_layers = 4\n",
    "epochs_num = 15\n",
    "batch_size_set = 50\n",
    "optimizer_set = 'adam'\n",
    "forecast_distance=6\n",
    "number_readings=8\n",
    "\n",
    "## Get New Data\n",
    "a=DataSampling(path=path)\n",
    "a.samplingDF\n",
    "X_train,X_test,y_train,y_test = a.SampleValidSequences(num_clients=3, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "#SETUP THE STACK\n",
    "\n",
    "model_cnn_rnn = Sequential()\n",
    "model_cnn_rnn.add(tf.keras.layers.Conv1D(32, 2, activation='relu', input_shape=(number_readings,1)))\n",
    "model_cnn_rnn.add(tf.keras.layers.MaxPooling1D((1)))\n",
    "model_cnn_rnn.add(SimpleRNN(120, activation='relu', return_sequences=True))\n",
    "#model_cnn_rnn.add(LSTM(10, activation='relu', return_sequences=True))\n",
    "model_cnn_rnn.add(Flatten())\n",
    "model_cnn_rnn.add(Dense(1))\n",
    "\n",
    "\n",
    "#START THE RUN\n",
    "print('\\nRunning CNN RNN model...')\n",
    "start = datetime.now()\n",
    "\n",
    "model_cnn_rnn.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "hist = model_cnn_rnn.fit(X_train, y_train, epochs=epochs_num, validation_split=0.2, batch_size=batch_size_set)\n",
    "train_loss, train_rmse = model_gru.evaluate(X_train, y_train)\n",
    "train_time = (datetime.now()-start).total_seconds()\n",
    "print(\"\\ntraining time %s\" % train_time)\n",
    "\n",
    "#PRINT RESULTS\n",
    "print(f'CNN RNN Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "#Test set results\n",
    "test_loss, test_rmse = model_cnn_rnn.evaluate(X_test, y_test)\n",
    "print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "\n",
    "#y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "Execution_time.append(train_time)\n",
    "train_rmse_results.append(train_rmse)\n",
    "test_rmse_results.append(test_rmse)\n",
    "run_id.append(model_name+str(datetime.now()))\n",
    "sample_size.append(len(X_train))\n",
    "epochs.append(epochs_num)\n",
    "batch_size.append(batch_size_set)\n",
    "optimizer.append(optimizer_set)\n",
    "layers.append(num_layers)\n",
    "forecast_distance_perf.append(forecast_distance)\n",
    "prev_readings.append(number_readings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GRU model...\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 4s 48ms/step - loss: 161.7147 - root_mean_squared_error: 12.7167 - val_loss: 52.0066 - val_root_mean_squared_error: 7.2116\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 33.9259 - root_mean_squared_error: 5.8246 - val_loss: 12.6275 - val_root_mean_squared_error: 3.5535\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 6.8331 - root_mean_squared_error: 2.6140 - val_loss: 6.2372 - val_root_mean_squared_error: 2.4974\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 3.9389 - root_mean_squared_error: 1.9847 - val_loss: 5.7127 - val_root_mean_squared_error: 2.3901\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 3.5591 - root_mean_squared_error: 1.8866 - val_loss: 5.4202 - val_root_mean_squared_error: 2.3281\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 3.4298 - root_mean_squared_error: 1.8520 - val_loss: 5.3547 - val_root_mean_squared_error: 2.3140\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 3.3586 - root_mean_squared_error: 1.8327 - val_loss: 5.2658 - val_root_mean_squared_error: 2.2947\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 3.3028 - root_mean_squared_error: 1.8174 - val_loss: 5.2284 - val_root_mean_squared_error: 2.2866\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 3.2077 - root_mean_squared_error: 1.7910 - val_loss: 5.0915 - val_root_mean_squared_error: 2.2564\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 3.1498 - root_mean_squared_error: 1.7748 - val_loss: 5.0465 - val_root_mean_squared_error: 2.2464\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 3.4775 - root_mean_squared_error: 1.8648\n",
      "\n",
      "training time 8.366772\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 3.4774603843688965 with RMSE metric of 1.8647949695587158\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 5.1516 - root_mean_squared_error: 2.2697\n",
      "Test set has a loss (MSE) of 5.15162467956543 with RMSE metric of 2.269719123840332\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 5s 25ms/step - loss: 23.5996 - root_mean_squared_error: 4.8579 - val_loss: 4.4147 - val_root_mean_squared_error: 2.1011\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 4.5487 - root_mean_squared_error: 2.1328 - val_loss: 3.7420 - val_root_mean_squared_error: 1.9344\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 1s 19ms/step - loss: 3.8334 - root_mean_squared_error: 1.9579 - val_loss: 3.0976 - val_root_mean_squared_error: 1.7600\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 3.4964 - root_mean_squared_error: 1.8699 - val_loss: 2.9344 - val_root_mean_squared_error: 1.7130\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 3.2918 - root_mean_squared_error: 1.8143 - val_loss: 2.7946 - val_root_mean_squared_error: 1.6717\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 3.2037 - root_mean_squared_error: 1.7899 - val_loss: 2.7654 - val_root_mean_squared_error: 1.6630\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 3.1342 - root_mean_squared_error: 1.7704 - val_loss: 2.7840 - val_root_mean_squared_error: 1.6685\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 3.0944 - root_mean_squared_error: 1.7591 - val_loss: 2.6523 - val_root_mean_squared_error: 1.6286\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 3.1622 - root_mean_squared_error: 1.7783 - val_loss: 2.6364 - val_root_mean_squared_error: 1.6237\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 2.9914 - root_mean_squared_error: 1.7296 - val_loss: 3.2345 - val_root_mean_squared_error: 1.7985\n",
      "258/258 [==============================] - 2s 6ms/step - loss: 3.5178 - root_mean_squared_error: 1.8756\n",
      "\n",
      "training time 16.832319\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 3.517841100692749 with RMSE metric of 1.8755909204483032\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 3.1623 - root_mean_squared_error: 1.7783\n",
      "Test set has a loss (MSE) of 3.162264108657837 with RMSE metric of 1.7782756090164185\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/10\n",
      "60/60 [==============================] - 4s 31ms/step - loss: 35.4349 - root_mean_squared_error: 5.9527 - val_loss: 5.9787 - val_root_mean_squared_error: 2.4451\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 4.9026 - root_mean_squared_error: 2.2142 - val_loss: 4.7378 - val_root_mean_squared_error: 2.1766\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 4.2222 - root_mean_squared_error: 2.0548 - val_loss: 4.3116 - val_root_mean_squared_error: 2.0764\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 3.7831 - root_mean_squared_error: 1.9450 - val_loss: 3.4918 - val_root_mean_squared_error: 1.8686\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 3.5714 - root_mean_squared_error: 1.8898 - val_loss: 3.2998 - val_root_mean_squared_error: 1.8165\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 3.5677 - root_mean_squared_error: 1.8888 - val_loss: 3.3565 - val_root_mean_squared_error: 1.8321\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 3.3898 - root_mean_squared_error: 1.8411 - val_loss: 3.2280 - val_root_mean_squared_error: 1.7967\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 3.3749 - root_mean_squared_error: 1.8371 - val_loss: 3.1186 - val_root_mean_squared_error: 1.7659\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 3.3745 - root_mean_squared_error: 1.8370 - val_loss: 3.3241 - val_root_mean_squared_error: 1.8232\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 3.2337 - root_mean_squared_error: 1.7983 - val_loss: 2.9900 - val_root_mean_squared_error: 1.7292\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 3.1263 - root_mean_squared_error: 1.7681\n",
      "\n",
      "training time 18.127947\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 3.1263070106506348 with RMSE metric of 1.7681366205215454\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.3602 - root_mean_squared_error: 1.8331\n",
      "Test set has a loss (MSE) of 3.360171318054199 with RMSE metric of 1.8330769538879395\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/10\n",
      "83/83 [==============================] - 4s 25ms/step - loss: 33.2155 - root_mean_squared_error: 5.7633 - val_loss: 7.2686 - val_root_mean_squared_error: 2.6960\n",
      "Epoch 2/10\n",
      "83/83 [==============================] - 2s 21ms/step - loss: 7.9089 - root_mean_squared_error: 2.8123 - val_loss: 6.8048 - val_root_mean_squared_error: 2.6086\n",
      "Epoch 3/10\n",
      "83/83 [==============================] - 2s 23ms/step - loss: 7.5317 - root_mean_squared_error: 2.7444 - val_loss: 6.4942 - val_root_mean_squared_error: 2.5484\n",
      "Epoch 4/10\n",
      "83/83 [==============================] - 2s 20ms/step - loss: 7.2479 - root_mean_squared_error: 2.6922 - val_loss: 7.2527 - val_root_mean_squared_error: 2.6931\n",
      "Epoch 5/10\n",
      "83/83 [==============================] - 2s 21ms/step - loss: 7.1562 - root_mean_squared_error: 2.6751 - val_loss: 6.1421 - val_root_mean_squared_error: 2.4783\n",
      "Epoch 6/10\n",
      "83/83 [==============================] - 2s 23ms/step - loss: 6.9608 - root_mean_squared_error: 2.6383 - val_loss: 6.2002 - val_root_mean_squared_error: 2.4900\n",
      "Epoch 7/10\n",
      "83/83 [==============================] - 2s 21ms/step - loss: 6.8251 - root_mean_squared_error: 2.6125 - val_loss: 6.3531 - val_root_mean_squared_error: 2.5205\n",
      "Epoch 8/10\n",
      "83/83 [==============================] - 2s 22ms/step - loss: 6.8387 - root_mean_squared_error: 2.6151 - val_loss: 6.0094 - val_root_mean_squared_error: 2.4514\n",
      "Epoch 9/10\n",
      "83/83 [==============================] - 2s 21ms/step - loss: 6.8974 - root_mean_squared_error: 2.6263 - val_loss: 5.9574 - val_root_mean_squared_error: 2.4408\n",
      "Epoch 10/10\n",
      "83/83 [==============================] - 2s 18ms/step - loss: 6.6853 - root_mean_squared_error: 2.5856 - val_loss: 5.7779 - val_root_mean_squared_error: 2.4037\n",
      "322/322 [==============================] - 2s 6ms/step - loss: 6.3409 - root_mean_squared_error: 2.5181\n",
      "\n",
      "training time 22.151731\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 6.3409342765808105 with RMSE metric of 2.5181212425231934\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 6.2080 - root_mean_squared_error: 2.4916\n",
      "Test set has a loss (MSE) of 6.207970142364502 with RMSE metric of 2.49157977104187\n",
      "\n",
      "\n",
      "Running GRU model...\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 4s 38ms/step - loss: 56.0716 - root_mean_squared_error: 7.4881 - val_loss: 4.3739 - val_root_mean_squared_error: 2.0914\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 6.0654 - root_mean_squared_error: 2.4628 - val_loss: 4.0867 - val_root_mean_squared_error: 2.0216\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 3.9660 - root_mean_squared_error: 1.9915 - val_loss: 3.4926 - val_root_mean_squared_error: 1.8689\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 3.6545 - root_mean_squared_error: 1.9117 - val_loss: 3.3605 - val_root_mean_squared_error: 1.8332\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 3.4712 - root_mean_squared_error: 1.8631 - val_loss: 3.2067 - val_root_mean_squared_error: 1.7907\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 3.2746 - root_mean_squared_error: 1.8096 - val_loss: 3.0322 - val_root_mean_squared_error: 1.7413\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 3.0919 - root_mean_squared_error: 1.7584 - val_loss: 2.9003 - val_root_mean_squared_error: 1.7030\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.8879 - root_mean_squared_error: 1.6994 - val_loss: 2.6440 - val_root_mean_squared_error: 1.6260\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.7486 - root_mean_squared_error: 1.6579 - val_loss: 2.6726 - val_root_mean_squared_error: 1.6348\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.6458 - root_mean_squared_error: 1.6266 - val_loss: 2.5497 - val_root_mean_squared_error: 1.5968\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 2.5830 - root_mean_squared_error: 1.6072\n",
      "\n",
      "training time 8.648026\n",
      "GRU Model: \n",
      "Training set has a loss (MSE) of 2.583026170730591 with RMSE metric of 1.6071795225143433\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 2.3859 - root_mean_squared_error: 1.5446\n",
      "Test set has a loss (MSE) of 2.3859291076660156 with RMSE metric of 1.5446453094482422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (5):\n",
    "    ## GRU w Features Model\n",
    "    ## Initialize\n",
    "    model_name = 'GRU - w Features personalised'\n",
    "    num_layers = 4\n",
    "    epochs_num = 10\n",
    "    batch_size_set = 100\n",
    "    optimizer_set = 'adam'\n",
    "    forecast_distance=6\n",
    "    number_readings=8\n",
    "\n",
    "    ## Get New Data\n",
    "    a=DataSampling(path=path)\n",
    "    a.samplingDF\n",
    "    X_train,X_test,y_train,y_test = a.SampleValidSequencesMulti(num_clients=1, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "    #SETUP THE STACK\n",
    "    model_gru = Sequential()\n",
    "    model_gru.add(GRU(70, activation='relu', input_shape=(number_readings,2), return_sequences=True))\n",
    "    model_gru.add(GRU(20, activation='relu'))\n",
    "    model_gru.add(Dense(10))\n",
    "    model_gru.add(Dense(1))\n",
    "\n",
    "\n",
    "    #START THE RUN\n",
    "    print('\\nRunning GRU model...')\n",
    "    start = datetime.now()\n",
    "\n",
    "    model_gru.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    hist = model_gru.fit(X_train, y_train, epochs=epochs_num, validation_split=0.2, batch_size=batch_size_set)\n",
    "    train_loss, train_rmse = model_gru.evaluate(X_train, y_train)\n",
    "    train_time = (datetime.now()-start).total_seconds()\n",
    "    print(\"\\ntraining time %s\" % train_time)\n",
    "\n",
    "    #PRINT RESULTS\n",
    "    print(f'GRU Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "    #Test set results\n",
    "    test_loss, test_rmse = model_gru.evaluate(X_test, y_test)\n",
    "    print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "\n",
    "    #y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "    Execution_time.append(train_time)\n",
    "    train_rmse_results.append(train_rmse)\n",
    "    test_rmse_results.append(test_rmse)\n",
    "    run_id.append(model_name+str(datetime.now()))\n",
    "    sample_size.append(len(X_train))\n",
    "    epochs.append(epochs_num)\n",
    "    batch_size.append(batch_size_set)\n",
    "    optimizer.append(optimizer_set)\n",
    "    layers.append(num_layers)\n",
    "    forecast_distance_perf.append(forecast_distance)\n",
    "    prev_readings.append(number_readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running RNN model...\n",
      "Epoch 1/12\n",
      "51/51 [==============================] - 2s 29ms/step - loss: 11.9767 - root_mean_squared_error: 3.4607 - val_loss: 2.6192 - val_root_mean_squared_error: 1.6184\n",
      "Epoch 2/12\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 2.6195 - root_mean_squared_error: 1.6185 - val_loss: 2.3643 - val_root_mean_squared_error: 1.5376\n",
      "Epoch 3/12\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 2.5583 - root_mean_squared_error: 1.5995 - val_loss: 2.2625 - val_root_mean_squared_error: 1.5041\n",
      "Epoch 4/12\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 2.4852 - root_mean_squared_error: 1.5765 - val_loss: 2.1706 - val_root_mean_squared_error: 1.4733\n",
      "Epoch 5/12\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 2.4896 - root_mean_squared_error: 1.5778 - val_loss: 2.1177 - val_root_mean_squared_error: 1.4552\n",
      "Epoch 6/12\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 2.6020 - root_mean_squared_error: 1.6131 - val_loss: 2.1697 - val_root_mean_squared_error: 1.4730\n",
      "Epoch 7/12\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 2.4167 - root_mean_squared_error: 1.5546 - val_loss: 2.0286 - val_root_mean_squared_error: 1.4243\n",
      "Epoch 8/12\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 2.4173 - root_mean_squared_error: 1.5548 - val_loss: 2.0182 - val_root_mean_squared_error: 1.4206\n",
      "Epoch 9/12\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 2.3622 - root_mean_squared_error: 1.5369 - val_loss: 2.0873 - val_root_mean_squared_error: 1.4447\n",
      "Epoch 10/12\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 2.4672 - root_mean_squared_error: 1.5707 - val_loss: 2.4079 - val_root_mean_squared_error: 1.5517\n",
      "Epoch 11/12\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 2.4722 - root_mean_squared_error: 1.5723 - val_loss: 2.2810 - val_root_mean_squared_error: 1.5103\n",
      "Epoch 12/12\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 2.3811 - root_mean_squared_error: 1.5431 - val_loss: 2.0149 - val_root_mean_squared_error: 1.4195\n",
      "396/396 [==============================] - 2s 5ms/step - loss: 2.2576 - root_mean_squared_error: 1.5025\n",
      "\n",
      "training time 18.184852\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 2.2575888633728027 with RMSE metric of 1.5025274753570557\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 2.6487 - root_mean_squared_error: 1.6275\n",
      "Test set has a loss (MSE) of 2.6487021446228027 with RMSE metric of 1.6274833679199219\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/12\n",
      "49/49 [==============================] - 3s 32ms/step - loss: 54.9203 - root_mean_squared_error: 7.4108 - val_loss: 5.1479 - val_root_mean_squared_error: 2.2689\n",
      "Epoch 2/12\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 4.6835 - root_mean_squared_error: 2.1641 - val_loss: 4.6598 - val_root_mean_squared_error: 2.1587\n",
      "Epoch 3/12\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 4.6162 - root_mean_squared_error: 2.1485 - val_loss: 4.5967 - val_root_mean_squared_error: 2.1440\n",
      "Epoch 4/12\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 4.5143 - root_mean_squared_error: 2.1247 - val_loss: 4.5290 - val_root_mean_squared_error: 2.1281\n",
      "Epoch 5/12\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 4.4838 - root_mean_squared_error: 2.1175 - val_loss: 4.4646 - val_root_mean_squared_error: 2.1130\n",
      "Epoch 6/12\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 4.4385 - root_mean_squared_error: 2.1068 - val_loss: 4.4037 - val_root_mean_squared_error: 2.0985\n",
      "Epoch 7/12\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 4.4844 - root_mean_squared_error: 2.1176 - val_loss: 4.3994 - val_root_mean_squared_error: 2.0975\n",
      "Epoch 8/12\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 4.3954 - root_mean_squared_error: 2.0965 - val_loss: 4.3146 - val_root_mean_squared_error: 2.0772\n",
      "Epoch 9/12\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 4.3769 - root_mean_squared_error: 2.0921 - val_loss: 4.3377 - val_root_mean_squared_error: 2.0827\n",
      "Epoch 10/12\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 4.4882 - root_mean_squared_error: 2.1185 - val_loss: 4.3069 - val_root_mean_squared_error: 2.0753\n",
      "Epoch 11/12\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 4.3470 - root_mean_squared_error: 2.0849 - val_loss: 4.4702 - val_root_mean_squared_error: 2.1143\n",
      "Epoch 12/12\n",
      "49/49 [==============================] - 1s 28ms/step - loss: 4.3870 - root_mean_squared_error: 2.0945 - val_loss: 4.2960 - val_root_mean_squared_error: 2.0727\n",
      "377/377 [==============================] - 2s 4ms/step - loss: 4.3005 - root_mean_squared_error: 2.0738\n",
      "\n",
      "training time 19.540176\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 4.300486087799072 with RMSE metric of 2.073761224746704\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 4.5162 - root_mean_squared_error: 2.1251\n",
      "Test set has a loss (MSE) of 4.516232967376709 with RMSE metric of 2.125143051147461\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/12\n",
      "60/60 [==============================] - 3s 28ms/step - loss: 30.9560 - root_mean_squared_error: 5.5638 - val_loss: 3.4259 - val_root_mean_squared_error: 1.8509\n",
      "Epoch 2/12\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 2.8751 - root_mean_squared_error: 1.6956 - val_loss: 3.0850 - val_root_mean_squared_error: 1.7564\n",
      "Epoch 3/12\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 2.7292 - root_mean_squared_error: 1.6520 - val_loss: 2.8572 - val_root_mean_squared_error: 1.6903\n",
      "Epoch 4/12\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 2.4417 - root_mean_squared_error: 1.5626 - val_loss: 2.5407 - val_root_mean_squared_error: 1.5940\n",
      "Epoch 5/12\n",
      "60/60 [==============================] - 2s 31ms/step - loss: 2.3750 - root_mean_squared_error: 1.5411 - val_loss: 2.5037 - val_root_mean_squared_error: 1.5823\n",
      "Epoch 6/12\n",
      "60/60 [==============================] - 2s 29ms/step - loss: 2.2505 - root_mean_squared_error: 1.5002 - val_loss: 2.4178 - val_root_mean_squared_error: 1.5549\n",
      "Epoch 7/12\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 2.3537 - root_mean_squared_error: 1.5342 - val_loss: 2.4904 - val_root_mean_squared_error: 1.5781\n",
      "Epoch 8/12\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 2.2580 - root_mean_squared_error: 1.5027 - val_loss: 2.3885 - val_root_mean_squared_error: 1.5455\n",
      "Epoch 9/12\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 2.1874 - root_mean_squared_error: 1.4790 - val_loss: 2.4508 - val_root_mean_squared_error: 1.5655\n",
      "Epoch 10/12\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 2.2236 - root_mean_squared_error: 1.4912 - val_loss: 2.7352 - val_root_mean_squared_error: 1.6538\n",
      "Epoch 11/12\n",
      "60/60 [==============================] - 2s 30ms/step - loss: 2.3434 - root_mean_squared_error: 1.5308 - val_loss: 2.7248 - val_root_mean_squared_error: 1.6507\n",
      "Epoch 12/12\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 2.2682 - root_mean_squared_error: 1.5061 - val_loss: 2.3881 - val_root_mean_squared_error: 1.5453\n",
      "467/467 [==============================] - 2s 4ms/step - loss: 2.1782 - root_mean_squared_error: 1.4759\n",
      "\n",
      "training time 23.172422\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 2.1782333850860596 with RMSE metric of 1.475883960723877\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 2.0611 - root_mean_squared_error: 1.4357\n",
      "Test set has a loss (MSE) of 2.0610926151275635 with RMSE metric of 1.4356505870819092\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/12\n",
      "9/9 [==============================] - 1s 51ms/step - loss: 486.1974 - root_mean_squared_error: 22.0499 - val_loss: 53.2832 - val_root_mean_squared_error: 7.2995\n",
      "Epoch 2/12\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 15.5238 - root_mean_squared_error: 3.9400 - val_loss: 8.2103 - val_root_mean_squared_error: 2.8654\n",
      "Epoch 3/12\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 4.5742 - root_mean_squared_error: 2.1387 - val_loss: 4.6283 - val_root_mean_squared_error: 2.1514\n",
      "Epoch 4/12\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 3.0043 - root_mean_squared_error: 1.7333 - val_loss: 4.0837 - val_root_mean_squared_error: 2.0208\n",
      "Epoch 5/12\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 2.7848 - root_mean_squared_error: 1.6688 - val_loss: 3.8718 - val_root_mean_squared_error: 1.9677\n",
      "Epoch 6/12\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 2.6770 - root_mean_squared_error: 1.6361 - val_loss: 3.7789 - val_root_mean_squared_error: 1.9439\n",
      "Epoch 7/12\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 2.6536 - root_mean_squared_error: 1.6290 - val_loss: 3.7462 - val_root_mean_squared_error: 1.9355\n",
      "Epoch 8/12\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 2.4878 - root_mean_squared_error: 1.5773 - val_loss: 3.3602 - val_root_mean_squared_error: 1.8331\n",
      "Epoch 9/12\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 2.4267 - root_mean_squared_error: 1.5578 - val_loss: 3.1495 - val_root_mean_squared_error: 1.7747\n",
      "Epoch 10/12\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 2.4325 - root_mean_squared_error: 1.5597 - val_loss: 2.9780 - val_root_mean_squared_error: 1.7257\n",
      "Epoch 11/12\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 2.2513 - root_mean_squared_error: 1.5004 - val_loss: 2.8978 - val_root_mean_squared_error: 1.7023\n",
      "Epoch 12/12\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 2.1875 - root_mean_squared_error: 1.4790 - val_loss: 2.8639 - val_root_mean_squared_error: 1.6923\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 2.3056 - root_mean_squared_error: 1.5184\n",
      "\n",
      "training time 4.763822\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 2.3055779933929443 with RMSE metric of 1.5184129476547241\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 2.5464 - root_mean_squared_error: 1.5958\n",
      "Test set has a loss (MSE) of 2.546444892883301 with RMSE metric of 1.5957584381103516\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/12\n",
      "13/13 [==============================] - 1s 38ms/step - loss: 51.4859 - root_mean_squared_error: 7.1754 - val_loss: 2.3147 - val_root_mean_squared_error: 1.5214\n",
      "Epoch 2/12\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 4.9954 - root_mean_squared_error: 2.2350 - val_loss: 1.9955 - val_root_mean_squared_error: 1.4126\n",
      "Epoch 3/12\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 3.3134 - root_mean_squared_error: 1.8203 - val_loss: 2.5410 - val_root_mean_squared_error: 1.5941\n",
      "Epoch 4/12\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 3.1159 - root_mean_squared_error: 1.7652 - val_loss: 2.0159 - val_root_mean_squared_error: 1.4198\n",
      "Epoch 5/12\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 3.0512 - root_mean_squared_error: 1.7468 - val_loss: 2.4978 - val_root_mean_squared_error: 1.5804\n",
      "Epoch 6/12\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.8762 - root_mean_squared_error: 1.6959 - val_loss: 2.2238 - val_root_mean_squared_error: 1.4912\n",
      "Epoch 7/12\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 2.8173 - root_mean_squared_error: 1.6785 - val_loss: 1.8032 - val_root_mean_squared_error: 1.3428\n",
      "Epoch 8/12\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.6920 - root_mean_squared_error: 1.6407 - val_loss: 1.7177 - val_root_mean_squared_error: 1.3106\n",
      "Epoch 9/12\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.6868 - root_mean_squared_error: 1.6392 - val_loss: 2.9730 - val_root_mean_squared_error: 1.7242\n",
      "Epoch 10/12\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.7632 - root_mean_squared_error: 1.6623 - val_loss: 1.7257 - val_root_mean_squared_error: 1.3136\n",
      "Epoch 11/12\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 2.5078 - root_mean_squared_error: 1.5836 - val_loss: 2.1083 - val_root_mean_squared_error: 1.4520\n",
      "Epoch 12/12\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.7475 - root_mean_squared_error: 1.6576 - val_loss: 1.5933 - val_root_mean_squared_error: 1.2623\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 2.3896 - root_mean_squared_error: 1.5458\n",
      "\n",
      "training time 5.413683\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 2.389557361602783 with RMSE metric of 1.5458192825317383\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.3723 - root_mean_squared_error: 1.5402\n",
      "Test set has a loss (MSE) of 2.3722903728485107 with RMSE metric of 1.5402240753173828\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/12\n",
      "13/13 [==============================] - 2s 38ms/step - loss: 335.8985 - root_mean_squared_error: 18.3275 - val_loss: 39.6954 - val_root_mean_squared_error: 6.3004\n",
      "Epoch 2/12\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 9.6560 - root_mean_squared_error: 3.1074 - val_loss: 10.9794 - val_root_mean_squared_error: 3.3135\n",
      "Epoch 3/12\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 4.6251 - root_mean_squared_error: 2.1506 - val_loss: 4.7493 - val_root_mean_squared_error: 2.1793\n",
      "Epoch 4/12\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 3.4071 - root_mean_squared_error: 1.8458 - val_loss: 4.8944 - val_root_mean_squared_error: 2.2123\n",
      "Epoch 5/12\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 3.3358 - root_mean_squared_error: 1.8264 - val_loss: 4.4927 - val_root_mean_squared_error: 2.1196\n",
      "Epoch 6/12\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 3.5237 - root_mean_squared_error: 1.8772 - val_loss: 4.5105 - val_root_mean_squared_error: 2.1238\n",
      "Epoch 7/12\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 3.4617 - root_mean_squared_error: 1.8606 - val_loss: 4.4539 - val_root_mean_squared_error: 2.1104\n",
      "Epoch 8/12\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 3.3195 - root_mean_squared_error: 1.8219 - val_loss: 4.6045 - val_root_mean_squared_error: 2.1458\n",
      "Epoch 9/12\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 3.2567 - root_mean_squared_error: 1.8046 - val_loss: 4.3328 - val_root_mean_squared_error: 2.0815\n",
      "Epoch 10/12\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 3.3250 - root_mean_squared_error: 1.8235 - val_loss: 4.6670 - val_root_mean_squared_error: 2.1603\n",
      "Epoch 11/12\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 3.2574 - root_mean_squared_error: 1.8048 - val_loss: 4.6420 - val_root_mean_squared_error: 2.1545\n",
      "Epoch 12/12\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 3.2256 - root_mean_squared_error: 1.7960 - val_loss: 4.8458 - val_root_mean_squared_error: 2.2013\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.6000 - root_mean_squared_error: 1.8974\n",
      "\n",
      "training time 6.257149\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 3.600039482116699 with RMSE metric of 1.8973770141601562\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 5.7227 - root_mean_squared_error: 2.3922\n",
      "Test set has a loss (MSE) of 5.72269344329834 with RMSE metric of 2.3922152519226074\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/12\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 252.2145 - root_mean_squared_error: 15.8813 - val_loss: 7.8102 - val_root_mean_squared_error: 2.7947\n",
      "Epoch 2/12\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 6.8753 - root_mean_squared_error: 2.6221 - val_loss: 6.1537 - val_root_mean_squared_error: 2.4807\n",
      "Epoch 3/12\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 5.4976 - root_mean_squared_error: 2.3447 - val_loss: 5.5647 - val_root_mean_squared_error: 2.3590\n",
      "Epoch 4/12\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 4.9842 - root_mean_squared_error: 2.2325 - val_loss: 5.0909 - val_root_mean_squared_error: 2.2563\n",
      "Epoch 5/12\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 4.7526 - root_mean_squared_error: 2.1800 - val_loss: 5.1133 - val_root_mean_squared_error: 2.2613\n",
      "Epoch 6/12\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 4.4688 - root_mean_squared_error: 2.1140 - val_loss: 4.5641 - val_root_mean_squared_error: 2.1364\n",
      "Epoch 7/12\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 4.0150 - root_mean_squared_error: 2.0037 - val_loss: 4.8126 - val_root_mean_squared_error: 2.1938\n",
      "Epoch 8/12\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 4.3467 - root_mean_squared_error: 2.0849 - val_loss: 5.0104 - val_root_mean_squared_error: 2.2384\n",
      "Epoch 9/12\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 3.8733 - root_mean_squared_error: 1.9681 - val_loss: 4.7345 - val_root_mean_squared_error: 2.1759\n",
      "Epoch 10/12\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 3.5533 - root_mean_squared_error: 1.8850 - val_loss: 4.4865 - val_root_mean_squared_error: 2.1181\n",
      "Epoch 11/12\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 3.4424 - root_mean_squared_error: 1.8554 - val_loss: 4.5638 - val_root_mean_squared_error: 2.1363\n",
      "Epoch 12/12\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 3.4134 - root_mean_squared_error: 1.8475 - val_loss: 4.6395 - val_root_mean_squared_error: 2.1539\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 3.6616 - root_mean_squared_error: 1.9135\n",
      "\n",
      "training time 6.195013\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 3.661642074584961 with RMSE metric of 1.9135417938232422\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.0825 - root_mean_squared_error: 2.0205\n",
      "Test set has a loss (MSE) of 4.082521915435791 with RMSE metric of 2.0205252170562744\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/12\n",
      "21/21 [==============================] - 2s 34ms/step - loss: 538.8373 - root_mean_squared_error: 23.2129 - val_loss: 13.2332 - val_root_mean_squared_error: 3.6377\n",
      "Epoch 2/12\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 13.4739 - root_mean_squared_error: 3.6707 - val_loss: 8.0758 - val_root_mean_squared_error: 2.8418\n",
      "Epoch 3/12\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 11.7794 - root_mean_squared_error: 3.4321 - val_loss: 7.8159 - val_root_mean_squared_error: 2.7957\n",
      "Epoch 4/12\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 11.4884 - root_mean_squared_error: 3.3895 - val_loss: 7.6813 - val_root_mean_squared_error: 2.7715\n",
      "Epoch 5/12\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 11.3382 - root_mean_squared_error: 3.3672 - val_loss: 7.5028 - val_root_mean_squared_error: 2.7391\n",
      "Epoch 6/12\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 11.1892 - root_mean_squared_error: 3.3450 - val_loss: 7.4595 - val_root_mean_squared_error: 2.7312\n",
      "Epoch 7/12\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 11.0071 - root_mean_squared_error: 3.3177 - val_loss: 7.4568 - val_root_mean_squared_error: 2.7307\n",
      "Epoch 8/12\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 11.1729 - root_mean_squared_error: 3.3426 - val_loss: 7.5002 - val_root_mean_squared_error: 2.7386\n",
      "Epoch 9/12\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 10.8612 - root_mean_squared_error: 3.2956 - val_loss: 7.2160 - val_root_mean_squared_error: 2.6863\n",
      "Epoch 10/12\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 10.7772 - root_mean_squared_error: 3.2829 - val_loss: 7.0228 - val_root_mean_squared_error: 2.6501\n",
      "Epoch 11/12\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 10.6715 - root_mean_squared_error: 3.2667 - val_loss: 6.8493 - val_root_mean_squared_error: 2.6171\n",
      "Epoch 12/12\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 10.5064 - root_mean_squared_error: 3.2414 - val_loss: 6.6853 - val_root_mean_squared_error: 2.5856\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 9.6010 - root_mean_squared_error: 3.0986\n",
      "\n",
      "training time 7.525861\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 9.60104751586914 with RMSE metric of 3.09855580329895\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 7.9070 - root_mean_squared_error: 2.8119\n",
      "Test set has a loss (MSE) of 7.907026290893555 with RMSE metric of 2.811943531036377\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/12\n",
      "6/6 [==============================] - 1s 64ms/step - loss: 135.8054 - root_mean_squared_error: 11.6536 - val_loss: 101.4457 - val_root_mean_squared_error: 10.0720\n",
      "Epoch 2/12\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 19.0909 - root_mean_squared_error: 4.3693 - val_loss: 17.5999 - val_root_mean_squared_error: 4.1952\n",
      "Epoch 3/12\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.8373 - root_mean_squared_error: 2.9728 - val_loss: 4.9416 - val_root_mean_squared_error: 2.2230\n",
      "Epoch 4/12\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.5090 - root_mean_squared_error: 2.1235 - val_loss: 7.5091 - val_root_mean_squared_error: 2.7403\n",
      "Epoch 5/12\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 3.5450 - root_mean_squared_error: 1.8828 - val_loss: 2.4841 - val_root_mean_squared_error: 1.5761\n",
      "Epoch 6/12\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.6585 - root_mean_squared_error: 1.6305 - val_loss: 3.3752 - val_root_mean_squared_error: 1.8372\n",
      "Epoch 7/12\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 2.4416 - root_mean_squared_error: 1.5626 - val_loss: 1.4037 - val_root_mean_squared_error: 1.1848\n",
      "Epoch 8/12\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 2.3220 - root_mean_squared_error: 1.5238 - val_loss: 2.0899 - val_root_mean_squared_error: 1.4456\n",
      "Epoch 9/12\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.1809 - root_mean_squared_error: 1.4768 - val_loss: 1.3351 - val_root_mean_squared_error: 1.1555\n",
      "Epoch 10/12\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.0204 - root_mean_squared_error: 1.4214 - val_loss: 1.6514 - val_root_mean_squared_error: 1.2851\n",
      "Epoch 11/12\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.9712 - root_mean_squared_error: 1.4040 - val_loss: 1.3215 - val_root_mean_squared_error: 1.1496\n",
      "Epoch 12/12\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.9187 - root_mean_squared_error: 1.3852 - val_loss: 1.4346 - val_root_mean_squared_error: 1.1978\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.8053 - root_mean_squared_error: 1.3436\n",
      "\n",
      "training time 3.230127\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 1.8053158521652222 with RMSE metric of 1.3436204195022583\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.9548 - root_mean_squared_error: 2.2259\n",
      "Test set has a loss (MSE) of 4.954784393310547 with RMSE metric of 2.2259345054626465\n",
      "\n",
      "\n",
      "Running RNN model...\n",
      "Epoch 1/12\n",
      "73/73 [==============================] - 3s 26ms/step - loss: 36.9133 - root_mean_squared_error: 6.0756 - val_loss: 5.3024 - val_root_mean_squared_error: 2.3027\n",
      "Epoch 2/12\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 4.0510 - root_mean_squared_error: 2.0127 - val_loss: 4.6840 - val_root_mean_squared_error: 2.1643\n",
      "Epoch 3/12\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 3.4709 - root_mean_squared_error: 1.8630 - val_loss: 4.0536 - val_root_mean_squared_error: 2.0134\n",
      "Epoch 4/12\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 3.4369 - root_mean_squared_error: 1.8539 - val_loss: 4.2160 - val_root_mean_squared_error: 2.0533\n",
      "Epoch 5/12\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 3.4225 - root_mean_squared_error: 1.8500 - val_loss: 4.0966 - val_root_mean_squared_error: 2.0240\n",
      "Epoch 6/12\n",
      "73/73 [==============================] - 2s 27ms/step - loss: 3.2973 - root_mean_squared_error: 1.8158 - val_loss: 3.9488 - val_root_mean_squared_error: 1.9872\n",
      "Epoch 7/12\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 3.2276 - root_mean_squared_error: 1.7966 - val_loss: 4.1205 - val_root_mean_squared_error: 2.0299\n",
      "Epoch 8/12\n",
      "73/73 [==============================] - 2s 27ms/step - loss: 3.2361 - root_mean_squared_error: 1.7989 - val_loss: 3.9323 - val_root_mean_squared_error: 1.9830\n",
      "Epoch 9/12\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 3.2935 - root_mean_squared_error: 1.8148 - val_loss: 3.9664 - val_root_mean_squared_error: 1.9916\n",
      "Epoch 10/12\n",
      "73/73 [==============================] - 2s 28ms/step - loss: 3.2307 - root_mean_squared_error: 1.7974 - val_loss: 4.0039 - val_root_mean_squared_error: 2.0010\n",
      "Epoch 11/12\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 3.2346 - root_mean_squared_error: 1.7985 - val_loss: 3.9209 - val_root_mean_squared_error: 1.9801\n",
      "Epoch 12/12\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 3.2093 - root_mean_squared_error: 1.7915 - val_loss: 3.9204 - val_root_mean_squared_error: 1.9800\n",
      "566/566 [==============================] - 3s 5ms/step - loss: 3.2854 - root_mean_squared_error: 1.8126\n",
      "\n",
      "training time 26.390184\n",
      "RNN Model: \n",
      "Training set has a loss (MSE) of 3.2854230403900146 with RMSE metric of 1.8125735521316528\n",
      "269/269 [==============================] - 1s 5ms/step - loss: 3.1231 - root_mean_squared_error: 1.7672\n",
      "Test set has a loss (MSE) of 3.1231348514556885 with RMSE metric of 1.7672393321990967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    ## Simple RNN Model w Features\n",
    "    ## Initialize\n",
    "    model_name = 'SimpleRNN w Features Personalised'\n",
    "    num_layers = 5\n",
    "    epochs_num = 12\n",
    "    batch_size_set = 200\n",
    "    optimizer_set = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    forecast_distance=6\n",
    "    number_readings=8\n",
    "\n",
    "    ## Get New Data\n",
    "    a=DataSampling(path=path)\n",
    "    a.samplingDF\n",
    "    X_train,X_test,y_train,y_test = a.SampleValidSequencesMulti(num_clients=1, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "    #a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "\n",
    "    #SETUP THE STACK\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(SimpleRNN(150, activation='relu', input_shape=(number_readings,2)))\n",
    "    model_rnn.add(Dense(60))\n",
    "    model_rnn.add(Dense(20))\n",
    "    model_rnn.add(Dense(10))\n",
    "    model_rnn.add(Dense(1))\n",
    "    #START THE RUN\n",
    "    print('\\nRunning RNN model...')\n",
    "    start = datetime.now()\n",
    "\n",
    "    model_rnn.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    hist = model_rnn.fit(X_train, y_train, epochs=epochs_num, validation_split=0.2, batch_size=batch_size_set)\n",
    "    train_loss, train_rmse = model_rnn.evaluate(X_train, y_train)\n",
    "    train_time = (datetime.now()-start).total_seconds()\n",
    "    print(\"\\ntraining time %s\" % train_time)\n",
    "\n",
    "    #PRINT RESULTS\n",
    "    print(f'RNN Model: \\nTraining set has a loss (MSE) of {train_loss} with RMSE metric of {train_rmse}')\n",
    "    #Test set results\n",
    "    test_loss, test_rmse = model_rnn.evaluate(X_test, y_test)\n",
    "    print(f'Test set has a loss (MSE) of {test_loss} with RMSE metric of {test_rmse}\\n')\n",
    "\n",
    "    #y_pred = model_rnn.predict(X_test)\n",
    "\n",
    "    Execution_time.append(train_time)\n",
    "    train_rmse_results.append(train_rmse)\n",
    "    test_rmse_results.append(test_rmse)\n",
    "    run_id.append(model_name+str(datetime.now()))\n",
    "    sample_size.append(len(X_train))\n",
    "    epochs.append(epochs_num)\n",
    "    batch_size.append(batch_size_set)\n",
    "    optimizer.append(optimizer_set)\n",
    "    layers.append(num_layers)\n",
    "    forecast_distance_perf.append(forecast_distance)\n",
    "    prev_readings.append(number_readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(list(zip(Execution_time,train_rmse_results,test_rmse_results,run_id,sample_size,epochs,batch_size,optimizer,layers,forecast_distance_perf,\n",
    "prev_readings))\n",
    "    ,columns=['Execution_time','train_rmse_results','test_rmse_results','run_id','sample_size','epochs','batch_size','optimizer','layers','forecast_distance_perf',\n",
    "'prev_readings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Execution_time</th>\n",
       "      <th>train_rmse_results</th>\n",
       "      <th>test_rmse_results</th>\n",
       "      <th>run_id</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>layers</th>\n",
       "      <th>forecast_distance_perf</th>\n",
       "      <th>prev_readings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.459268</td>\n",
       "      <td>1.775936</td>\n",
       "      <td>1.869360</td>\n",
       "      <td>GRU - w Features2022-08-12 07:55:31.274619</td>\n",
       "      <td>16059</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>adam</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.449500</td>\n",
       "      <td>1.874869</td>\n",
       "      <td>1.934751</td>\n",
       "      <td>SimpleRNN w Features2022-08-12 07:57:07.442585</td>\n",
       "      <td>28530</td>\n",
       "      <td>15</td>\n",
       "      <td>120</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.160103</td>\n",
       "      <td>2.073965</td>\n",
       "      <td>2.158123</td>\n",
       "      <td>GRU - w Features2022-08-12 07:58:29.655361</td>\n",
       "      <td>19476</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.594147</td>\n",
       "      <td>1.820412</td>\n",
       "      <td>1.861851</td>\n",
       "      <td>GRU - w Features2022-08-12 07:59:03.117479</td>\n",
       "      <td>13910</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.955700</td>\n",
       "      <td>1.738953</td>\n",
       "      <td>1.881305</td>\n",
       "      <td>GRU - w Features2022-08-12 07:59:51.171444</td>\n",
       "      <td>20601</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>16.542284</td>\n",
       "      <td>1.975558</td>\n",
       "      <td>2.148362</td>\n",
       "      <td>SimpleRNN - Personal2022-08-12 16:00:47.745372</td>\n",
       "      <td>13587</td>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>13.030077</td>\n",
       "      <td>2.231526</td>\n",
       "      <td>2.028022</td>\n",
       "      <td>SimpleRNN - Personal2022-08-12 16:01:08.444732</td>\n",
       "      <td>11107</td>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3.798726</td>\n",
       "      <td>1.507133</td>\n",
       "      <td>1.290481</td>\n",
       "      <td>SimpleRNN - Personal2022-08-12 16:01:20.355310</td>\n",
       "      <td>1864</td>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>14.289721</td>\n",
       "      <td>1.389069</td>\n",
       "      <td>1.451305</td>\n",
       "      <td>SimpleRNN - Personal2022-08-12 16:03:43.372867</td>\n",
       "      <td>9032</td>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>7.029363</td>\n",
       "      <td>1.690271</td>\n",
       "      <td>1.552484</td>\n",
       "      <td>SimpleRNN - Personal2022-08-12 16:03:57.820259</td>\n",
       "      <td>3977</td>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>&lt;keras.optimizer_v2.adam.Adam object at 0x0000...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Execution_time  train_rmse_results  test_rmse_results  \\\n",
       "0        37.459268            1.775936           1.869360   \n",
       "1        41.449500            1.874869           1.934751   \n",
       "2        32.160103            2.073965           2.158123   \n",
       "3        24.594147            1.820412           1.861851   \n",
       "4        37.955700            1.738953           1.881305   \n",
       "..             ...                 ...                ...   \n",
       "60       16.542284            1.975558           2.148362   \n",
       "61       13.030077            2.231526           2.028022   \n",
       "62        3.798726            1.507133           1.290481   \n",
       "63       14.289721            1.389069           1.451305   \n",
       "64        7.029363            1.690271           1.552484   \n",
       "\n",
       "                                            run_id  sample_size  epochs  \\\n",
       "0       GRU - w Features2022-08-12 07:55:31.274619        16059      10   \n",
       "1   SimpleRNN w Features2022-08-12 07:57:07.442585        28530      15   \n",
       "2       GRU - w Features2022-08-12 07:58:29.655361        19476      10   \n",
       "3       GRU - w Features2022-08-12 07:59:03.117479        13910      10   \n",
       "4       GRU - w Features2022-08-12 07:59:51.171444        20601      10   \n",
       "..                                             ...          ...     ...   \n",
       "60  SimpleRNN - Personal2022-08-12 16:00:47.745372        13587      12   \n",
       "61  SimpleRNN - Personal2022-08-12 16:01:08.444732        11107      12   \n",
       "62  SimpleRNN - Personal2022-08-12 16:01:20.355310         1864      12   \n",
       "63  SimpleRNN - Personal2022-08-12 16:03:43.372867         9032      12   \n",
       "64  SimpleRNN - Personal2022-08-12 16:03:57.820259         3977      12   \n",
       "\n",
       "    batch_size                                          optimizer  layers  \\\n",
       "0           50                                               adam       4   \n",
       "1          120  <keras.optimizer_v2.adam.Adam object at 0x0000...       3   \n",
       "2          100                                               adam       4   \n",
       "3          100                                               adam       4   \n",
       "4          100                                               adam       4   \n",
       "..         ...                                                ...     ...   \n",
       "60         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       5   \n",
       "61         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       5   \n",
       "62         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       5   \n",
       "63         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       5   \n",
       "64         200  <keras.optimizer_v2.adam.Adam object at 0x0000...       5   \n",
       "\n",
       "    forecast_distance_perf  prev_readings  \n",
       "0                        6              8  \n",
       "1                        6              8  \n",
       "2                        6              8  \n",
       "3                        6              8  \n",
       "4                        6              8  \n",
       "..                     ...            ...  \n",
       "60                       6              8  \n",
       "61                       6              8  \n",
       "62                       6              8  \n",
       "63                       6              8  \n",
       "64                       6              8  \n",
       "\n",
       "[65 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(neurons=150, activation='relu',dropout_rate=0.1):\n",
    "    ## Simple RNN Model\n",
    "    ## Initialize\n",
    "    model_name = 'SimpleRNN - Personal'\n",
    "    optimizer_set = tf.keras.optimizers.Adam(learning_rate=0.01) #momentum - 0.9?\n",
    "    forecast_distance=6\n",
    "    number_readings=8\n",
    "\n",
    "    ## Get New Data\n",
    "    a=DataSampling(path=path)\n",
    "    a.samplingDF\n",
    "\n",
    "\n",
    "    #SETUP THE STACK\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(SimpleRNN(neurons, activation=activation, input_shape=(number_readings,1)))\n",
    "    model_rnn.add(Dropout(dropout_rate))\n",
    "    model_rnn.add(Dense(10))\n",
    "    model_rnn.add(Dense(1))\n",
    "\n",
    "    \n",
    "    model_rnn.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model_rnn\n",
    "\n",
    "a=DataSampling(path=path)\n",
    "a.samplingDF\n",
    "X_train,X_test,y_train,y_test = a.SampleValidSequences(num_clients=2, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "kModel=KerasRegressor(model=buildModel, verbose=0) ##epochs 30 for final\n",
    "\n",
    "#epochs=10,batch_size=200,\n",
    "\n",
    "epochs=[15,30,45] #30\n",
    "batch_size=[100,150,200] #200\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3] #0.01\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9] ##NA\n",
    "activation_set=['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'] #tanh,relu.softsign\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] #0.1 or 0.2\n",
    "neurons = [50, 100, 150, 200, 250] #150 or 200\n",
    "## Activation function / Number Neurons / Optimizer\n",
    "\n",
    "param_grid = dict(epochs=epochs,batch_size=batch_size)\n",
    "#param_grid = dict(epochs=epochs,batch_size=batch_size)\n",
    "#param_grid = dict(model__activation=activation_set)\n",
    "#param_grid = dict(model__dropout_rate=dropout_rate)\n",
    "#param_grid = dict(model__neurons=neurons)\n",
    "grid = GridSearchCV(estimator=kModel, param_grid=param_grid, n_jobs=-1, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_result = grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(neurons=150, activation='relu',dropout_rate=0.1):\n",
    "    ## Simple RNN Model\n",
    "    ## Initialize\n",
    "    model_name = 'GRU'\n",
    "    optimizer_set = tf.keras.optimizers.Adam(learning_rate=0.01) #momentum - 0.9?\n",
    "    forecast_distance=6\n",
    "    number_readings=8\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #SETUP THE STACK\n",
    "    model_gru = Sequential()\n",
    "    model_gru.add(GRU(neurons, activation=activation, input_shape=(number_readings,1), return_sequences=True))\n",
    "    model_gru.add(GRU(20, activation=activation))\n",
    "    model_gru.add(Dense(10))\n",
    "    model_gru.add(Dense(1))\n",
    "\n",
    "    \n",
    "    model_gru.compile(optimizer=optimizer_set, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model_gru\n",
    "\n",
    "a=DataSampling(path=path)\n",
    "a.samplingDF\n",
    "X_train,X_test,y_train,y_test = a.SampleValidSequences(num_clients=2, test_split=0.3,reading_length=number_readings, forecast_dist=forecast_distance)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3)\n",
    "#a.SampleValidSequences(num_clients=5, test_split=0.3,forecast_dist=forecast_distance,reading_length=number_readings)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "kModel=KerasRegressor(model=buildModel, verbose=0) ##epochs 30 for final\n",
    "\n",
    "#epochs=10,batch_size=200,\n",
    "\n",
    "epochs=[15,30,45] #30\n",
    "batch_size=[100,150,200] #200\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3] #0.01\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9] ##NA\n",
    "activation_set=['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'] #tanh,relu.softsign\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] #0.1 or 0.2\n",
    "neurons = [50, 100, 150, 200, 250] #150 or 200\n",
    "## Activation function / Number Neurons / Optimizer\n",
    "\n",
    "param_grid = dict(epochs=epochs,batch_size=batch_size)\n",
    "#param_grid = dict(epochs=epochs,batch_size=batch_size)\n",
    "#param_grid = dict(model__activation=activation_set)\n",
    "#param_grid = dict(model__dropout_rate=dropout_rate)\n",
    "#param_grid = dict(model__neurons=neurons)\n",
    "grid = GridSearchCV(estimator=kModel, param_grid=param_grid, n_jobs=-1, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_result = grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -2.695702 using {'batch_size': 200, 'epochs': 30}\n",
      "-2.884388 (0.514634) with: {'batch_size': 100, 'epochs': 15}\n",
      "-2.744219 (0.496258) with: {'batch_size': 100, 'epochs': 30}\n",
      "-2.781870 (0.523337) with: {'batch_size': 100, 'epochs': 45}\n",
      "-2.785050 (0.482216) with: {'batch_size': 150, 'epochs': 15}\n",
      "-2.966836 (0.080778) with: {'batch_size': 150, 'epochs': 30}\n",
      "-2.767534 (0.487310) with: {'batch_size': 150, 'epochs': 45}\n",
      "-2.735126 (0.383618) with: {'batch_size': 200, 'epochs': 15}\n",
      "-2.695702 (0.470909) with: {'batch_size': 200, 'epochs': 30}\n",
      "-2.726045 (0.421071) with: {'batch_size': 200, 'epochs': 45}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='metrics_full.csv'\n",
    "metrics_file = os.path.join(path, filename)\n",
    "## Load all previously generate metrics\n",
    "all_history = pd.read_csv(metrics_file)\n",
    "all_history.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "## Concatenate all metrics\n",
    "full_metrics=pd.concat([all_history,metrics_df])\n",
    "full_metrics.to_csv(metrics_file)\n",
    "## Write complete DF back to original File\n",
    "#drop recorded results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "y_pred = model_gru.predict(X_test)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(range(len(y_pred[:300])),y_pred[:300], label='Prediction')\n",
    "plt.plot(y_test[:300], label='Actual')\n",
    "plt.xlabel('Time Series')\n",
    "plt.ylabel('Readings')\n",
    "plt.title('GRU Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7c2045393b2e3298fba416c7980a67b423cc5ff7d51bff314d8a0df9b998066"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7c2045393b2e3298fba416c7980a67b423cc5ff7d51bff314d8a0df9b998066"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
